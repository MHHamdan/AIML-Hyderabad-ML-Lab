{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"name": "Demo_Word_Similarity.ipynb", "provenance": [], "collapsed_sections": []}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "accelerator": "GPU"}, "cells": [{"cell_type": "markdown", "metadata": {"id": "y9NNhMb5wbUK"}, "source": ["# Advanced Certification in AIML\n", "## A Program by IIIT-H and TalentSprint\n", "\n", "### Not for Grading"]}, {"cell_type": "markdown", "metadata": {"id": "qu26Vq9jDTpj"}, "source": ["### Learning Objectives:\n", "\n", "At the end of the experiment, you will be able to:\n", " \n", "*  generate word embeddings using pre-trained models\n", "*  visualize the similar words"]}, {"cell_type": "markdown", "metadata": {"id": "rN0OyDALwbUU"}, "source": ["### Setup Steps"]}, {"cell_type": "code", "metadata": {"id": "dl8SNclREUFc"}, "source": ["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n", "Id = \"\" #@param {type:\"string\"}\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "2mZWqpx3EUKh"}, "source": ["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n", "password = \"\" #@param {type:\"string\"}\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "QRvlfkw5rV_Q", "cellView": "form"}, "source": ["#@title Run this cell to complete the setup for this Notebook\n", "from IPython import get_ipython\n", "\n", "ipython = get_ipython()\n", "  \n", "notebook= \"Demo_Word_Similarity\" #name of the notebook\n", "Answer = \"Ungraded\"\n", "def setup():\n", "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/glove.6B.zip\")\n", "    ipython.magic(\"sx unzip glove.6B.zip\")\n", "    ipython.magic(\"sx wget https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/experiment_related_data/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\")\n", "    ipython.magic(\"sx unrar e /content/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\")\n", "    from IPython.display import HTML, display\n", "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n", "    print(\"Setup completed successfully\")\n", "    return\n", "\n", "def submit_notebook():\n", "    \n", "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n", "    \n", "    import requests, json, base64, datetime\n", "\n", "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n", "    if not submission_id:\n", "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n", "      r = requests.post(url, data = data)\n", "      r = json.loads(r.text)\n", "\n", "      if r[\"status\"] == \"Success\":\n", "          return r[\"record_id\"]\n", "      elif \"err\" in r:        \n", "        print(r[\"err\"])\n", "        return None        \n", "      else:\n", "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n", "        return None\n", "\n", "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts():\n", "      f = open(notebook + \".ipynb\", \"rb\")\n", "      file_hash = base64.b64encode(f.read())\n", "\n", "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n", "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n", "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n", "              \"feedback_experiments_input\" : Comments, \"notebook\" : notebook}\n", "\n", "      r = requests.post(url, data = data)\n", "      r = json.loads(r.text)\n", "      if \"err\" in r:        \n", "        print(r[\"err\"])\n", "        return None   \n", "      else:\n", "        print(\"Your submission is successful.\")\n", "        print(\"Ref Id:\", submission_id)\n", "        print(\"Date of submission: \", r[\"date\"])\n", "        print(\"Time of submission: \", r[\"time\"])\n", "        print(\"View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\")\n", "        # print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n", "      return submission_id\n", "    else: submission_id\n", "    \n", "\n", "def getAdditional():\n", "  try:\n", "    if not Additional: \n", "      raise NameError\n", "    else:\n", "      return Additional  \n", "  except NameError:\n", "    print (\"Please answer Additional Question\")\n", "    return None\n", "def getComments():\n", "  try:\n", "    if not Comments:\n", "      raise NameError\n", "    else:\n", "      return Comments\n", "  except NameError:\n", "    print (\"Please answer Comments Question\")\n", "    return None\n", "\n", "def getComplexity():\n", "  try:\n", "    if not Complexity:\n", "      raise NameError\n", "    else:\n", "      return Complexity\n", "  except NameError:\n", "    print (\"Please answer Complexity Question\")\n", "    return None\n", "  \n", "def getConcepts():\n", "  try:\n", "    if not Concepts:\n", "      raise NameError\n", "    else:\n", "      return Concepts\n", "  except NameError:\n", "    print (\"Please answer Concepts Question\")\n", "    return None\n", "\n", "def getAnswer():\n", "  try:\n", "    if not Answer:\n", "      raise NameError \n", "    else: \n", "      return Answer\n", "  except NameError:\n", "    print (\"Please answer Question\")\n", "    return None\n", "\n", "def getId():\n", "  try: \n", "    return Id if Id else None\n", "  except NameError:\n", "    return None\n", "\n", "def getPassword():\n", "  try:\n", "    return password if password else None\n", "  except NameError:\n", "    return None\n", "\n", "submission_id = None\n", "### Setup \n", "if getPassword() and getId():\n", "  submission_id = submit_notebook()\n", "  if submission_id:\n", "    setup()\n", "    \n", "else:\n", "  print (\"Please complete Id and Password cells before running setup\")\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "mmXvUFOt9fJv"}, "source": ["# PART I\n", "#Find the similarity between words using GloVe"]}, {"cell_type": "code", "metadata": {"id": "H9sC9--9wbUq"}, "source": ["# Importing required Packages\n", "import pandas as pd\n", "import numpy as np\n", "import pprint\n", "import warnings\n", "warnings.filterwarnings(\"ignore\")"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "hDwNJHcfPaKd"}, "source": ["* **Load the GloVe pretrained model**\n", "\n", "  GloVe stands for \u201cGlobal Vectors\u201d for word representation. It is developed by Stanford for generating word embeddings. GloVe captures both global statistics and local statistics of a corpus, in order to come up with word vectors. "]}, {"cell_type": "code", "metadata": {"id": "fZt0USXAZVnk"}, "source": ["GloVe_Dict = {}\n", "\n", "with open(\"glove.6B.50d.txt\", 'r', encoding=\"utf-8\") as f:\n", "  for line in f:\n", "      values = line.split()\n", "      word = values[0]\n", "      vector = np.asarray(values[1:], \"float32\")\n", "      GloVe_Dict[word] = vector"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "isE0P3iIPaKf"}, "source": ["* Develop GloVe Embeddings for the given list of words"]}, {"cell_type": "code", "metadata": {"id": "UMzp4I3L9c4b"}, "source": ["words = ['king','queen','river','water','ocean','tree','leaf','happy', 'glad', 'mother', 'daughter']"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "cChTS3_BZsnh"}, "source": ["pp = pprint.PrettyPrinter()\n", "\n", "# Vector representation of a specific word \n", "print(\"Size of the vector is\", len(GloVe_Dict[\"king\"]))\n", "pp.pprint(GloVe_Dict[\"king\"])"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "1eBRiHNB-WJ1"}, "source": ["# Vector representation of each word using GloVe\n", "vectors = []\n", "for word in words:\n", "  vector = GloVe_Dict[word]\n", "  vectors.append(vector)\n", "print(\"There are %d words and the vector size of each word is %d\" %((len(vectors),len(vectors[0]))))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "1J8Kjgo_PaKh"}, "source": ["* Measure the similarity between the words using cosine_similarity\n"]}, {"cell_type": "code", "metadata": {"id": "FO1Vc6ZTMavW"}, "source": ["# Importing the cosine similarity\n", "from sklearn.metrics.pairwise import cosine_similarity"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "WuRZ_OZo0Z-y"}, "source": ["word_similarity = []\n", "for i,word_1 in enumerate(words):\n", "  row_wise_simiarity = []\n", "  for j,word_2 in enumerate(words):\n", "    # Get the vectors of the word using GloVe\n", "    vec_1, vec_2 = GloVe_Dict[word_1], GloVe_Dict[word_2]\n", "\n", "    # As the vectors are in one dimensional, convert it to 2D by reshaping\n", "    vec_1, vec_2 = np.array(vec_1).reshape(1,-1), np.array(vec_2).reshape(1,-1) \n", "\n", "    # Measure the cosine similarity between the vectors.\n", "    similarity = cosine_similarity(vec_1,vec_2)\n", "    row_wise_simiarity.append(np.array(similarity).item())\n", "\n", "  # Store the cosine similarity values in a list  \n", "  word_similarity.append(row_wise_simiarity)\n", "\n", "# Create a DataFrame to view the similarity between words\n", "pd.DataFrame(word_similarity, columns=words, index=words)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "7D3ZvdVjMqIH"}, "source": [" *GloVe derives the semantic relationship between the words. Higher the cosine similarity, the words are relatively closer*\n", "\n", "*For eg:* *The word 'King' is more closer to word 'Queen'*"]}, {"cell_type": "markdown", "metadata": {"id": "SzDW1vT2PaKj"}, "source": ["* Visualize the words in 2D-plane by reducing the dimensions using PCA"]}, {"cell_type": "code", "metadata": {"id": "6QnczXr2BLNj"}, "source": ["from sklearn.decomposition import PCA\n", "pca = PCA(n_components = 2)\n", "\n", "# All the vectors of each word was stored in vectors list. \n", "# Apply PCA and transform the data to 2 dimensions\n", "\n", "reduced_vectors = pca.fit_transform(vectors)\n", "\n", "from matplotlib import pyplot as plt\n", "plt.figure(figsize=(7,5))\n", "plt.scatter(reduced_vectors[:,0],reduced_vectors[:,1], s = 12, color = 'red')\n", "plt.xlim([-3.5,4.5])\n", "plt.ylim([-3.5,3.5])\n", "x, y = reduced_vectors[:,0] , reduced_vectors[:,1]\n", "for i in range(len(x)):\n", "  plt.annotate(words[i],xy=(x[i], y[i]),xytext=(x[i]+0.05,y[i]+0.05))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "YkQDxw7m9k-j"}, "source": ["# PART II\n", "# Find the similarity between words using Word2Vec\n", "\n"]}, {"cell_type": "markdown", "metadata": {"id": "jWJai9jPO3RX"}, "source": ["* Load Gensim pretrained model\n", "\n", "  * Gensim is an open source Python library for natural language processing. It is developed and is maintained by the Czech natural language processing researcher Radim \u0158eh\u016f\u0159ek and his company RaRe Technologies. \n", "\n", "  * Use gensim to load a word2vec model, pretrained on google news, covering approximately 3 million words and phrases. The vector size is 300 features.\n", "\n", "  * Download the google news bin file with the limit 500000 words and save in a binary word2vec format. If **binary = True**, then the data will be saved in binary word2vec format, else it will be saved in plain text."]}, {"cell_type": "code", "metadata": {"id": "2mfXzP6WCXOB"}, "source": ["import gensim\n", "\n", "# Load Google news 300 vectors file\n", "model = gensim.models.KeyedVectors.load_word2vec_format('AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.bin', binary=True, limit=500000)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "_PgoxX5VO9dd"}, "source": ["* Develop Word2Vec Embeddings for the list of words"]}, {"cell_type": "code", "metadata": {"id": "hg3R90IqMwQG"}, "source": ["# Vector representation of a specific word \n", "pp = pprint.PrettyPrinter()\n", "print(\"Size of the vector is\", len(model[\"king\"]))\n", "pp.pprint(model[\"king\"])"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "euxldHh-M4BL"}, "source": ["# Vector representation of each word using Word2Vec\n", "word2vec = []\n", "\n", "for word in words:\n", "  try:\n", "    word2vec.append(model[word])\n", "  except:\n", "    pass\n", "print(\"There are %d words and the vector size of each word is %d\" %(len(word2vec),len(word2vec[0])))\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "w23olxol8BIf"}, "source": ["* Measure the similarity between the words using cosine_similarity\n"]}, {"cell_type": "code", "metadata": {"id": "KvdSBvgP30h-"}, "source": ["w2v_similarity = []\n", "for i,word_1 in enumerate(words):\n", "  w2v_row_wise_simiarity = []\n", "  for j,word_2 in enumerate(words):\n", "    # Get the vectors of the word using Word2Vec\n", "    vec_1, vec_2 = model[word_1],model[word_2]\n", "\n", "    # As the vectors are in one dimensional, convert it to 2D by reshaping\n", "    vec_1, vec_2 = np.array(vec_1).reshape(1,-1), np.array(vec_2).reshape(1,-1) \n", "\n", "    # Measure the cosine similarity between two vectors\n", "    similarity = cosine_similarity(vec_1,vec_2)\n", "    w2v_row_wise_simiarity.append(np.array(similarity).item())\n", "\n", "  # Store the cosine similarity values in a list    \n", "  w2v_similarity.append(w2v_row_wise_simiarity)\n", "\n", "pd.DataFrame(w2v_similarity, columns = words, index = words)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "8JKH7o3lYlbm"}, "source": ["*Higher the cosine similarity, the words are more closer*\n", "\n", "*For eg: The word 'King' is more similar to the word 'Queen'*"]}, {"cell_type": "markdown", "metadata": {"id": "xkD6RUWK8GUG"}, "source": ["* Visualize the words in 2D-plane by reducing the dimensions using PCA"]}, {"cell_type": "code", "metadata": {"id": "27VShOpkNKay"}, "source": ["from sklearn.decomposition import PCA\n", "pca = PCA(n_components = 2)\n", "\n", "# All the vectors of each word was stored in word2vec \n", "# Apply PCA and transform the data to 2 dimensions\n", "reduced_w2v = pca.fit_transform(word2vec)\n", "\n", "plt.figure(figsize=(8,5))\n", "plt.scatter(reduced_w2v[:,0],reduced_w2v[:,1], s = 12, color = 'red')\n", "plt.xlim([-2.5,2.5])\n", "plt.ylim([-2.5,2.5])\n", "x, y = reduced_w2v[:,0] , reduced_w2v[:,1]\n", "for i in range(len(x)):\n", "  plt.annotate(words[i],xy=(x[i], y[i]),xytext=(x[i]+0.05,y[i]+0.05))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "tC2rt1ZxrgC7"}, "source": ["## Please answer the questions below to complete the experiment:"]}, {"cell_type": "code", "metadata": {"id": "NMzKSbLIgFzQ"}, "source": ["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n", "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "DjcH1VWSFI2l"}, "source": ["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n", "Additional = \"\" #@param {type:\"string\"}\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "_cTetkuegP7d"}, "source": ["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n", "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "QFQw0ddId_Ej"}, "source": ["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n", "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "-CXztFuygSBG", "cellView": "form"}, "source": ["#@title Run this cell to submit your notebook  { vertical-output: true }\n", "try:\n", "  if submission_id:\n", "      return_id = submit_notebook()\n", "      if return_id : submission_id =return_id\n", "  else:\n", "      print(\"Please complete the setup first.\")\n", "except NameError:\n", "  print (\"Please complete the setup first.\")"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "hWHEy78w-sPM"}, "source": [""], "execution_count": null, "outputs": []}]}