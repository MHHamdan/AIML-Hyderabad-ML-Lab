{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"U1W5_16_Text_representation_using_Sckit_learn.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-uKoHMMJ0iOE"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","### Not for Grading"]},{"cell_type":"markdown","metadata":{"id":"c-9LguthAIGs"},"source":["## Objective\n","\n","- To understand several techniques in Text representation"]},{"cell_type":"markdown","metadata":{"id":"snBfzAFAkIFA"},"source":["## Dataset\n","   Here we will be using Movies_review data which contains 50000 reviews. The training data and testing are split evenly, 25k reviews under reviews_train and 25k under reviews_test. \n","Under each file first 12500 reviews are positive and remaining 12500 are negative reviews.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tYLk8_mcUOQm"},"source":["### Setup Steps"]},{"cell_type":"code","metadata":{"id":"ao1f-O4AUQpe"},"source":["#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n","Id = \"2100121\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ApY1qrn-UT7r"},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"5142192291\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRvlfkw5rV_Q","cellView":"form"},"source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","\n","ipython = get_ipython()\n","  \n","notebook= \"U1W5_16_Text_representation_using_Sckit_learn\" #name of the notebook\n","Answer = \"Ungraded\"\n","def setup():\n","    ipython.magic(\"sx pip3 install gensim\")\n","    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/movie_data.tar.gz\")\n","    from IPython.display import HTML, display\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"feedback_experiments_input\" : Comments, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:        \n","        print(r[\"err\"])\n","        return None   \n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\")\n","        # print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if not Additional: \n","      raise NameError\n","    else:\n","      return Additional  \n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    if not Answer:\n","      raise NameError \n","    else: \n","      return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","    \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0ZzWcaEAC6s"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qBgMzy4jAxbU"},"source":["#Extract the files from the downloaded folder\n","import tarfile\n","my_tar = tarfile.open('movie_data.tar.gz')\n","my_tar.extractall('./sample_data') # Specify which folder to extract to\n","my_tar.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LsXb4LeA8qPA"},"source":["# Importing required libraries\n","from sklearn.metrics import accuracy_score\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import os\n","import re\n","#warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KZv8zJIt8zy4"},"source":["# Read each line and append in a list\n","reviews_train = []\n","for line in open('/content/sample_data/movie_data/full_train.txt', 'r'):  # 'r' means that the file should be opened in read mode\n","    \n","    reviews_train.append(line.strip()) \n","    \n","reviews_test = []\n","for line in open('/content/sample_data/movie_data/full_test.txt', 'r'):\n","    \n","    reviews_test.append(line.strip())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xBZqzPqR8_md"},"source":["# To read the 20000th review from train text file.\n","reviews_train[20000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ekBGXYC2_S-8"},"source":["Replace_without_space = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")# All these charaacters in text will be removed\n","Replace_with_space = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")# All these characters in text will be replaced by space\n","NO_SPACE = \"\"\n","SPACE = \" \"\n","\n","def preprocess_reviews(reviews):\n","    reviews = [Replace_without_space.sub(NO_SPACE, line.lower()) for line in reviews]\n","    reviews = [Replace_with_space.sub(SPACE, line) for line in reviews]\n","    return reviews\n","\n","reviews_train_clean = preprocess_reviews(reviews_train)\n","reviews_test_clean = preprocess_reviews(reviews_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0O_3LXcs_of2"},"source":["reviews_train_clean[20000] # Print one of the review"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GCbUX25rDkD0"},"source":["Creating target where first 12500 reviews are positive and remaining 12500 are negative reviews."]},{"cell_type":"code","metadata":{"id":"RVNZvV2oy7FD"},"source":["target = [1 if i < 12500 else 0 for i in range(25000)]# labeling positive reviews as 1 and negative reviews as 0\n","print(len(target), target[345], target[20000])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S9MnDcKliORP"},"source":["## CountVectorizer \n"]},{"cell_type":"markdown","metadata":{"id":"oiz7XKrmQ9l3"},"source":["Using N-grams get the consecutive words from the given text and get the feature vector using the countvectorizer for the same."]},{"cell_type":"code","metadata":{"id":"p4ocUqUv_sLf"},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","'''To get binary values (1 for present or 0 for absent) instead of counts of terms/tokens, give binary=True. \n","N-Gram range basically lets you decide the length of the sequence of consecutive words in the given text. Suppose the n-gram range = (1, 3).\n","Then it will pick the unigram(only single word), bigram (group of 2 consecutive words), and the trigram (group of 3 consecutive words).'''\n","\n","ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))  \n","ngram_vectorizer.fit(reviews_train_clean)     # Tokenize and build vocab\n","X = ngram_vectorizer.transform(reviews_train_clean) # To get the features\n","X_test_vec = ngram_vectorizer.transform(reviews_test_clean) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YeEuYxynkBtn"},"source":["### Splitting the review_train data into train and test sets \n","\n","Hint: [Train-Test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"]},{"cell_type":"code","metadata":{"id":"u7kCsHWMkA-M"},"source":["from sklearn.model_selection import train_test_split\n","\n","#YOUR CODE HERE\n","# split into train test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=42)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qpfOG53zlz5S"},"source":["#### Applying the Logistic Regression for the splitted review_train data"]},{"cell_type":"code","metadata":{"id":"5MobyOy-j05p"},"source":["from sklearn.linear_model import LogisticRegression\n","lr = LogisticRegression(max_iter=25000)  \n","\n","#YOUR CODE HERE\n","lr.fit(X_train,y_train)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJL-EiZZofOR"},"source":["# Using the trained model get the predictions on the review_test data\n","predict = lr.predict(X_test_vec)\n","accuracy_score(target, predict)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YQr_afHnUcTL"},"source":["### TF IDF\n"," tf-idf aims to represent the number of times a given word appears in a document (a movie review in our case) relative to the number of documents in the corpus that the word appears in — where, words that appear in many documents have a value closer to zero and words that appear in less documents have values closer to 1.\n","\n","We have seen how to get the consecutive words using n-grams, similarly you can try without using n-grams\n"]},{"cell_type":"code","metadata":{"id":"_x75doewBlY-"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","tfidf_vectorizer = TfidfVectorizer()\n","tfidf_vectorizer.fit(reviews_train_clean)\n","Y = tfidf_vectorizer.transform(reviews_train_clean)\n","X_test_tfidf = tfidf_vectorizer.transform(reviews_test_clean)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GXQcZ_plKMDh"},"source":["### Splitting the review_train data into train and test sets \n","\n","Hint: [Train-Test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"]},{"cell_type":"code","metadata":{"id":"pgjZaKTUKMDm"},"source":["from sklearn.model_selection import train_test_split\n","#YOUR CODE HERE\n","X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=42)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lZwW_AFZxlXt"},"source":["#### Applying the Logistic Regression"]},{"cell_type":"code","metadata":{"id":"E1vkXQEExlXx"},"source":["lr = LogisticRegression(max_iter=25000) \n"," \n","#YOUR CODE HERE\n","lr.fit(X_train,y_train)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYwelCgQxlYK"},"source":["# Using the trained model get the predictions on the review_test data\n","\n","predict = lr.predict(X_test_vec)\n","accuracy_score(target, predict)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tC2rt1ZxrgC7"},"source":["## Please answer the questions below to complete the experiment:"]},{"cell_type":"code","metadata":{"id":"NMzKSbLIgFzQ"},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Good, But Not Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjcH1VWSFI2l"},"source":["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"nan\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_cTetkuegP7d"},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFQw0ddId_Ej"},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CXztFuygSBG","cellView":"form"},"source":["#@title Run this cell to submit your notebook  { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9j_nWEu3O9eb"},"source":[""],"execution_count":null,"outputs":[]}]}