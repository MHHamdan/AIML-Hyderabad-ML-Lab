{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"name": "U2W7_02_Aptitude_Classification_B.ipynb", "provenance": [], "collapsed_sections": []}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "cells": [{"cell_type": "markdown", "metadata": {"id": "UH62CWxTDTpf"}, "source": ["# Advanced Certification in AIML\n", "## A Program by IIIT-H and TalentSprint"]}, {"cell_type": "code", "metadata": {"cellView": "form", "id": "FEDdr-Rf54DD"}, "source": ["#@title Experiment Walkthrough\n", "from IPython.display import HTML\n", "\n", "HTML(\"\"\"<video width=\"320\" height=\"240\" controls>\n", "  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/Aptitude_classification.mp4\">\n", "</video>\n", "\"\"\")"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "qu26Vq9jDTpj"}, "source": ["### Learning Objectives:\n", "\n", "At the end of the experiment, you will be able to:\n", "\n", "*  generate vectors using Word2Vec model"]}, {"cell_type": "markdown", "metadata": {"id": "FL0Ve1abn6YJ"}, "source": ["## Dataset\n", "Being able to classify the questions will be difficult in natural language processing. The dataset is taken from the TalentSprint aptitude questions which contains more than 20K questions.\n", "\n", "## Description\n", "This dataset has the following columns:\n", "1. **Category:** Gives the high-level categorization of the question\n", "2. **Sub-Category:** Determines the type of questions\n", "3. **Article:** Gives the article name of the question\n", "4. **Questions:** Questions are listed\n", "5. **Answers:** Contains answers\n", "\n", "\n", "\n", "The dataset, which is considered in the experiment is partially pre-processed using BeautifulSoup and removed punctuations, HTML tags.\n"]}, {"cell_type": "markdown", "metadata": {"id": "-ZYYZDRUDZQe"}, "source": ["### Setup Steps"]}, {"cell_type": "code", "metadata": {"id": "dl8SNclREUFc"}, "source": ["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n", "Id = \"\" #@param {type:\"string\"}\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "2mZWqpx3EUKh"}, "source": ["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n", "password = \"\" #@param {type:\"string\"}\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "WBPPuGmBlDIN", "cellView": "form"}, "source": ["#@title Run this cell to complete the setup for this Notebook\n", "from IPython import get_ipython\n", "\n", "ipython = get_ipython()\n", "  \n", "notebook= \"U2W7_02_Aptitude_Classification_B\" #name of the notebook\n", "\n", "def setup():\n", "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Cleaned_Aptitude_Classification.csv\")\n", "    ipython.magic(\"sx wget https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/experiment_related_data/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\")\n", "    ipython.magic(\"sx unrar e /content/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\") \n", "    from IPython.display import HTML, display\n", "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n", "    print(\"Setup completed successfully\")\n", "    return\n", "\n", "def submit_notebook():\n", "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n", "    \n", "    import requests, json, base64, datetime\n", "\n", "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n", "    if not submission_id:\n", "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n", "      r = requests.post(url, data = data)\n", "      r = json.loads(r.text)\n", "\n", "      if r[\"status\"] == \"Success\":\n", "          return r[\"record_id\"]\n", "      elif \"err\" in r:        \n", "        print(r[\"err\"])\n", "        return None        \n", "      else:\n", "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n", "        return None\n", "    \n", "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n", "      f = open(notebook + \".ipynb\", \"rb\")\n", "      file_hash = base64.b64encode(f.read())\n", "\n", "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n", "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n", "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n", "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n", "              \"feedback_experiments_input\" : Comments,\n", "              \"feedback_mentor_support\": Mentor_support}\n", "\n", "      r = requests.post(url, data = data)\n", "      r = json.loads(r.text)\n", "      if \"err\" in r:        \n", "        print(r[\"err\"])\n", "        return None   \n", "      else:\n", "        print(\"Your submission is successful.\")\n", "        print(\"Ref Id:\", submission_id)\n", "        print(\"Date of submission: \", r[\"date\"])\n", "        print(\"Time of submission: \", r[\"time\"])\n", "        print(\"View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\")\n", "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n", "        return submission_id\n", "    else: submission_id\n", "    \n", "\n", "def getAdditional():\n", "  try:\n", "    if not Additional: \n", "      raise NameError\n", "    else:\n", "      return Additional  \n", "  except NameError:\n", "    print (\"Please answer Additional Question\")\n", "    return None\n", "\n", "def getComplexity():\n", "  try:\n", "    if not Complexity:\n", "      raise NameError\n", "    else:\n", "      return Complexity\n", "  except NameError:\n", "    print (\"Please answer Complexity Question\")\n", "    return None\n", "  \n", "def getConcepts():\n", "  try:\n", "    if not Concepts:\n", "      raise NameError\n", "    else:\n", "      return Concepts\n", "  except NameError:\n", "    print (\"Please answer Concepts Question\")\n", "    return None\n", "  \n", "  \n", "def getWalkthrough():\n", "  try:\n", "    if not Walkthrough:\n", "      raise NameError\n", "    else:\n", "      return Walkthrough\n", "  except NameError:\n", "    print (\"Please answer Walkthrough Question\")\n", "    return None\n", "  \n", "def getComments():\n", "  try:\n", "    if not Comments:\n", "      raise NameError\n", "    else:\n", "      return Comments\n", "  except NameError:\n", "    print (\"Please answer Comments Question\")\n", "    return None\n", "  \n", "\n", "def getMentorSupport():\n", "  try:\n", "    if not Mentor_support:\n", "      raise NameError\n", "    else:\n", "      return Mentor_support\n", "  except NameError:\n", "    print (\"Please answer Mentor support Question\")\n", "    return None\n", "\n", "def getAnswer():\n", "  try:\n", "    if not Answer:\n", "      raise NameError \n", "    else: \n", "      return Answer\n", "  except NameError:\n", "    print (\"Please answer Question\")\n", "    return None\n", "  \n", "\n", "def getId():\n", "  try: \n", "    return Id if Id else None\n", "  except NameError:\n", "    return None\n", "\n", "def getPassword():\n", "  try:\n", "    return password if password else None\n", "  except NameError:\n", "    return None\n", "\n", "submission_id = None\n", "### Setup \n", "if getPassword() and getId():\n", "  submission_id = submit_notebook()\n", "  if submission_id:\n", "    setup() \n", "else:\n", "  print (\"Please complete Id and Password cells before running setup\")\n", "\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "pP9bMLVgLRTp"}, "source": ["#### Importing required packages"]}, {"cell_type": "code", "metadata": {"id": "1uTIg1Jtaj_w"}, "source": ["# Importing and downloading required packages\n", "import nltk\n", "import gensim\n", "import pandas as pd\n", "from nltk.stem import WordNetLemmatizer \n", "from nltk import word_tokenize\n", "from nltk.corpus import stopwords\n", "nltk.download('punkt')\n", "nltk.download(\"stopwords\")\n", "nltk.download('wordnet')"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "KeTxW7Uf8xYn"}, "source": ["### Data loading and preparation\n", "\n", "Loading the aptitude classification dataset containing all the aptitude questions of various sub-categories\n", "\n", "Selecting the two sub-categories (Time and Distance, Finding Errors) from the loaded data"]}, {"cell_type": "code", "metadata": {"id": "LbrgXcFcBtgW"}, "source": ["data = pd.read_csv(\"/content/Cleaned_Aptitude_Classification.csv\")\n", "data.shape"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "4sEP70HSTRlw"}, "source": ["data.head()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "I0T5jFli81J0"}, "source": ["Out of 15 sub-categories from the data, choosing two sub-categories for this experiment"]}, {"cell_type": "code", "metadata": {"id": "zglkFtj-LAIf"}, "source": ["# Extracting two sub-categories questions \n", "category1_Que = data[data['Sub-Category']=='Misspell words']['Questions'].values\n", "category2_Que = data[data['Sub-Category']== 'Finding Errors']['Questions'].values"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "dGxvheKY-lmv"}, "source": ["# Printing the sample question from first chosen Sub-Category\n", "category1_Que[0]"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "T7WYeZTQLlu6"}, "source": ["#### Pre-processing and tokenization\n", "\n", "Pre-processing the text and applying tokenization to get vocabulary words of both chosen sub-categories"]}, {"cell_type": "code", "metadata": {"id": "fopV3S-OuImU"}, "source": ["# Intializing nltk requirements for pre-processing\n", "lemmatizer = WordNetLemmatizer()\n", "stoplist = set(stopwords.words('english')) "], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "oWzYzn50uoLr"}, "source": ["# Tokenize the sentence and get vocab words\n", "def Tokenize(AllQuestions):\n", "  pre_processed_words = []\n", "  for each in AllQuestions:\n", "    # YOUR CODE HERE to tokenize and pre-process the words\n", "    \n", "  pre_processed_words = set(pre_processed_words)\n", "\n", "  pre_processed_words = [word for word in pre_processed_words if word not in stoplist]\n", "  return pre_processed_words"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "h6yQqOLuvHbj"}, "source": ["# Calling the above Tokenize function to get vocab words of both sub-categories\n", "category1_words = Tokenize(category1_Que)\n", "category2_words = Tokenize(category2_Que)\n", "\n", "# Combining the words of two sub-categories\n", "all_words = category1_words + category2_words\n", "print(\"Number of valid words after pre-processing:\", len(all_words))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "QTNmN01RHUf-"}, "source": ["\n", "### Loading the word2vec model"]}, {"cell_type": "markdown", "metadata": {"id": "csm5a0hrDTqI"}, "source": ["Load Gensim pretrained model\n", "\n", "  * Gensim is an open source Python library for natural language processing. It is developed and is maintained by the Czech natural language processing researcher Radim \u0158eh\u016f\u0159ek and his company RaRe Technologies. \n", "\n", "  * Use gensim to load a word2vec model, pretrained on google news, covering approximately 3 million words and phrases. The vector length is 300 features.\n", "\n", "  * Download the google news bin file with the limit 500000 words and save in a binary word2vec format. If **binary = True**, then the data will be saved in binary word2vec format, else it will be saved in plain text.\n"]}, {"cell_type": "code", "metadata": {"id": "2mfXzP6WCXOB"}, "source": ["# Load 300 vectors directly from the file. As the model is in .bin extension, we need to enable default parameter, binary = True\n", "model = gensim.models.KeyedVectors.load_word2vec_format('AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.bin', binary=True, limit=500000)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "ksKrewQRDLKe"}, "source": ["# Pre-trained model gives representation of 300 size vector\n", "print(\"Dimension of the word 'tree': \", len(model['tree']))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "W3Y6UlpLKAeT"}, "source": ["### Generate vectors for each word\n", "\n", "Words that appear in both the sub-categories will have the same representation but different label, which may lead to less accuracy in classification, Ignoring the words that are intersecting both the chosen sub-categories"]}, {"cell_type": "code", "metadata": {"id": "fxCopZzgEuwW"}, "source": ["# Get vector representation using model for the all the extraced words of two sub-categories\n", "vectors, labels = [], []\n", "for word in all_words:\n", "  try:\n", "    # Ignoring the words that appear in both sub-categories\n", "    if ~(word in category1_words and word in category2_words):\n", "      # YOUR CODE HERE to generate vectors and append label\n", "  except:\n", "    pass\n", "print(\"Number of words:\", len(labels))\n", "print(\"Number of dimensions in each vector:\", len(vectors[0]))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "Lwye2kelJLy2"}, "source": ["### Split the Data into train and test"]}, {"cell_type": "code", "metadata": {"id": "FjlN6HSMQkqm"}, "source": ["# YOUR CODE HERE to split the data"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "PSGk6xiGJPMt"}, "source": ["### Fit the model and calculate the accuracy"]}, {"cell_type": "code", "metadata": {"id": "Ig9_o2V1FcOC"}, "source": ["# YOUR CODE HERE to classify"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "Jfj1RGVTIEPM"}, "source": ["### Ungraded Exercise: \n", "\n", "Take any other two sub-categories and get vector representation using word2vec"]}, {"cell_type": "code", "metadata": {"id": "_z5_5cRKIBWd"}, "source": ["# YOUR CODE HERE"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "tC2rt1ZxrgC7"}, "source": ["## Please answer the questions below to complete the experiment:"]}, {"cell_type": "code", "metadata": {"id": "pIZzNYjiZnLk"}, "source": ["#@title Word embeddings capture multiple dimensions of data and are represented as vectors { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n", "Answer = \"\" #@param [\"\",\"True\",\"False\"]\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "NMzKSbLIgFzQ"}, "source": ["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n", "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "DjcH1VWSFI2l"}, "source": ["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n", "Additional = \"\" #@param {type:\"string\"}\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "4VBk_4VTAxCM"}, "source": ["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n", "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "r35isHfTVGKc"}, "source": ["#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n", "Walkthrough = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "XH91cL1JWH7m"}, "source": ["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n", "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "z8xLqj7VWIKW"}, "source": ["#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n", "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "FzAZHt1zw-Y-", "cellView": "form"}, "source": ["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n", "try:\n", "  if submission_id:\n", "      return_id = submit_notebook()\n", "      if return_id : submission_id = return_id\n", "  else:\n", "      print(\"Please complete the setup first.\")\n", "except NameError:\n", "  print (\"Please complete the setup first.\")"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "95e95q1N8Wt4"}, "source": [""], "execution_count": null, "outputs": []}]}