{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"U3W14_29_Overfitting_Ants_Bees_PyTorch_A.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-zSWyuZTlYS1"},"source":["\n","# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"oU2MBx7JtTyP"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"Ot3pfe3AtWaN"},"source":["At the end of the experiment, you will be able to:\n","\n","* reduce overfitting using regularization method"]},{"cell_type":"code","metadata":{"id":"VDtOUGiIbwT2","cellView":"form"},"source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"800\" height=\"300\" controls>\n","  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/Walkthrough_Overfitting_Ants_Bees.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"35RBpSDUtYUm"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"SVIILnxWtcKA"},"source":["### Description\n","\n","For this experiment we have choosen a dataset which is subset of Imagenet. We have taken images belonging to ants and bees. The dataset contains 244 training images and 153 validation images. \n","\n","![alt text]( https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/15.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iiXPGTW_lgPr"},"source":["### Setup Steps"]},{"cell_type":"code","metadata":{"id":"b6IbB-MBliAa","executionInfo":{"status":"ok","timestamp":1608265757933,"user_tz":300,"elapsed":370,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n","Id = \"2100121\" #@param {type:\"string\"}\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNFH7eLklj18","executionInfo":{"status":"ok","timestamp":1608265760458,"user_tz":300,"elapsed":762,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"5142192291\" #@param {type:\"string\"}\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"oWC2d3i-DY4s","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1608265769318,"user_tz":300,"elapsed":8019,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"08b52359-3572-4223-aea2-27d00b3962d9"},"source":["#@title Run this cell to complete the setup for this Notebook  \n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"U3W14_29_Overfitting_Ants_Bees_PyTorch_A\" #name of the notebook\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\") \n","    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/hymenoptera_data.zip\")\n","    ipython.magic(\"sx unzip /content/hymenoptera_data.zip\")\n","    from IPython.display import HTML, display\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","\n","def submit_notebook():\n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","    \n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n","              \"feedback_experiments_input\" : Comments,\n","              \"feedback_mentor_support\": Mentor_support}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:        \n","        print(r[\"err\"])\n","        return None   \n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\")\n","        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","        return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if not Additional: \n","      raise NameError\n","    else:\n","      return Additional  \n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","  \n","  \n","def getWalkthrough():\n","  try:\n","    if not Walkthrough:\n","      raise NameError\n","    else:\n","      return Walkthrough\n","  except NameError:\n","    print (\"Please answer Walkthrough Question\")\n","    return None\n","  \n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","  \n","\n","def getMentorSupport():\n","  try:\n","    if not Mentor_support:\n","      raise NameError\n","    else:\n","      return Mentor_support\n","  except NameError:\n","    print (\"Please answer Mentor support Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    if not Answer:\n","      raise NameError \n","    else: \n","      return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","  \n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup() \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2100121&recordId=11669\"></script>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GEeo3n0ElYS_"},"source":["### Importing the required packages"]},{"cell_type":"code","metadata":{"id":"6Ydf-Vi2P2r6","executionInfo":{"status":"ok","timestamp":1608265773639,"user_tz":300,"elapsed":4319,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["import torch\n","from torch import nn\n","from torchvision import datasets, transforms\n","from torch import optim\n","import matplotlib.pyplot as plt"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wKWUSRUQuwmW"},"source":["### Defining Transformation\n"]},{"cell_type":"code","metadata":{"id":"zPjq8djgJY7v","executionInfo":{"status":"ok","timestamp":1608265803013,"user_tz":300,"elapsed":582,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["image_size = (128,128)\n","# Define Transformation for an image\n","transformations = transforms.Compose([\n","                                # YOUR CODE HERE to define transformations\n","                                transforms.Resize(image_size), \n","                                transforms.Grayscale(),\n","                                transforms.ToTensor(), \n","                                transforms.Normalize((0.5,), (0.5,))\n","                                ])"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SM5nwIvuu2Nw"},"source":["### Data Loading\n","\n","\n","**torch.utils.data.DataLoader** class represents a Python iterable over a dataset, with following features.\n","\n","1. Batching the data\n","2. Shuffling the data\n","3. Load the data in parallel using multiprocessing workers.\n","\n","\n","The batches of train and test data are provided via data loaders that provide iterators over the datasets to train our models."]},{"cell_type":"code","metadata":{"id":"1OxC0CShJZZ7","executionInfo":{"status":"ok","timestamp":1608265860134,"user_tz":300,"elapsed":390,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["batch_size = 100 \n","train_set = datasets.ImageFolder('/content/hymenoptera_data/train', transform = transformations)\n","trainloader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True, num_workers=8)\n","\n","# YOUR CODE HERE for Val Image folder\n","val_set = datasets.ImageFolder('/content/hymenoptera_data/val',transform=transformations)\n","# YOUR CODE HERE for Val Image folder\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size=100, shuffle=True)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pEYZoawOppFN"},"source":["### Defining the Architecture"]},{"cell_type":"markdown","metadata":{"id":"TEhqiDSmfE3C"},"source":["Neural Networks are inherited from the nn.Module class.\n","\n","Now let us define a neural network. Here we are using two functions \\__init__ and forward function.\n","\n","In the \\__init__  function, we define the layers using the provided modules from the nn package. The forward function is called on the Neural Network for a set of inputs, and it passes that input through the different layers that have been defined. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"oEJHXJD0jTwD","executionInfo":{"status":"ok","timestamp":1608265993384,"user_tz":300,"elapsed":540,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","\n","        self.linear1 = nn.Linear(16384,4096)\n","        self.linear2 = nn.Linear(4096,1024)\n","        self.linear3 = nn.Linear(1024,256)\n","        self.linear4 = nn.Linear(256,10)\n","        self.linear5 = nn.Linear(10,2)\n","    \n","    def forward(self, x):\n","        \n","        # YOUR CODE HERE to implement forward pass\n","        out = x.view(x.shape[0],-1)\n","        out = self.linear1(out)\n","\n","        out = self.linear2(out)\n","        out = self.linear3(out)\n","        out = self.linear4(out)\n","        \n","        out = self.linear5(out)\n","        return out\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nw3kD1Kjqvx_"},"source":["### Calling the instances of the network\n","\n","Let us declare an object of class model, and make it a CUDA model if CUDA is available:"]},{"cell_type":"code","metadata":{"id":"F_5p3NM4S9CR","executionInfo":{"status":"ok","timestamp":1608266199998,"user_tz":300,"elapsed":885,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["# Instantiate the model\n","device = torch.device(\"cuda\")\n","# YOUR CODE HERE to instantiate the model and convert to cuda type\n","model = Model().to(device)\n","\n","# YOUR CODE HERE to define loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr = 0.001)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F75Z3ABdqvyY"},"source":["### Training and Testing the model\n","\n","In Training Phase, we iterate over a batch of images in the train_loader. For each batch, we perform  the following steps:\n","\n","* First we zero out the gradients using zero_grad()\n","\n","* We pass the data to the model i.e. we perform forward pass by calling the forward()\n","\n","* We calculate the loss using the actual and predicted labels\n","\n","* Perform Backward pass using backward() to update the weights"]},{"cell_type":"code","metadata":{"id":"kG_e4hjdrgs7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608266530996,"user_tz":300,"elapsed":3363,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"897bb8ca-e72b-49d5-9117-e86e9dc12fa1"},"source":["# No of Epochs\n","epoch = 1\n","\n","# keeping the network in train mode\n","model.train()\n","train_losses,  train_accuracy = [], []\n","val_losses , val_accuracy = [], []\n","# Loop for no of epochs\n","for e in range(epoch):\n","    train_loss = 0\n","    correct = 0\n","    # Iterate through all the batches in each epoch\n","    for images, labels in trainloader:\n","\n","      # Convert the image and label to gpu for faster execution\n","      images = images.to(device)\n","      labels = labels.to(device)\n","\n","      # Zero the parameter gradients\n","      optimizer.zero_grad()\n","\n","      # Passing the data to the model (Forward Pass)\n","      outputs = model(images)\n","\n","      # Calculating the loss\n","      loss = criterion(outputs, labels)\n","      train_loss += loss.item()\n","\n","      # Performing backward pass (Backpropagation)\n","      loss.backward()\n","\n","      # optimizer.step() updates the weights accordingly\n","      optimizer.step()\n","\n","      # Accuracy calculation\n","      _, predicted = torch.max(outputs, 1)\n","      correct += (predicted == labels).sum().item()\n","    val_loss = 0\n","    val_correct = 0\n","    with torch.no_grad():\n","        # Loop through all of the validation set\n","        for images, labels in val_loader:\n","            \n","            # YOUR CODE HERE to pass the val_images to model, calculate error and accuracy\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            val_output = model(images)                                                                  \n","            val_loss += criterion(val_output, labels)             \n","            _, predicted = torch.max(val_output, 1)\n","            val_correct += (predicted == labels).sum()\n"," \n","\n","    train_losses.append(train_loss/len(train_set))\n","    # YOUR CODE HERE to append val losses\n","    val_losses.append(val_loss/len(val_set))\n","    train_accuracy.append(100 * correct/len(train_set))\n","    # YOUR CODE HERE to append val accuracy\n","    val_accuracy.append(100 * val_correct/len(val_set))\n","    print('epoch: {}, Train Loss:{:.6f} Validation Loss {:.6f}Train Accuracy: {:.2f}, Validation accuracy {:.2f} '.format(e+1,train_losses[-1], val_losses[-1], train_accuracy[-1], val_accuracy[-1]))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["epoch: 1, Train Loss:0.229372 Validation Loss 0.141163Train Accuracy: 49.18, Validation accuracy 56.86 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R1338yNobnnZ"},"source":["### Data Augmentation\n","\n","\n","\n","Diversity of data and a larger dataset is the easiest way to avoid overfitting of the model. Data augmentation allows you to increase the size of your dataset by performing processes like flipping, cropping, rotation, scaling and translation on the existing images. Data augmentation not only increases the dataset size but also exposes the model to different angles and lighting and reduces the bias in the dataset, thus avoiding chances of overfitting. \n","\n","Added two more transformations to the original data.\n","\n","\n","*   Applied random rotation of $45^o$ using **`transforms.RandomRotation`**\n","*   Applied vertical flip to the images using **`transforms.RandomVerticalFlip()`**\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"n7hR9B_pbm2g","executionInfo":{"status":"ok","timestamp":1608266536773,"user_tz":300,"elapsed":348,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["image_size = (128,128)\n","transformations = transforms.Compose([\n","                                transforms.Resize(image_size), \n","                                transforms.Grayscale(),\n","                                transforms.RandomRotation(45),\n","                                transforms.RandomVerticalFlip(),\n","                                transforms.ToTensor(), \n","                                transforms.Normalize((0.5,), (0.5,)),\n","\n","                                ])"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HdQKsm-bm2i","executionInfo":{"status":"ok","timestamp":1608266572927,"user_tz":300,"elapsed":385,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["batch_size = 100 \n","\n","# YOUR CODE HERE to load train and validaion data in batches\n","\n","train_set = datasets.ImageFolder('/content/hymenoptera_data/train', transform = transformations)\n","trainloader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True, num_workers=8)\n","\n","val_set = datasets.ImageFolder('/content/hymenoptera_data/val',transform=transformations)\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size=100, shuffle=True, num_workers=8)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tHgEW9-RmdL1"},"source":["#### Regularization\n","\n","Dropouts: Regularization techniques prevent the model from overfitting by modifying the cost function. Dropout, on the other hand, prevents overfitting by modifying the network itself. Every neuron apart from the ones in the output layer is assigned a probability p of being temporarily ignored from calculations. p is also called dropout rate and is initialized to 0.2. Then, as each iteration progresses, the neurons in each layer with the highest probability get dropped. This results in creating a smaller network with each epoch. Since in each iteration, a random input value can be eliminated, the network tries to balance the risk and not to favour any of the features and reduces bias and noise. "]},{"cell_type":"markdown","metadata":{"id":"0ZAiX592ZeoG"},"source":["### Optimize the Architecture"]},{"cell_type":"code","metadata":{"id":"Et6X_fnFGR3t","executionInfo":{"status":"ok","timestamp":1608266593635,"user_tz":300,"elapsed":369,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["class Optimized_Model(nn.Module):\n","    def __init__(self):\n","        super(Optimized_Model, self).__init__()\n","\n","        self.linear1 = nn.Linear(16384,4096)\n","        self.linear2 = nn.Linear(4096,1024)\n","        self.linear3 = nn.Linear(1024,256)\n","        self.linear4 = nn.Linear(256,10)\n","        self.linear5 = nn.Linear(10,2)\n","        self.dropout = nn.Dropout(0.2)\n","    def forward(self, x):\n","        # YOUR CODE HERE to implement forward pass\n","\n","        out = x.view(x.shape[0],-1)\n","        out = self.linear1(out)\n","\n","        out = self.linear2(out)\n","        out = self.linear3(out)\n","        out = self.linear4(out)\n","        out = self.dropout(self.linear5(out))\n","        \n","        return out\n"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Au6wjEGWZADQ"},"source":["#### Initialize the optimized model"]},{"cell_type":"code","metadata":{"id":"kRMMDeiFWlOY","executionInfo":{"status":"ok","timestamp":1608266619535,"user_tz":300,"elapsed":1088,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["# Instantiate the model\n","device = torch.device(\"cuda\")\n","\n","# YOUR CODE BELOW to instantiate model and define loss function and optimizer\n","model2 = Optimized_Model().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model2.parameters(), lr = 0.001)\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xEmKN7nRvDwm"},"source":["### Training the optimized model\n","\n","In Training Phase, we iterate over a batch of images in the train_loader. For each batch, we perform  the following steps:\n","\n","* First we zero out the gradients using zero_grad()\n","\n","* We pass the data to the model i.e. we perform forward pass by calling the forward()\n","\n","* We calculate the loss using the actual and predicted labels\n","\n","* Perform Backward pass using backward() to update the weights"]},{"cell_type":"code","metadata":{"id":"gt_oZCN3P8rd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608266964996,"user_tz":300,"elapsed":3278,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"15b7428f-e2f8-4cb4-dfa5-fec01941368e"},"source":["# No of Epochs\n","epoch = 1\n","\n","model2.train()\n","train_losses_opt,  train_accuracy_opt = [], []\n","val_losses_opt , val_accuracy_opt = [], []\n","    \n","for e in range(epoch):\n","    otrain_loss = 0\n","    ocorrect = 0\n","    # Iterate through all the batches in each epoch\n","    for images, labels in trainloader:\n","      \n","      # Convert the image and label to gpu for faster execution\n","      images = images.to(device)\n","      labels = labels.to(device)\n","      \n","      # Zero the parameter gradients\n","      optimizer.zero_grad()\n","      \n","      # YOUR CODE HERE to perform forward pass\n","      outputs = model2(images)\n","\n","      # Calculating the loss\n","      loss = criterion(outputs, labels)\n","      otrain_loss += loss.item()\n","\n","      # Performing backward pass (Backpropagation)\n","      loss.backward()\n","\n","      # optimizer.step() updates the weights accordingly\n","      optimizer.step()\n","\n","      # YOUR CODE HERE for accuracy calculation\n","      _, predicted = torch.max(outputs, 1)\n","      ocorrect += (predicted == labels).sum().item()\n","      \n","    oval_loss = 0\n","    oval_correct = 0\n","    with torch.no_grad():\n","        # Loop through all of the validation set\n","        for images, labels in val_loader:\n","            # YOUR CODE HERE to pass the val_images to model, calculate error and accuracy\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            val_output = model2(images)                                                                  \n","            oval_loss += criterion(val_output, labels)             \n","            _, predicted = torch.max(val_output, 1)\n","            oval_correct += (predicted == labels).sum() \n","\n","    # YOUR CODE HERE to append all train, validation accuracy and losses\n","    train_losses_opt.append(otrain_loss/len(train_set))\n","    val_losses_opt.append(oval_loss/len(val_set))\n","    train_accuracy_opt.append(100 * ocorrect/len(train_set))\n","    val_accuracy_opt.append(100 * oval_correct/len(val_set))\n","\n","    print('epoch: {}, Train Loss:{:.6f} Test Loss {:.6f} Train Accuracy: {:.2f}, Test accuracy {:.2f} '.format(e+1,train_losses_opt[-1], val_losses_opt[-1], train_accuracy_opt[-1], val_accuracy_opt[-1]))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["epoch: 1, Train Loss:0.118302 Test Loss 0.055144 Train Accuracy: 51.23, Test accuracy 47.06 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"goqw4VOf3u4h"},"source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"DIzeiEtRh5nZ","executionInfo":{"status":"ok","timestamp":1608266973155,"user_tz":300,"elapsed":386,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title State True or False: Using dropout, a random neuron in the layer gets deactivated { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer= \"TRUE\" #@param [\"\",\"TRUE\",\"FALSE\"]\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMzKSbLIgFzQ","executionInfo":{"status":"ok","timestamp":1608266976461,"user_tz":300,"elapsed":351,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Good, But Not Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjcH1VWSFI2l","executionInfo":{"status":"ok","timestamp":1608266981209,"user_tz":300,"elapsed":333,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"nn\" #@param {type:\"string\"}\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VBk_4VTAxCM","executionInfo":{"status":"ok","timestamp":1608266985673,"user_tz":300,"elapsed":361,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"r35isHfTVGKc","executionInfo":{"status":"ok","timestamp":1608266988515,"user_tz":300,"elapsed":362,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Walkthrough = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH91cL1JWH7m","executionInfo":{"status":"ok","timestamp":1608266991892,"user_tz":300,"elapsed":529,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8xLqj7VWIKW","executionInfo":{"status":"ok","timestamp":1608266994254,"user_tz":300,"elapsed":357,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzAZHt1zw-Y-","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608266996787,"user_tz":300,"elapsed":1307,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"bd4e24ed-4d50-4ae6-99d3-d0a96955e13d"},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id = return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Your submission is successful.\n","Ref Id: 11669\n","Date of submission:  18 Dec 2020\n","Time of submission:  10:18:34\n","View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\n"],"name":"stdout"}]}]}