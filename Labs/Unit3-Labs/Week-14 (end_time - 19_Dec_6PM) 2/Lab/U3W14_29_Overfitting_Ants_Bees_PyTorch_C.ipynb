{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"U3W14_29_Overfitting_Ants_Bees_PyTorch_C.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-zSWyuZTlYS1"},"source":["\n","# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"oU2MBx7JtTyP"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"Ot3pfe3AtWaN"},"source":["At the end of the experiment, you will be able to:\n","\n","* reduce overfitting using regularization method"]},{"cell_type":"code","metadata":{"id":"VDtOUGiIbwT2","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":322},"executionInfo":{"status":"ok","timestamp":1607247417642,"user_tz":300,"elapsed":388,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"4f8fe0c0-3f96-44b6-d8e1-0b92ceaaea91"},"source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"800\" height=\"300\" controls>\n","  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/Walkthrough_Overfitting_Ants_Bees.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<video width=\"800\" height=\"300\" controls>\n","  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/Walkthrough_Overfitting_Ants_Bees.mp4\" type=\"video/mp4\">\n","</video>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"35RBpSDUtYUm"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"SVIILnxWtcKA"},"source":["### Description\n","\n","For this experiment we have choosen a dataset which is subset of Imagenet. We have taken images belonging to ants and bees. The dataset contains 244 training images and 153 validation images. \n","\n","![alt text]( https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/15.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iiXPGTW_lgPr"},"source":["### Setup Steps"]},{"cell_type":"code","metadata":{"id":"b6IbB-MBliAa"},"source":["#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n","Id = \"2100121\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNFH7eLklj18"},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"5142192291\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tles91FY20M8","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1608183857247,"user_tz":300,"elapsed":9055,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"c941cf20-74e8-43ce-f13e-3a628a5e5d0f"},"source":["#@title Run this cell to complete the setup for this Notebook  \n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"U3W14_29_Overfitting_Ants_Bees_PyTorch_C\" #name of the notebook\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\") \n","    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/hymenoptera_data.zip\")\n","    ipython.magic(\"sx unzip /content/hymenoptera_data.zip\")\n","    from IPython.display import HTML, display\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","\n","def submit_notebook():\n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","    \n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n","              \"feedback_experiments_input\" : Comments,\n","              \"feedback_mentor_support\": Mentor_support}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:        \n","        print(r[\"err\"])\n","        return None   \n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\")\n","        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","        return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if not Additional: \n","      raise NameError\n","    else:\n","      return Additional  \n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","  \n","  \n","def getWalkthrough():\n","  try:\n","    if not Walkthrough:\n","      raise NameError\n","    else:\n","      return Walkthrough\n","  except NameError:\n","    print (\"Please answer Walkthrough Question\")\n","    return None\n","  \n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","  \n","\n","def getMentorSupport():\n","  try:\n","    if not Mentor_support:\n","      raise NameError\n","    else:\n","      return Mentor_support\n","  except NameError:\n","    print (\"Please answer Mentor support Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    if not Answer:\n","      raise NameError \n","    else: \n","      return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","  \n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup() \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2100121&recordId=11623\"></script>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GEeo3n0ElYS_"},"source":["### Importing the required packages"]},{"cell_type":"code","metadata":{"id":"6Ydf-Vi2P2r6"},"source":["import torch\n","from torch import nn\n","from torchvision import datasets, transforms\n","from torch import optim\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wKWUSRUQuwmW"},"source":["### Defining Transformation\n"]},{"cell_type":"code","metadata":{"id":"zPjq8djgJY7v"},"source":["image_size = (128,128)\n","# Define Transformation for an image\n","transformations = transforms.Compose([\n","                                transforms.Resize(image_size), \n","                                transforms.Grayscale(),\n","                                transforms.ToTensor(), \n","                                transforms.Normalize((0.5,), (0.5,))\n","                                ])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SM5nwIvuu2Nw"},"source":["### Data Loading\n","\n","\n","**torch.utils.data.DataLoader** class represents a Python iterable over a dataset, with following features.\n","\n","1. Batching the data\n","2. Shuffling the data\n","\n","\n","The batches of train and test data are provided via data loaders that provide iterators over the datasets to train our models."]},{"cell_type":"code","metadata":{"id":"1OxC0CShJZZ7"},"source":["batch_size = 100 \n","train_set = datasets.ImageFolder('/content/hymenoptera_data/train', transform = transformations)\n","trainloader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n","\n","val_set = datasets.ImageFolder('/content/hymenoptera_data/val',transform=transformations)\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size=100, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"puscOKllaft3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608183903153,"user_tz":300,"elapsed":302,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"3b1dd30e-c20c-494e-99b7-69db57995d59"},"source":["train_set"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset ImageFolder\n","    Number of datapoints: 244\n","    Root location: /content/hymenoptera_data/train\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(128, 128), interpolation=PIL.Image.BILINEAR)\n","               Grayscale(num_output_channels=1)\n","               ToTensor()\n","               Normalize(mean=(0.5,), std=(0.5,))\n","           )"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"pEYZoawOppFN"},"source":["### Defining the Architecture"]},{"cell_type":"markdown","metadata":{"id":"TEhqiDSmfE3C"},"source":["Neural Networks are inherited from the nn.Module class.\n","\n","Now let us define a neural network. Here we are using two functions \\__init__ and forward function.\n","\n","In the \\__init__  function, we define the layers using the provided modules from the nn package. The forward function is called on the Neural Network for a set of inputs, and it passes that input through the different layers that have been defined. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"oEJHXJD0jTwD"},"source":["class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","\n","        self.linear1 = nn.Linear(16384,4096)\n","        self.linear2 = nn.Linear(4096,1024)\n","        self.linear3 = nn.Linear(1024,256)\n","        self.linear4 = nn.Linear(256,10)\n","        self.linear5 = nn.Linear(10,2)\n","    \n","    def forward(self, x):\n","        out = x.view(x.shape[0],-1)\n","        out = self.linear1(out)\n","\n","        out = self.linear2(out)\n","        out = self.linear3(out)\n","        out = self.linear4(out)\n","        out = self.linear5(out)\n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nw3kD1Kjqvx_"},"source":["### Calling the instances of the network\n","\n","Let us declare an object of class model, and make it a CUDA model if CUDA is available:"]},{"cell_type":"code","metadata":{"id":"F_5p3NM4S9CR"},"source":["# Instantiate the model\n","device = torch.device(\"cuda\")\n","model = Model().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr = 0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F75Z3ABdqvyY"},"source":["### Training and Testing the model\n","\n","In Training Phase, we iterate over a batch of images in the train_loader. For each batch, we perform  the following steps:\n","\n","* First we zero out the gradients using zero_grad()\n","\n","* We pass the data to the model i.e. we perform forward pass by calling the forward()\n","\n","* We calculate the loss using the actual and predicted labels\n","\n","* Perform Backward pass using backward() to update the weights"]},{"cell_type":"code","metadata":{"id":"kG_e4hjdrgs7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607248124097,"user_tz":300,"elapsed":59516,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"16194a3c-2a55-48ab-8bdc-e2b26c9fa9a2"},"source":["# No of Epochs\n","epoch = 20\n","\n","# keeping the network in train mode\n","model.train()\n","train_losses,  train_accuracy = [], []\n","val_losses , val_accuracy = [], []\n","# Loop for no of epochs\n","for e in range(epoch):\n","    train_loss = 0\n","    correct = 0\n","    # Iterate through all the batches in each epoch\n","    for images, labels in trainloader:\n","\n","      # Convert the image and label to gpu for faster execution\n","      images = images.to(device)\n","      labels = labels.to(device)\n","\n","      # Zero the parameter gradients\n","      optimizer.zero_grad()\n","\n","      # Passing the data to the model (Forward Pass)\n","      outputs = model(images)\n","\n","      # Calculating the loss\n","      loss = criterion(outputs, labels)\n","      train_loss += loss.item()\n","\n","      # Performing backward pass (Backpropagation)\n","      loss.backward()\n","\n","      # optimizer.step() updates the weights accordingly\n","      optimizer.step()\n","\n","      # Accuracy calculation\n","      _, predicted = torch.max(outputs, 1)\n","      correct += (predicted == labels).sum().item()\n","    val_loss = 0\n","    val_correct = 0\n","    with torch.no_grad():\n","        # Loop through all of the validation set\n","        for images, labels in val_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            val_output = model(images)                                                                  \n","            val_loss += criterion(val_output, labels)             \n","            _, predicted = torch.max(val_output, 1)\n","            val_correct += (predicted == labels).sum()\n","\n","    train_losses.append(train_loss/len(train_set))\n","    val_losses.append(val_loss/len(val_set))\n","    train_accuracy.append(100 * correct/len(train_set))\n","    val_accuracy.append(100 * val_correct/len(val_set))\n","    print('epoch: {}, Train Loss:{:.6f} Validation Loss {:.6f} Train Accuracy: {:.2f}, Validation accuracy {:.2f} '.format(e+1,train_losses[-1], val_losses[-1], train_accuracy[-1], val_accuracy[-1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch: 1, Train Loss:0.252522 Validation Loss 0.120910 Train Accuracy: 50.41, Validation accuracy 54.25 \n","epoch: 2, Train Loss:0.093768 Validation Loss 0.091118 Train Accuracy: 54.92, Validation accuracy 46.41 \n","epoch: 3, Train Loss:0.046150 Validation Loss 0.027701 Train Accuracy: 52.05, Validation accuracy 56.21 \n","epoch: 4, Train Loss:0.021717 Validation Loss 0.023406 Train Accuracy: 52.46, Validation accuracy 45.75 \n","epoch: 5, Train Loss:0.021533 Validation Loss 0.029145 Train Accuracy: 60.25, Validation accuracy 60.78 \n","epoch: 6, Train Loss:0.017809 Validation Loss 0.023586 Train Accuracy: 61.07, Validation accuracy 48.37 \n","epoch: 7, Train Loss:0.011787 Validation Loss 0.020425 Train Accuracy: 66.80, Validation accuracy 60.13 \n","epoch: 8, Train Loss:0.014191 Validation Loss 0.009755 Train Accuracy: 66.39, Validation accuracy 59.48 \n","epoch: 9, Train Loss:0.009708 Validation Loss 0.009798 Train Accuracy: 54.51, Validation accuracy 58.82 \n","epoch: 10, Train Loss:0.006897 Validation Loss 0.011768 Train Accuracy: 71.31, Validation accuracy 56.21 \n","epoch: 11, Train Loss:0.006320 Validation Loss 0.012661 Train Accuracy: 74.18, Validation accuracy 54.90 \n","epoch: 12, Train Loss:0.005381 Validation Loss 0.010991 Train Accuracy: 77.05, Validation accuracy 58.82 \n","epoch: 13, Train Loss:0.005491 Validation Loss 0.011378 Train Accuracy: 77.05, Validation accuracy 54.90 \n","epoch: 14, Train Loss:0.005301 Validation Loss 0.012199 Train Accuracy: 80.33, Validation accuracy 56.86 \n","epoch: 15, Train Loss:0.005021 Validation Loss 0.012950 Train Accuracy: 77.87, Validation accuracy 50.98 \n","epoch: 16, Train Loss:0.004140 Validation Loss 0.013717 Train Accuracy: 81.15, Validation accuracy 50.33 \n","epoch: 17, Train Loss:0.003417 Validation Loss 0.014759 Train Accuracy: 86.07, Validation accuracy 50.98 \n","epoch: 18, Train Loss:0.002736 Validation Loss 0.016087 Train Accuracy: 88.52, Validation accuracy 53.59 \n","epoch: 19, Train Loss:0.002197 Validation Loss 0.016877 Train Accuracy: 93.85, Validation accuracy 53.59 \n","epoch: 20, Train Loss:0.001578 Validation Loss 0.017374 Train Accuracy: 95.90, Validation accuracy 50.33 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R1338yNobnnZ"},"source":["### Data Augmentation\n","\n","\n","\n","Diversity of data and a larger dataset is the easiest way to avoid overfitting of the model. Data augmentation allows you to increase the size of your dataset by performing processes like flipping, cropping, rotation, scaling and translation on the existing images. Data augmentation not only increases the dataset size but also exposes the model to different angles and lighting and reduces the bias in the dataset, thus avoiding chances of overfitting. \n","\n","Added two more transformations to the original data.\n","\n","\n","*   Applied random rotation of $45^o$ using **`transforms.RandomRotation`**\n","*   Applied vertical flip to the images using **`transforms.RandomVerticalFlip()`**\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"n7hR9B_pbm2g"},"source":["image_size = (128,128)\n","transformations = transforms.Compose([\n","                                transforms.Resize(image_size), \n","                                transforms.Grayscale(),\n","                                transforms.RandomRotation(45),\n","                                transforms.RandomVerticalFlip(),\n","                                transforms.ToTensor(), \n","                                transforms.Normalize((0.5,), (0.5,)),\n","\n","                                ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HdQKsm-bm2i"},"source":["batch_size = 100 \n","train_set = datasets.ImageFolder('/content/hymenoptera_data/train', transform = transformations)\n","trainloader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True, num_workers=8)\n","\n","val_set = datasets.ImageFolder('/content/hymenoptera_data/val',transform=transformations)\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size=100, shuffle=True, num_workers=8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tHgEW9-RmdL1"},"source":["#### Regularization\n","\n","**Regularization** techniques prevent the model from overfitting by modifying the cost function. \n","\n","**Dropout**, on the other hand, prevents overfitting by modifying the network itself. Every neuron apart from the ones in the output layer is assigned a probability p of being temporarily ignored from calculations. p is also called dropout rate and is initialized to 0.2. Then, as each iteration progresses, the neurons in each layer with the highest probability get dropped. This results in creating a smaller network with each epoch. Since in each iteration, a random input value can be eliminated, the network tries to balance the risk and not to favour any of the features and reduces bias and noise. "]},{"cell_type":"markdown","metadata":{"id":"0ZAiX592ZeoG"},"source":["### Optimize the Architecture"]},{"cell_type":"code","metadata":{"id":"Et6X_fnFGR3t"},"source":["class Optimized_Model(nn.Module):\n","    def __init__(self):\n","        super(Optimized_Model, self).__init__()\n","\n","        self.linear1 = nn.Linear(16384,4096)\n","        self.linear2 = nn.Linear(4096,1024)\n","        self.linear3 = nn.Linear(1024,256)\n","        self.linear4 = nn.Linear(256,10)\n","        self.linear5 = nn.Linear(10,2)\n","        self.dropout = nn.Dropout(0.2)\n","    def forward(self, x):\n","        out = x.view(x.shape[0],-1)\n","        out = self.linear1(out)\n","\n","        out = self.linear2(out)\n","        out = self.linear3(out)\n","        out = self.linear4(out)\n","        out = self.dropout(self.linear5(out))\n","        \n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Au6wjEGWZADQ"},"source":["#### Initialize the optimized model"]},{"cell_type":"code","metadata":{"id":"kRMMDeiFWlOY"},"source":["# Instantiate the model\n","device = torch.device(\"cuda\")\n","model2 = Optimized_Model().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model2.parameters(), lr = 0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xEmKN7nRvDwm"},"source":["### Training the optimized model\n","\n","In Training Phase, we iterate over a batch of images in the train_loader. For each batch, we perform  the following steps:\n","\n","* First we zero out the gradients using zero_grad()\n","\n","* We pass the data to the model i.e. we perform forward pass by calling the forward()\n","\n","* We calculate the loss using the actual and predicted labels\n","\n","* Perform Backward pass using backward() to update the weights"]},{"cell_type":"code","metadata":{"id":"gt_oZCN3P8rd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607248623161,"user_tz":300,"elapsed":64098,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"1a571b2c-0f48-41a0-bde0-263a920c4694"},"source":["# No of Epochs\n","epoch = 20\n","\n","model2.train()\n","train_losses_opt,  train_accuracy_opt = [], []\n","val_losses_opt , val_accuracy_opt = [], []\n","    \n","for e in range(epoch):\n","    otrain_loss = 0\n","    ocorrect = 0\n","    # Iterate through all the batches in each epoch\n","    for images, labels in trainloader:\n","      \n","      # Convert the image and label to gpu for faster execution\n","      images = images.to(device)\n","      labels = labels.to(device)\n","      \n","      # Zero the parameter gradients\n","      optimizer.zero_grad()\n","      \n","      # Passing the data to the model (Forward Pass)\n","      outputs = model2(images)\n","      \n","      # Calculating the loss\n","      loss = criterion(outputs, labels)\n","      otrain_loss += loss.item()\n","\n","      \n","      # Performing backward pass (Backpropagation)\n","      loss.backward()\n","\n","      # optimizer.step() updates the weights accordingly\n","      optimizer.step()\n","\n","      # Accuracy calculation\n","      _, predicted = torch.max(outputs, 1)\n","      ocorrect += (predicted == labels).sum().item()\n","    oval_loss = 0\n","    oval_correct = 0\n","    with torch.no_grad():\n","        # Loop through all of the validation set\n","        for images, labels in val_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            val_output = model2(images)                                                                  \n","            oval_loss += criterion(val_output, labels)             \n","            _, predicted = torch.max(val_output, 1)\n","            oval_correct += (predicted == labels).sum()\n","\n","    train_losses_opt.append(otrain_loss/len(train_set))\n","    val_losses_opt.append(oval_loss/len(val_set))\n","    train_accuracy_opt.append(100 * ocorrect/len(train_set))\n","    val_accuracy_opt.append(100 * oval_correct/len(val_set))\n","    print('epoch: {}, Train Loss:{:.6f} Test Loss {:.6f} Train Accuracy: {:.2f}, Test accuracy {:.2f} '.format(e+1,train_losses_opt[-1], val_losses_opt[-1], train_accuracy_opt[-1], val_accuracy_opt[-1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch: 1, Train Loss:0.254423 Test Loss 0.028410 Train Accuracy: 53.69, Test accuracy 54.90 \n","epoch: 2, Train Loss:0.145764 Test Loss 0.163024 Train Accuracy: 52.05, Test accuracy 46.41 \n","epoch: 3, Train Loss:0.077703 Test Loss 0.032718 Train Accuracy: 49.59, Test accuracy 56.21 \n","epoch: 4, Train Loss:0.049014 Test Loss 0.042877 Train Accuracy: 44.26, Test accuracy 49.67 \n","epoch: 5, Train Loss:0.039262 Test Loss 0.023163 Train Accuracy: 56.97, Test accuracy 56.21 \n","epoch: 6, Train Loss:0.033259 Test Loss 0.012808 Train Accuracy: 49.18, Test accuracy 58.82 \n","epoch: 7, Train Loss:0.019410 Test Loss 0.022751 Train Accuracy: 56.97, Test accuracy 54.90 \n","epoch: 8, Train Loss:0.018206 Test Loss 0.013044 Train Accuracy: 53.28, Test accuracy 56.21 \n","epoch: 9, Train Loss:0.015116 Test Loss 0.023787 Train Accuracy: 47.54, Test accuracy 45.10 \n","epoch: 10, Train Loss:0.017699 Test Loss 0.012927 Train Accuracy: 48.77, Test accuracy 54.25 \n","epoch: 11, Train Loss:0.012029 Test Loss 0.015034 Train Accuracy: 56.56, Test accuracy 49.02 \n","epoch: 12, Train Loss:0.014200 Test Loss 0.009944 Train Accuracy: 47.13, Test accuracy 56.86 \n","epoch: 13, Train Loss:0.009575 Test Loss 0.009429 Train Accuracy: 52.87, Test accuracy 58.17 \n","epoch: 14, Train Loss:0.009562 Test Loss 0.011274 Train Accuracy: 57.38, Test accuracy 58.17 \n","epoch: 15, Train Loss:0.010285 Test Loss 0.010118 Train Accuracy: 59.43, Test accuracy 56.86 \n","epoch: 16, Train Loss:0.008864 Test Loss 0.010692 Train Accuracy: 57.38, Test accuracy 54.25 \n","epoch: 17, Train Loss:0.009707 Test Loss 0.014160 Train Accuracy: 56.15, Test accuracy 52.29 \n","epoch: 18, Train Loss:0.012057 Test Loss 0.012921 Train Accuracy: 56.56, Test accuracy 47.06 \n","epoch: 19, Train Loss:0.011029 Test Loss 0.012523 Train Accuracy: 58.61, Test accuracy 58.17 \n","epoch: 20, Train Loss:0.011093 Test Loss 0.011449 Train Accuracy: 56.97, Test accuracy 47.06 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"goqw4VOf3u4h"},"source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"DIzeiEtRh5nZ"},"source":["#@title State True or False: Using dropout, a random neuron in the layer gets deactivated { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer= \"TRUE\" #@param [\"\",\"TRUE\",\"FALSE\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMzKSbLIgFzQ"},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Good, But Not Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjcH1VWSFI2l"},"source":["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"non\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VBk_4VTAxCM"},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r35isHfTVGKc"},"source":["#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Walkthrough = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH91cL1JWH7m"},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8xLqj7VWIKW"},"source":["#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzAZHt1zw-Y-","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607250532721,"user_tz":300,"elapsed":1305,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"652bb463-5487-4c7f-fedc-e70539d26337"},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id = return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Your submission is successful.\n","Ref Id: 10890\n","Date of submission:  06 Dec 2020\n","Time of submission:  15:57:34\n","View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\n"],"name":"stdout"}]}]}