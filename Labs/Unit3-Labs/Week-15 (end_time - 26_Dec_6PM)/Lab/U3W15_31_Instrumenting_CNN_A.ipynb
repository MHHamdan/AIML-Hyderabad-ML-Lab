{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"U3W15_31_Instrumenting_CNN_A.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"l-lz7-0HC24p"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"vmx1zlGdWoUw"},"source":["## Learning Objectives\n","\n"]},{"cell_type":"markdown","metadata":{"id":"enYFutAiiWED"},"source":["At the end of the experiment, you will be able to:\n","\n","* classify the MNIST data using CNN\n","* understand the importance of Gradient descent algorithm"]},{"cell_type":"code","metadata":{"id":"9OerY5NgyXqn","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":322},"executionInfo":{"status":"ok","timestamp":1608712141148,"user_tz":300,"elapsed":623,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"c4993fbe-e3f9-48b4-a128-1e0d116e9346"},"source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"800\" height=\"300\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/aiml_batch_15/preview_videos/Instrumenting_CNN.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/html":["<video width=\"800\" height=\"300\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/aiml_batch_15/preview_videos/Instrumenting_CNN.mp4\" type=\"video/mp4\">\n","</video>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"2hCJasxI__be"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"zzWueA91AA7q"},"source":["### Description\n","\n","\n","1. The dataset contains 60,000 Handwritten digits as training samples and 10,000 Test samples, \n","which means each digit occurs 6000 times in the training set and 1000 times in the testing set. \n","2. Each image is Size Normalized and Centered \n","3. Each image is 28 X 28 Pixel with 0-255 Gray Scale Value. \n","4. That means each image is represented as 784 (28 X28) dimension vector where each value is in the range 0- 255."]},{"cell_type":"markdown","metadata":{"id":"k5Eb8UcIE4r2"},"source":["### History\n","\n","Yann LeCun (Director of AI Research, Facebook, Courant Institute, NYU) was given the task of identifying the cheque numbers (in the 90’s) and the amount associated with that cheque without manual intervention. That is when this dataset was created which raised the bars and became a benchmark.\n","\n","Yann LeCun and Corinna Cortes (Google Labs, New York) hold the copyright of MNIST dataset, which is a subset of the original NIST datasets. This dataset is made available under the terms of the Creative Commons Attribution-Share Alike 3.0 license. \n","\n","It is the handwritten digits dataset in which half of them are written by the Census Bureau employees and remaining by the high school students. The digits collected among the Census Bureau employees are easier and cleaner to recognize than the digits collected among the students.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AqAHNnh3E7C0"},"source":["### Challenges\n","\n","Now, if you notice the images below, you will find that between 2 characters there are always certain similarities and differences. To teach a machine to recognize these patterns and identify the correct output.\n","\n","![altxt](https://www.researchgate.net/profile/Radu_Tudor_Ionescu/publication/282924675/figure/fig3/AS:319968869666820@1453297931093/A-random-sample-of-6-handwritten-digits-from-the-MNIST-data-set-before-and-after.png)\n","\n","Hence, all these challenges make this a good problem to solve in Machine Learning."]},{"cell_type":"markdown","metadata":{"id":"A9O2_IcPiNYV"},"source":["## Domain Information"]},{"cell_type":"markdown","metadata":{"id":"_X-e2l14iXvo"},"source":["\n","\n","\n","Handwriting changes person to person. Some of us have neat handwriting and some have illegible handwriting such as doctors. However, if you think about it even a child who recognizes alphabets and numerics can identify the characters of a text even written by a stranger. But even a technically knowledgeable adult cannot describe the process by which he or she recognizes the text/letters. As you know this is an excellent challenge for Machine Learning.\n","\n","![altxt](https://i.pinimg.com/originals/f2/7a/ac/f27aac4542c0090872110836d65f4c99.jpg)\n"]},{"cell_type":"markdown","metadata":{"id":"Bwhk9hAX_Weh"},"source":["## AI/ML Technique"]},{"cell_type":"markdown","metadata":{"id":"7xMc9ipI_ZZ-"},"source":["A neural network is a system of interconnected artificial “neurons” that\n","exchange messages between each other. The connections have numeric weights\n","that are tuned during the training process, so that a properly trained network will\n","respond correctly when presented with an image or pattern to recognize. A\n","network consists of multiple layers of feature-detecting “neurons”. Each layer\n","has many neurons that respond to different combinations of inputs from the\n","previous layers"]},{"cell_type":"markdown","metadata":{"id":"dM8vmjipJral"},"source":["### CNN (Convolutional Neural Network)\n","\n","CNN is also referred to as ConvNets. They are part of neural networks that have proven effective in areas as image classification and recognition.\n","\n","While building or training the CNN network we follow  below steps :\n","\n","1. We start with an input image.\n","2. Then we try to apply filters or feature maps to the image, which gives us a convolutional layer.\n","\n","3. Then we break up the linearity of that image using the rectifier function. The image becomes ready for the pooling step.\n","4. Once we're done with the pooling layer, we end up with a pooled feature map.\n","5. Finally, we try to flatten our pooled feature map before inserting it into an artificial neural network.\n","\n","By following the above steps recurrently, we get the network's building blocks, like the weights and the feature maps, are trained and repeatedly altered in order for the network to reach the optimal performance. This will make the network to classify images and objects as accurately as possible.\n","\n","![alt text](https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/16.png)\n","\n","\n","While working on the experiment you will be able to understand different layers involved in CNN's architecture and their importance."]},{"cell_type":"markdown","metadata":{"id":"btdbDNPstOyG"},"source":["In this experiment, we build a neural network consisting of convolutional, pooling and fully connected layers to classify handwritten digits of the MNIST dataset."]},{"cell_type":"markdown","metadata":{"id":"DlEtqiEzC24u"},"source":["As we learned during the lecture sessions, CNN programming involves the following steps:\n","\n","1. Load the data\n","2. Specify a Neural Network Model \n","3. Specify the loss function and Gradient Update Algorithm\n","4. Training the loop \n","5. Compute the accuracy on the testing dataset\n"]},{"cell_type":"markdown","metadata":{"id":"zEPfO7gbDATX"},"source":["## Setup Steps"]},{"cell_type":"code","metadata":{"id":"vdTGBB-iDEJi","executionInfo":{"status":"ok","timestamp":1608712141438,"user_tz":300,"elapsed":897,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n","Id=\"2100121\"#@param{type:\"string\"}"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"7tlCjgEKDHVV","executionInfo":{"status":"ok","timestamp":1608712141438,"user_tz":300,"elapsed":891,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password=\"5142192291\"#@param{type:\"string\"}"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"WBPPuGmBlDIN","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1608712146325,"user_tz":300,"elapsed":5772,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"aea36894-ce3b-43a8-d6f0-59870217d7a3"},"source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","\n","ipython = get_ipython()\n","  \n","notebook=\"U3W15_31_Instrumenting_CNN_A\" #name of the notebook\n","\n","def setup():\n","    ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx pip3 install torchvision\")\n","    print (\"Setup completed successfully\")\n","    from IPython.display import HTML, display\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    return\n","\n","def submit_notebook():\n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","    \n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n","              \"feedback_experiments_input\" : Comments,\n","              \"feedback_mentor_support\": Mentor_support}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:        \n","        print(r[\"err\"])\n","        return None   \n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\")\n","        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","        return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if not Additional: \n","      raise NameError\n","    else:\n","      return Additional  \n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","  \n","  \n","def getWalkthrough():\n","  try:\n","    if not Walkthrough:\n","      raise NameError\n","    else:\n","      return Walkthrough\n","  except NameError:\n","    print (\"Please answer Walkthrough Question\")\n","    return None\n","  \n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","  \n","\n","def getMentorSupport():\n","  try:\n","    if not Mentor_support:\n","      raise NameError\n","    else:\n","      return Mentor_support\n","  except NameError:\n","    print (\"Please answer Mentor support Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    if not Answer:\n","      raise NameError \n","    else: \n","      return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","  \n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup() \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2100121&recordId=12317\"></script>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Bikcf-BRC24z"},"source":["### Importing required packages"]},{"cell_type":"code","metadata":{"id":"3GuIxHsqC240","executionInfo":{"status":"ok","timestamp":1608712146326,"user_tz":300,"elapsed":5767,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["# Importing Pytorch library\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","# Matplotllib is used for ploting graphs\n","import matplotlib.pyplot as plt"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"U02Zy4m7CGbg","executionInfo":{"status":"ok","timestamp":1608712146327,"user_tz":300,"elapsed":5764,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EUarXxbEC246"},"source":["### Loading the data\n"]},{"cell_type":"markdown","metadata":{"id":"s0wMGecqu5Ic"},"source":["The database contains 60,000 training images and 10,000 testing images each of size 28x28. Loading the dataset can be easily done through the torch.utils package. The dataset is downloaded automatically when you run the below cell for the first time."]},{"cell_type":"code","metadata":{"id":"CWvuH-yKDv_1","executionInfo":{"status":"ok","timestamp":1608712146327,"user_tz":300,"elapsed":5760,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["# Normalize with mean and std ( 0.1307 and 0.3081 are the mean and std of MNIST data )\n","transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"ENEeWQzZD0x2","executionInfo":{"status":"ok","timestamp":1608712146328,"user_tz":300,"elapsed":5756,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["# Loading the train set file\n","mnist_train = datasets.MNIST(root='../data', \n","                            train=True, \n","                            transform=transform,  \n","                            download=True)"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssNtVBHvFOgL","executionInfo":{"status":"ok","timestamp":1608712146328,"user_tz":300,"elapsed":5750,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["# Loading the test set file\n","mnist_test = datasets.MNIST(root='../data', \n","                           train=False, \n","                           transform=transform)"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bmxkoOr_v6oh"},"source":[" Let’s visualize a few data from the training set to get a better idea about the purpose of using the deep learning model."]},{"cell_type":"code","metadata":{"id":"ywedmu7Rv0dJ","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"ok","timestamp":1608712146329,"user_tz":300,"elapsed":5745,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"8938330d-822c-483b-f0eb-fde64c0cf84a"},"source":["# Plotting one example\n","print(\"Shape of the training data (no of images, height, width) : \", mnist_train.train_data.size()) # (60000, 28, 28)\n","print(\"Shape of the testing data (no of images, height, width) : \", mnist_test.test_data.size())  # (10000, 28, 28)\n","\n","# YOUR CODE HERE : Plot one image from the training set as a gray scale image.\n","print(\"\\n\")\n","print(\"#### An Example Image, Label pair #####\")\n","plt.imshow(mnist_train.train_data[0].numpy(), cmap='gray')\n","plt.title('Label : %i' % mnist_train.train_labels[0])\n","plt.show()"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Shape of the training data (no of images, height, width) :  torch.Size([60000, 28, 28])\n","Shape of the testing data (no of images, height, width) :  torch.Size([10000, 28, 28])\n","\n","\n","#### An Example Image, Label pair #####\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"Z2--teHtC25E"},"source":["#### Minibatch\n","The Machine learning dataset can be really large. Hence we cannot often load the entire data into the memory. Hence neural network training is done by loading small batches (commonly called minibatch) of data and using it to update the learnable parameters (weights and biases) of the model."]},{"cell_type":"code","metadata":{"id":"4NDlkt8UGQGX","executionInfo":{"status":"ok","timestamp":1608712146330,"user_tz":300,"elapsed":5740,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["# The mini batch size used for training\n","batch_size = 1000 \n","\n","# Loading the train dataset\n","# Data Loader loads the images and corresponding labels of defined mini batch size.\n","# the image batch shape will be (batch_size, 1, 28, 28)\n","train_loader = torch.utils.data.DataLoader(dataset=mnist_train, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","# Loading the test dataset\n","# Data loader will behave like an iterator, so we can loop over it and fetch a different mini-batch every time.\n","test_loader = torch.utils.data.DataLoader(dataset=mnist_test, \n","                                          batch_size=batch_size, \n","                                          shuffle=True)"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"06iKhdT5H9tI"},"source":["Let’s visualize a few images in the mini batch of training set"]},{"cell_type":"code","metadata":{"id":"PfXCm8nTC25F","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1608712147095,"user_tz":300,"elapsed":6500,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"0384ebe0-de1a-4f68-802a-8aae9612c3e6"},"source":["batch_count = 0\n","for mini_batch in train_loader:\n","    images, labels = mini_batch    \n","    print('Mini batch size: images -', images.size(), ' labels - ', labels.size())\n","    for j in range(5):  # Basically iterating a few times (hence range(5)) to print a few images in this mini-batch\n","        print(images[j].size(), labels[j])\n","        # YOUR CODE HERE : Print few images from the mini-batch. Note: You might need to convert tensor to numpy to plot it.\n","        plt.imshow(images[j][0].numpy(), cmap='gray')\n","        plt.title('Label : %i' % labels[j])\n","        plt.show()\n","\n","        # Some logic to break out of the loop at range  = 1.\n","        if j == 1:\n","            break\n","    # If you want to visualize images in the next mini-batches you can increase the Batch count value.\n","    if batch_count == 1:\n","        break\n","\n","    batch_count +=1"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Mini batch size: images - torch.Size([1000, 1, 28, 28])  labels -  torch.Size([1000])\n","torch.Size([1, 28, 28]) tensor(9)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPVUlEQVR4nO3df+xV9X3H8eerFFOxTKRORlBrp2YEmkgdkZphdXZ2lthgNTM1rcPM7dtgdatxc+pcJMvMtK5lLjN1NFrRdbpm6vxmkk6HU9aYtSChimjRKV+QIKhU+apoK773xz10X+B7z/1yz733XHi/HsnN937P+/x4c8Pre86955z7UURgZge/D9XdgJn1hsNuloTDbpaEw26WhMNuloTDbpaEw56QpMck/WGvl7V6OewHMEkbJP1O3X2MlaRJkpZK2lY8FtXdUyYfrrsBS2UxMAE4DjgKWC5pKCK+W2tXSXjPfhCSdISkf5f0qqSfFc+P3mu24yX9WNIOSQ9Kmjxi+U9LekLSG5J+IumMDrX2BeAbEfFORGwAbgf+oEPrthYc9oPTh4DvAh8HjgV2Av+w1zy/TyNoU4H3gb8HkDQNeAj4a2Ay8KfAfZJ+tdVGJc2V9Ear2fZ6/slW67XOcNgPQhHxekTcV+xBh4EbgNP3mu3uiFgbEW8DfwlcIGkc8BVgWUQsi4gPIuIRYBUwbwzb/WFETCqZ5QfA1ZImSjqBxh+bCW38E60NDvtBSNIESf8oaUjSDmAFMKkI826bRjwfAsYDR9I4Gvi94hD+jWJPPZfGEUBVf0zjKON54EHgHuDlDqzXxsBhPzhdCfwGMCcifgX4TDF95CH0MSOeHwv8AniNxh+BuyNi0ojHYRFxY9WmImJ7RHw5In4tImbS+P/346rrtbFx2A984yV9ZMTjw8BEGnvQN4oP3q4fZbmvSJohaQLwV8C/RsQu4J+AL0j6XUnjinWeMcoHfPtN0vGSPlas9/PAAI3PBqwHHPYD3zIawd79WAT8HXAojT31/9B4r7y3u4E7gVeAj9A4xCYiNgHzgWuBV2ns6f+MMfxfkXSapLdKZvlN4GlgGPgb4MsR8Uyr9VpnyF9eYZaD9+xmSTjsZkk47GZJOOxmSfT0RhhJ/jTQrMsiQqNNr7Rnl3S2pJ9KekHS1VXWZWbd1fapt+LSy/XAWTQueVwJXBgR60qW8Z7drMu6sWc/BXghIl6MiJ8D99K4GMPM+lCVsE9jz5spXi6m7UHSgKRVklZV2JaZVdT1D+giYgmwBHwYb1anKnv2zex559TRxTQz60NVwr4SOFHSJyQdAnwJGOxMW2bWaW0fxkfE+5IuA/4DGAfc4TuYzPpXT+9683t2s+7rykU1ZnbgcNjNknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZJoe3x2AEkbgGFgF/B+RMzuRFNm1nmVwl747Yh4rQPrMbMu8mG8WRJVwx7Aw5KelDQw2gySBiStkrSq4rbMrAJFRPsLS9MiYrOko4BHgMsjYkXJ/O1vzMzGJCI02vRKe/aI2Fz83AY8AJxSZX1m1j1th13SYZIm7n4OfA5Y26nGzKyzqnwaPwV4QNLu9fxzRPygI13Zfrn44oub1i666KLSZc8888zS+rp160rrV111VWn9oYceKq1b77Qd9oh4ETipg72YWRf51JtZEg67WRIOu1kSDrtZEg67WRKVrqDb7435Crq2LFy4sLS+ePHiprVDDjmk0+3s4e233y6tT58+vWlt8+bNnW7H6NIVdGZ24HDYzZJw2M2ScNjNknDYzZJw2M2ScNjNkvB59j5wySWXlNZvu+220vq4ceOa1jZu3Fi67IoVTb9YCCg/Tw4we3b5FwqvXLmyaW3evHmly77++uuldRudz7ObJeewmyXhsJsl4bCbJeGwmyXhsJsl4bCbJeHz7D3Q6p7yxx9/vLQ+Z86c0vrg4GDT2vnnn1+67K5du0rrkyZNKq1v3769tF7miiuuKK3fcsstba87M59nN0vOYTdLwmE3S8JhN0vCYTdLwmE3S8JhN0uiypDNNkatzlXPmjWrtH7//feX1su+V77VefRWhoeHS+s33HBDaf2aa65pWjvppPJBgA899NDS+s6dO0vrtqeWe3ZJd0jaJmntiGmTJT0i6fni5xHdbdPMqhrLYfydwNl7TbsaWB4RJwLLi9/NrI+1DHtErAD2viZyPrC0eL4UOLfDfZlZh7X7nn1KRGwpnr8CTGk2o6QBYKDN7ZhZh1T+gC4iouwGl4hYAiyBvDfCmPWDdk+9bZU0FaD4ua1zLZlZN7Qb9kFgQfF8AfBgZ9oxs25peT+7pHuAM4Ajga3A9cC/Ad8HjgWGgAsiouWNzVkP4ydPnlxaf+6550rrL730Umm91f3u3TRt2rTS+rp165rWJk6cWLps2Tl6gJtuuqm0nlWz+9lbvmePiAublD5bqSMz6ylfLmuWhMNuloTDbpaEw26WhMNuloRvce2Bd999t7S+devWHnXSeZdeemlpvdXptTKthpu2/eM9u1kSDrtZEg67WRIOu1kSDrtZEg67WRIOu1kSPs/eA++8805pfdOmTaX1008/vbR+8sknN62tXr26dNlWjjrqqNL6Oeec0/a6W11/sGzZsrbXbfvynt0sCYfdLAmH3SwJh90sCYfdLAmH3SwJh90sCZ9n7wNDQ0Ol9VZDFz/xxBNNaw8//HBbPe122mmnldYPP/zwttfd6iuy33zzzbbXbfvynt0sCYfdLAmH3SwJh90sCYfdLAmH3SwJh90sCZ9n7wOLFy8urc+dO7e0PnPmzKa1Kvebd9ujjz5adwuptNyzS7pD0jZJa0dMWyRps6Q1xWNed9s0s6rGchh/J3D2KNMXR8Ss4uGvFDHrcy3DHhErgO096MXMuqjKB3SXSXqqOMw/otlMkgYkrZK0qsK2zKyidsP+beB4YBawBfhmsxkjYklEzI6I2W1uy8w6oK2wR8TWiNgVER8A3wFO6WxbZtZpbYVd0tQRv34RWNtsXjPrDy3Ps0u6BzgDOFLSy8D1wBmSZgEBbAC+2sUeD3rr168vrc+ZM6e0ft111zWtLVy4sK2edhscHCytn3rqqaX1E044odL2rXNahj0iLhxl8u1d6MXMusiXy5ol4bCbJeGwmyXhsJsl4bCbJaGI6N3GpN5tzDpi/PjxpfXHHnustF52au7WW28tXfbyyy8vrdvoIkKjTfee3SwJh90sCYfdLAmH3SwJh90sCYfdLAmH3SwJf5W0lZowYUJpvdUtrmXuvffetpe1/ec9u1kSDrtZEg67WRIOu1kSDrtZEg67WRIOu1kSPs9upaZPn961db/33ntdW7fty3t2syQcdrMkHHazJBx2syQcdrMkHHazJBx2syTGMmTzMcBdwBQaQzQviYhbJE0G/gU4jsawzRdExM+616rV4bzzzqu0/PDwcNPajh07Kq3b9s9Y9uzvA1dGxAzg08DXJM0ArgaWR8SJwPLidzPrUy3DHhFbImJ18XwYeBaYBswHlhazLQXO7VaTZlbdfr1nl3Qc8CngR8CUiNhSlF6hcZhvZn1qzNfGS/oocB/w9YjYIf3/cFIREc3GcZM0AAxUbdTMqhnTnl3SeBpB/15E3F9M3ippalGfCmwbbdmIWBIRsyNidicaNrP2tAy7Grvw24FnI+JbI0qDwILi+QLgwc63Z2adMpbD+N8CLgKelrSmmHYtcCPwfUmXAEPABd1p0ep01llnVVr+5ptvblpbv359pXXb/mkZ9oj4ITDqeM/AZzvbjpl1i6+gM0vCYTdLwmE3S8JhN0vCYTdLwmE3S8JfJW1dtXPnzrpbsIL37GZJOOxmSTjsZkk47GZJOOxmSTjsZkk47GZJOOxmSTjsZkk47GZJOOxmSTjsZkk47GZJOOxmSTjsZkn4fvbkZs6cWVqfMWNGpfWvXr260vLWOd6zmyXhsJsl4bCbJeGwmyXhsJsl4bCbJeGwmyXR8jy7pGOAu4ApQABLIuIWSYuAPwJeLWa9NiKWdatR646hoaHS+saNGyvVV65cud89WXeM5aKa94ErI2K1pInAk5IeKWqLI+Jvu9eemXVKy7BHxBZgS/F8WNKzwLRuN2ZmnbVf79klHQd8CvhRMekySU9JukPSEU2WGZC0StKqSp2aWSVjDrukjwL3AV+PiB3At4HjgVk09vzfHG25iFgSEbMjYnYH+jWzNo0p7JLG0wj69yLifoCI2BoRuyLiA+A7wCnda9PMqmoZdkkCbgeejYhvjZg+dcRsXwTWdr49M+sURUT5DNJc4L+Bp4EPisnXAhfSOIQPYAPw1eLDvLJ1lW/MzCqLCI02vWXYO8lhN+u+ZmH3FXRmSTjsZkk47GZJOOxmSTjsZkk47GZJOOxmSTjsZkk47GZJOOxmSTjsZkk47GZJOOxmSTjsZkn0esjm14CR3118ZDGtH/Vrb/3aF7i3dnWyt483K/T0fvZ9Ni6t6tfvpuvX3vq1L3Bv7epVbz6MN0vCYTdLou6wL6l5+2X6tbd+7QvcW7t60lut79nNrHfq3rObWY847GZJ1BJ2SWdL+qmkFyRdXUcPzUjaIOlpSWvqHp+uGENvm6S1I6ZNlvSIpOeLn6OOsVdTb4skbS5euzWS5tXU2zGS/kvSOknPSPqTYnqtr11JXz153Xr+nl3SOGA9cBbwMrASuDAi1vW0kSYkbQBmR0TtF2BI+gzwFnBXRHyymPYNYHtE3Fj8oTwiIv68T3pbBLxV9zDexWhFU0cOMw6cC1xMja9dSV8X0IPXrY49+ynACxHxYkT8HLgXmF9DH30vIlYA2/eaPB9YWjxfSuM/S8816a0vRMSWiFhdPB8Gdg8zXutrV9JXT9QR9mnAphG/v0x/jfcewMOSnpQ0UHczo5gyYpitV4ApdTYzipbDePfSXsOM981r187w51X5A7p9zY2Ik4HPA18rDlf7UjTeg/XTudMxDePdK6MMM/5Ldb527Q5/XlUdYd8MHDPi96OLaX0hIjYXP7cBD9B/Q1Fv3T2CbvFzW839/FI/DeM92jDj9MFrV+fw53WEfSVwoqRPSDoE+BIwWEMf+5B0WPHBCZIOAz5H/w1FPQgsKJ4vAB6ssZc99Msw3s2GGafm16724c8joucPYB6NT+T/F/iLOnpo0tevAz8pHs/U3RtwD43Dul/Q+GzjEuBjwHLgeeA/gcl91NvdNIb2fopGsKbW1NtcGofoTwFrise8ul+7kr568rr5clmzJPwBnVkSDrtZEg67WRIOu1kSDrtZEg67WRIOu1kS/weFOcqUQLw2bgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["torch.Size([1, 28, 28]) tensor(0)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Mini batch size: images - torch.Size([1000, 1, 28, 28])  labels -  torch.Size([1000])\n","torch.Size([1, 28, 28]) tensor(8)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["torch.Size([1, 28, 28]) tensor(5)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"e8aYrO1awfiV"},"source":["### Defining a CNN based Neural Network"]},{"cell_type":"markdown","metadata":{"id":"cC1rDpB5wj58"},"source":["Now we will define a CNN based neural network, that takes the input as 28x28 MNIST images and predicts a label from 0 to 9. The predictions will be of the form of a probability distribution given as an array $P$ of length 10, where each entry $P_i$  denotes the probability of the input image being the digit $i$.\n","\n","\n","We will divide the neural network into two parts. First is the feature extractor, which given the 28x28 images, gives a feature vector. The feature extractor is a CNN based neural network. Second is a classifier, which takes the feature vector as input and produces a 10 dimensional vector called the logits. Finally the logits are converted in the prediction probabilities by applying the softmax function"]},{"cell_type":"markdown","metadata":{"id":"epKavSwZwvFs"},"source":["The Deep CNN we will be using is called LeNet. A pictorial representation is given below: </br>\n","**NOTE: The diagram below assumes the image of size 32 \\* 32, however, MNIST is 28 \\* 28; So the diagram is not a representation of the problem dataset, but a LeNet architecture in general. It could however be treated as an interesting exercise for you to recompute each of the layers gives the slight change in the input dimension.**\n","\n","![alt text](https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/cnn.png)\n"]},{"cell_type":"markdown","metadata":{"id":"QIgeu0AqC25L"},"source":["\n","\n","\n","\n","As you can see, the neural network has multiple operations happening one after another. Each operation has learnable parameters (weights and biases). Typically we call them the layers of a neural network. Neural networks can have many layers, and are hence called Deep Neural Networks (DNNs) or Deep CNNs. \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nxyDKtLlw6Pq"},"source":["LeNet feature extractor shown above has the following layers:\n","\n","1. Convolutional layer which:\n","    1. takes an image with 1 channel (since MNIST digits are black and white; for color images, they are represented by 3 channels giving the intensities of Red, Blue and Green) : 1x28x28\n","    2. convolves with 6 filters (weights) of kernel size 5x5 and stride 1\n","    3. without padding\n","    4. so, gives a 6x24x24 tensor as output\n","2. Subsampling or MaxPooling (which reduces the height and width by half). Here we are doing 2x2-MaxPooling which takes the maximum value of every non-overlapping 2x2 window: outputs a 6x12x12 tensor\n","3. ReLU activation function applied to every entry of the tensor\n","4. Convolutional layer which:\n","    1. takes a tensor with 6 channels: 6x12x12\n","    2. convolves with 16 filters of kernel size 5x5 and stride 1\n","    3. so, gives a 16x8x8 tensor as output\n","4. MaxPooling: gives a 16x4x4 tensor as output\n","5. ReLU"]},{"cell_type":"markdown","metadata":{"id":"EMjkQOxyw0hz"},"source":["Note that the output of the below neural network is a 3D tensor. This is because the input is a 3D tensor (with one dimension =1) and Convolutional and Max-Pooling layers give 3D tensors as output. Next, we will reshape this 3D tensor into a long vector and pass it through the classifier network. The Classifier network is typically a Multi-Layered Perceptron Network that you have seen previously."]},{"cell_type":"code","metadata":{"id":"4KFQv7tOC25M","executionInfo":{"status":"ok","timestamp":1608712147096,"user_tz":300,"elapsed":6495,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["# A CNN based Feature extractor\n","# Defining neural network in python by a class that inherits from nn.Module\n","class LeNet(nn.Module):\n","    \"\"\"LeNet feature extractor model.\"\"\"\n","\n","    def __init__(self):\n","        \"\"\"Init LeNet feature extractor model.\"\"\"\n","        super(LeNet, self).__init__()\n","\n","        # Defining the CNNfeature Extractor\n","        self.feature_extractor = nn.Sequential(\n","            # input [1 x 28 x 28]\n","            # 1st conv layer\n","            # Conv which convolves input image with 6 filters of 5x5 size, without padding\n","            nn.Conv2d(1, 6, kernel_size=5),\n","            \n","            # YOUR CODE HERE : Define Max pooling subsampling operation layer where kernel size is '2'.\n","            nn.MaxPool2d(kernel_size=2),\n","           \n","            # YOUR CODE HERE : Define a Non linear activation function (relu)\n","            nn.ReLU(),\n","\n","            # 2nd conv layer\n","            # input [6 x 12 x 12]\n","            # Conv which convolves input image with 16 filters of 5x5 size, without padding\n","            nn.Conv2d(6, 16, kernel_size=5), # [16 x 8 x 8]\n","\n","            # YOUR CODE HERE : Define Max pooling subsampling operation layer where kernel size is '2'.\n","            nn.MaxPool2d(kernel_size=2),\n","            # [16 x 4 x 4]\n","           \n","            # YOUR CODE HERE : Define a Non linear activation function (relu)\n","            nn.ReLU()\n","        )\n","        \n","        # Defining the Classifier\n","        self.classifier = nn.Sequential(\n","            # Linear layer with 120 hidden nodes, taking a flattened [16 x 4 x 4] as input\n","            nn.Linear(16 * 4 * 4, 120),\n","\n","            # YOUR CODE HERE : Define a linear layer (following from the layer one line above, for a output size of 84)\n","            nn.Linear(120, 84),\n","\n","            # YOUR CODE HERE : Define activation (relu) layer\n","            nn.ReLU(),\n","\n","            # YOUR CODE HERE : Define a linear layer (following from the layer above, for out of 10 i.e. the final number of classes)\n","            nn.Linear(84, 10)\n","        )\n","        \n","    def forward(self, input):\n","        \"\"\"Define a Forward pass of the LeNet.\"\"\"\n","        out = self.feature_extractor(input) # YOUR CODE HERE : Extract the features by passing input through the 'feature_extractor' defined above.\n","        \n","        out = out.view(-1, 16 * 4 * 4) # Reshape the 2D to a vector\n","        out = self.classifier(out) # YOUR CODE HERE : Get the predictions by passing features through the 'classifier' defined above.\n","        out = F.softmax(out) # YOUR CODE HERE : Convert the predictions to probabilities, by applying the softmax function\n","        return out"],"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vFmW4izimMaM"},"source":["Every Tensor in PyTorch has a **to()** member function. Its job is to put the tensor on which it's called to a certain device whether it be the CPU or a certain GPU.\n","\n","Input to the to function is a torch.device object which can be initialized with either of the following inputs. \n","* cpu for CPU \n","* cuda:0 for putting it on GPU number 0. Similarly, if your system has multiple GPUs, then the respective number would be considered while initializing the device.\n","\n","Generally, whenever you initialize a Tensor, it’s put on the CPU. You should move it to the GPU to make the related calculation faster.\n"]},{"cell_type":"code","metadata":{"id":"NeuqAK-Il3yj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608712147096,"user_tz":300,"elapsed":6489,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"1fd3cf2f-e2eb-46e6-b1ca-2d31d73bca7b"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"markdown","metadata":{"id":"1ElGuL0rLgSj"},"source":["### Creating an instance of the network\n","Let us declare an object of class LeNet, and make it a CUDA model if CUDA is available:"]},{"cell_type":"markdown","metadata":{"id":"5uE3NRs80inX"},"source":["Next we will inspect our model, and see the parameters in each layer. Note that the activation and MaxPooling layers do not have any learnable parameters. Also note the sizes of parameters for each layer.\n","\n","- For convolutional layer weights, it is input channels x output_channels x window_width x window_height.\n","- For convolutional layer biases, it is output_channels.\n","- For linear layer weights, it is input_size x output_size\n","- For linear layer biases, it is output_size"]},{"cell_type":"code","metadata":{"id":"4uPkNRmsC25R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608712147097,"user_tz":300,"elapsed":6484,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"8809f9ba-e8f9-4554-8393-6d653f1c7d57"},"source":["lenet = LeNet()\n","lenet = lenet.to(device)  # Making the lenet to run on available runtime\n","\n","# Print out the size of parameters of each layer\n","# state_dict() is simply a Python dictionary object that maps each layer to its parameter tensor\n","for name, param in lenet.state_dict().items():\n","    print(name, '\\n', param.size(), '\\n')"],"execution_count":50,"outputs":[{"output_type":"stream","text":["feature_extractor.0.weight \n"," torch.Size([6, 1, 5, 5]) \n","\n","feature_extractor.0.bias \n"," torch.Size([6]) \n","\n","feature_extractor.3.weight \n"," torch.Size([16, 6, 5, 5]) \n","\n","feature_extractor.3.bias \n"," torch.Size([16]) \n","\n","classifier.0.weight \n"," torch.Size([120, 256]) \n","\n","classifier.0.bias \n"," torch.Size([120]) \n","\n","classifier.1.weight \n"," torch.Size([84, 120]) \n","\n","classifier.1.bias \n"," torch.Size([84]) \n","\n","classifier.3.weight \n"," torch.Size([10, 84]) \n","\n","classifier.3.bias \n"," torch.Size([10]) \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pox6ItueC25X"},"source":["### Do a Forward Pass (an example), and compute the accuracy\n","\n","The code below randomly loops over the train-data, does forward pass and compute the accuracy on the same. The weights and biases of the network are randomly initialized by default. \n","\n","Hence the prediction accuracy currently is very close to a random guess of the labels which is 1/10 = 10%.\n","\n","The step is done as the last step in the typical deep learning program. It is given here just for illustrating Forward pass."]},{"cell_type":"code","metadata":{"id":"y7mMsccnC25Z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa4f95a1-76d0-48b6-ef01-4ba3823d8a06"},"source":["correct = 0\n","total = 0\n","\n","for images, labels in train_loader:\n","    # Convert the images and labels to gpu for faster execution\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    \n","    result = lenet(images) # YOUR CODE HERE : Perform forward pass by passing 'images' as input to the model 'lenet' defined above.\n","     \n","    # Find the prediction with the largest probability\n","    _,pred = torch.max(result,1)\n","    total += labels.size(0)\n","\n","    # correct is incremented by the numer of predictions which are correct (equal to the ground truth labels)\n","    correct += (pred == labels).sum().item()\n","\n","print('Accuracy of random Train Data:', 100 * correct/total)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of random Train Data: 16.58\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R8ZaomZlC25e"},"source":["### Loss Function  and Gradient Update Algorithm\n"]},{"cell_type":"markdown","metadata":{"id":"2mzSRNhyxt_L"},"source":["The **loss function** is a way of measuring the difference between the current prediction of the network and the correct prediction. As we saw in the lecture, the gradient descent algorithm is essentially adjusting the learnable parameters (weights and biases) of the network so as to decrease the loss. Here we will be using the **cross entropy loss**, which is commonly used for classification tasks (predicting a class from 0 to 9).\n","\n","The **learning rate** is a small fraction which is used to multiply the gradients of the loss function with respect to the weights. The idea behind doing this is that, we do not want to make drastic change to the weights of the neural network in each step, but rather a gradual one. \n"]},{"cell_type":"markdown","metadata":{"id":"g5CdYXUPxwCk"},"source":["**Ungraded Exercise:** Try with different values of the learning rate and see how it affects the training. You should observe that if the learning rate is very small, the model hardly learns (that produces less accuracy). \n","\n","Finding the optimal learning rate is often a trial and error method. However, some gradient update algorithms can automatically find the right learning rate. \n","\n","Finally, we also need to specify the gradient update algorithm. "]},{"cell_type":"code","metadata":{"id":"iQRWcL7fC25f","executionInfo":{"status":"ok","timestamp":1608712493855,"user_tz":300,"elapsed":470,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["criterion = nn.CrossEntropyLoss() # YOUR CODE HERE : Explore and Define a loss function\n","\n","learning_rate = 0.5 # YOUR CODE HERE : Set the learning rate or step size.\n","\n","optimizer = torch.optim.Adam(lenet.parameters(), lr=learning_rate)"],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V5vKPAKCC25k"},"source":["### Training the Model\n","\n","\n","Now that we have loaded the data, defined the neural network, specified the loss function and optimizer algorithm, we can do the training. The training is done by loading a part of the training data, called minibatch. The size of the minibatch is specified by the batch_size. We will load one minibatch at a time and do forward as well as backward pass on the model. We will keep doing things by looping over the entire dataset.\n","\n","As we progress in the loop, we also plot the loss function to see if it is indeed decreasing. Plotting also helps in observing when the model has stopped learning. We will say that the model has stopped learning when the plotted loss curve becomes horizontal.\n"]},{"cell_type":"code","metadata":{"id":"ouOCz2SXC25l","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4fd17c68-0f68-4a9d-96bf-cb4f45ab6dfe"},"source":["# The number of times we should iterate over the training data\n","epoch = 8\n","\n","# First switch the module mode to lenet.train() so that new weights can be learned after every epoch. \n","lenet.train()\n","\n","loss_history = []\n","\n","for i in range(epoch):\n","    print('#### Epoch ', i)\n","    iter_loss = 0\n","    for batch_idx, (image, label) in enumerate(train_loader):\n","     \n","        # Convert image and label to gpu runtime for faster execution\n","        image = image.to(device)\n","        label = label.to(device)\n","\n","        # YOUR CODE HERE: Zero out the gradients using 'zero_grad' function\n","        optimizer.zero_grad() \n","\n","        predictions = lenet(image) # YOUR CODE HERE: Perform forward pass on the current mini batch by passing 'image' as input to the model.\n","        \n","        loss = criterion(predictions, label) # YOUR CODE HERE: Compute the loss using 'loss_func' defined above.\n","        iter_loss += loss.item()\n","        \n","        # YOUR CODE HERE :  Perform backward pass\n","        loss.backward()\n","        \n","        # YOUR CODE HERE :  Update the parameters using the gradients with the learning rate\n","        optimizer.step()\n","        \n","    loss_history.append(iter_loss/len(mnist_train)) \n","                    \n","plt.plot(loss_history)\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"loss\")\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["#### Epoch  0\n","#### Epoch  1\n","#### Epoch  2\n","#### Epoch  3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j2fo6SPxC25r"},"source":["### Compute the Accuracy of the Model on the Test data\n","Finally, we need to check how well the model is doing on the testing data. This step is also done by loading the data one minibatch at a time and computing the accuracy, which is finally averaged."]},{"cell_type":"code","metadata":{"id":"CKk8LeBdC25t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608711886611,"user_tz":300,"elapsed":1713,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"965e254a-cb82-4b5a-ab84-861c31b24748"},"source":["correct = 0\n","total = 0\n","\n","for images, labels in test_loader:\n","    \n","    # Convert images and labels to gpu runtime for faster execution\n","    images = images.to(device)\n","    labels = labels.to(device)\n","        \n","    # Passing the data to the model (Forward Pass)\n","    result = lenet(images)\n","\n","    _,pred = torch.max(result, 1) # YOUR CODE HERE : Find the predictions with the largest probability\n","    \n","    total += labels.size(0)\n","    \n","    # correct is incremented by the numer of prediction which are correct (equal to the ground truth labels)\n","    correct += (pred == labels).sum().item()\n","    \n","print(\"Accuracy of Test Data: {0:.2f}%\".format(correct/total *100))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Accuracy of Test Data: 82.73%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CNkrKEJ6Dpqj"},"source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"QOUuzd7rnx5U","executionInfo":{"status":"ok","timestamp":1608711893356,"user_tz":300,"elapsed":328,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title During forward pass when \"result = lenet(images)\" is called, the variable 'result' holds output of the forward() method of LeNet class? (You may refer the following [link](https://discuss.pytorch.org/t/confusion-regarding-use-of-forward-function-while-developing-a-cnn-model/52058/2)) { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer = \"TRUE\"#@param [\"\",\"TRUE\",\"FALSE\"]\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMzKSbLIgFzQ","executionInfo":{"status":"ok","timestamp":1608711897861,"user_tz":300,"elapsed":302,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Good, But Not Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjcH1VWSFI2l","executionInfo":{"status":"ok","timestamp":1608711903824,"user_tz":300,"elapsed":355,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"nn\" #@param {type:\"string\"}\n"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VBk_4VTAxCM","executionInfo":{"status":"ok","timestamp":1608711905759,"user_tz":300,"elapsed":407,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"r35isHfTVGKc","executionInfo":{"status":"ok","timestamp":1608711908909,"user_tz":300,"elapsed":429,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Walkthrough = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH91cL1JWH7m","executionInfo":{"status":"ok","timestamp":1608711911770,"user_tz":300,"elapsed":474,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8xLqj7VWIKW","executionInfo":{"status":"ok","timestamp":1608711914663,"user_tz":300,"elapsed":376,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"FzAZHt1zw-Y-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608711916185,"user_tz":300,"elapsed":991,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"41b81311-d049-45c8-87eb-69dd4423a0bc"},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id = return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Your submission is successful.\n","Ref Id: 12310\n","Date of submission:  23 Dec 2020\n","Time of submission:  13:53:52\n","View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\n"],"name":"stdout"}]}]}