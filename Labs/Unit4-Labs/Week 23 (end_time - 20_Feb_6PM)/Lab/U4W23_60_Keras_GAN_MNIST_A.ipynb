{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"U4W23_60_Keras_GAN_MNIST_A.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"lfiU7vYXTUxH"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"CL2dp3Y3DLdV"},"source":["## Learning Objective"]},{"cell_type":"markdown","metadata":{"id":"OTdi8IF4DPBK"},"source":["At the end of the experiment, you will be able to :\n","\n","* understand GAN using keras framework"]},{"cell_type":"code","metadata":{"id":"OvDJsz_mnH9j","cellView":"form"},"source":["#@title Experiment Walkthrough Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"420\" height=\"540\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/Keras_GANs.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9NuRcSZydkL_"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"5KqbKyGSdnuq"},"source":["###Description\n","\n","We use the MNIST dataset for this experiment. Below are the details:\n","\n","1. The dataset contains 60,000 Handwritten digits as training samples and 10,000 Test samples, \n","which means each digit occurs 6000 times in the training set and 1000 times in the testing set. (approximately). \n","2. Each image is Size Normalized and Centered \n","3. Each image is 28 X 28 Pixel with 0-255 Gray Scale Value. \n","4. That means each image is represented as 784 (28 X28) dimension vector where each value is in the range 0- 255.\n","\n","### History\n","\n","Yann LeCun (Director of AI Research, Facebook, Courant Institute, NYU) was given the task of identifying the cheque numbers (in the 90’s) and the amount associated with that cheque without manual intervention. That is when this dataset was created which raised the bars and became a benchmark.\n","\n","Yann LeCun and Corinna Cortes (Google Labs, New York) hold the copyright of MNIST dataset, which is a subset of the original NIST datasets. This dataset is made available under the terms of the Creative Commons Attribution-Share Alike 3.0 license. \n","\n","It is the handwritten digits dataset in which half of them are written by the Census Bureau employees and remaining by the high school students. The digits collected among the Census Bureau employees are easier and cleaner to recognize than the digits collected among the students.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MJu4cGUCdwTr"},"source":["## Domain Information"]},{"cell_type":"markdown","metadata":{"id":"vMtA8wDddypU"},"source":["\n","Handwriting changes person to person. Some of us have neat handwriting and some have illegible handwriting such as doctors. However, if you think about it even a child who recognizes alphabets and numerics can identify the characters of a text even written by a stranger. But even a technically knowledgeable adult cannot describe the process by which he or she recognizes the text/letters. As you know this is an excellent challenge for Machine Learning.\n","\n","![altxt](https://i.pinimg.com/originals/f2/7a/ac/f27aac4542c0090872110836d65f4c99.jpg)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"X4F3RvUAd4Hw"},"source":["## AI / ML Technique"]},{"cell_type":"markdown","metadata":{"id":"L1qJVLV4f2tw"},"source":["### Generative Adversary Networks (GAN)\n","\n","\n","GANs are generative models devised by Goodfellow et al. in 2014. GAN is about creating, like drawing a portrait or composing a symphony. This is hard compared to other deep learning fields. For instance, it is much easier to identify a Monet painting than painting one.\n","\n","\n","The main focus of GAN is to generate data from scratch, mostly images but other domains including music have been done.\n","\n","GAN composes of two deep networks :\n","\n","* Generator\n","* Discriminator\n","\n","\n","#### Generator \n","\n","The generator tries to produce data that come from some probability distribution. For example, that would be you trying to reproduce the party’s tickets.\n","\n","#### Discriminator\n","\n","The discriminator acts like a judge. It gets to decide if the input comes from the generator or from the true training set. For example, that would be the party’s security comparing your fake ticket with the true ticket to find flaws in your design.\n","\n","In summary, we can say that :\n","\n","* The generator trying to maximize the probability of making the discriminator mistake its inputs as real.\n","\n","* And the discriminator guiding the generator to produce more realistic images.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IfpAgIPxr1Em"},"source":["![alt text](https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/gan.png)"]},{"cell_type":"markdown","metadata":{"id":"e8ktuH54eQo8"},"source":["### Setup Steps"]},{"cell_type":"code","metadata":{"id":"9Y_UxOzPeVkW"},"source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2NKdNiU3eWap"},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WBPPuGmBlDIN","cellView":"form"},"source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","ipython = get_ipython()\n","\n","notebook= \"U4W23_60_Keras_GAN_MNIST_A\" #name of the notebook\n","\n","def setup():\n","    from IPython.display import HTML, display\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","    \n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n","              \"feedback_experiments_input\" : Comments,\n","              \"feedback_mentor_support\": Mentor_support}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:        \n","        print(r[\"err\"])\n","        return None   \n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\")\n","        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","        return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if not Additional: \n","      raise NameError\n","    else:\n","      return Additional  \n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","  \n","  \n","def getWalkthrough():\n","  try:\n","    if not Walkthrough:\n","      raise NameError\n","    else:\n","      return Walkthrough\n","  except NameError:\n","    print (\"Please answer Walkthrough Question\")\n","    return None\n","  \n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","  \n","\n","def getMentorSupport():\n","  try:\n","    if not Mentor_support:\n","      raise NameError\n","    else:\n","      return Mentor_support\n","  except NameError:\n","    print (\"Please answer Mentor support Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    if not Answer:\n","      raise NameError \n","    else: \n","      return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","  \n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup() \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eBD0M7uyinT3"},"source":["### Importing required  Packages\n","\n","\n"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-06-18T17:17:29.299849Z","start_time":"2018-06-18T17:17:28.948111Z"},"id":"UC3lWkPqxxoZ"},"source":["from keras.datasets import mnist\n","from keras.models import Model\n","from keras.layers import Dense, LeakyReLU, BatchNormalization, Input\n","from keras.optimizers import Adam\n","\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qasiyCseXjrD"},"source":["### Load the Data"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-06-18T17:17:31.211621Z","start_time":"2018-06-18T17:17:30.628121Z"},"id":"0oeOE4uhxxod"},"source":["# Load dataset\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SVhDIEMiX1bc"},"source":["### Visualize the data"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-06-18T17:17:31.673570Z","start_time":"2018-06-18T17:17:31.213616Z"},"id":"RxqRv7-Hxxoe"},"source":["fig = plt.figure()\n","for i in range(10):\n","    plt.subplot(2, 5, i+1)\n","    x_y = X_train[y_train == i]\n","    plt.imshow(x_y[0], cmap='gray', interpolation='none')\n","    plt.title(\"Class %d\" % (i))\n","    plt.xticks([])\n","    plt.yticks([])\n","    \n","plt.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Q9kNOoWfwiw"},"source":["### Data Pre-Processing\n"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-06-18T17:17:31.926590Z","start_time":"2018-06-18T17:17:31.675462Z"},"id":"YHbXFwH6xxof"},"source":["print('X_train shape', X_train.shape)\n","\n","# Reshaping the inputs\n","X_train = X_train.reshape(60000, 28*28)\n","# Normalizing the inputs (-1, 1)\n","X_train = (X_train.astype('float32') / 255 - 0.5) * 2\n","\n","print('X_train reshape:', X_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RSopxRZEZsp4"},"source":["### Build the Generator Model"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-06-18T17:17:32.266239Z","start_time":"2018-06-18T17:17:31.929037Z"},"id":"rd7tLDOHxxog"},"source":["# Get the generator model\n","def build_generator(latent_dim):\n","\n","  # Generator takes in a vector from the latent space\n","  i = Input(shape=(latent_dim,))\n","\n","  # The Leaky ReLU modifies the ReLu function to allow small negative values when the input is less than zero\n","  # below the threshold value of the activation function, the values will be damped or set to zero\n","  # alpha governs the slope for values lower than the threshold \n","  \n","  # YOUR CODE HERE: To dfine the dense layer with the latent dimension as input with 256 hidden nodes\n","  # YOUR CODE HERE: To define the batch normalization with momentum\n","\n","\n","  # YOUR CODE HERE: To dfine the second dense layer with 512 hidden nodes\n","  # YOUR CODE HERE: To define the batch normalization with momentum\n","\n","  x = Dense(1024, activation=LeakyReLU(alpha=0.2))(x)\n","  x = BatchNormalization(momentum=0.7)(x)\n","\n","  # Because our image pixels are censored to be between -1 and +1 use tanh activation function\n","  # The range of the tanh function is from (-1 to 1)\n","\n","  # YOUR CODE HERE: To define the output layer with activation as 'tanh'\n","\n","  model = Model(i, x)\n","  return model\n","\n","\n","# Dimensionality of the latent space\n","latent_dim = 100 # Can be replaced with any number\n","\n","generator = # YOUR CODE HERE: To call the generator function with latent_dim as input\n","\n","\n","# Display the summary representation of the model\n","generator.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9vuIL62FaNht"},"source":["### Build the Discriminator Model"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-06-18T17:17:32.326856Z","start_time":"2018-06-18T17:17:32.275681Z"},"id":"j2gtkJGUxxoi"},"source":["# Get the discriminator model\n","def build_discriminator(img_size):\n","  i = Input(shape=(img_size,))\n","  x = Dense(512, activation=LeakyReLU(alpha=0.2))(i)\n","  x = Dense(256, activation=LeakyReLU(alpha=0.2))(x)\n","  \n","  # YOUR CODE HERE: To define the output layer with sigmoid activation function\n","\n","  model = Model(i, x)\n","  return model\n","\n","discriminator = # YOUR CODE HERE: To call the discriminator function with img_size as 784"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h8ULw_8Xxxoi"},"source":["#### Discriminator model visualization"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-06-18T17:17:32.332285Z","start_time":"2018-06-18T17:17:32.328654Z"},"id":"6c4uTVUOxxok"},"source":["# Display the summary representation of the model\n","discriminator.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3r4SBVvHbStP"},"source":["### Compile the Discriminator Model"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-06-18T17:17:32.385813Z","start_time":"2018-06-18T17:17:32.334488Z"},"id":"19dhxJY0xxok"},"source":["# # YOUR CODE HERE: To define the Adam optimizer\n","\n","# YOUR CODE HERE: To compile the discriminator Model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DmPfXUHhAq1f"},"source":["# Create an input to represent noise sample from latent space\r\n","noise = Input(shape=(latent_dim,))\r\n","\r\n","# Pass noise through generator to get an image\r\n","img = generator(noise)\r\n","\r\n","# YOUR CODE HERE: Freeze the discriminator layers by setting trainable parameter to False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32Z2bddlPJbl"},"source":["Pass output image of the generator as input to the discriminator model"]},{"cell_type":"code","metadata":{"id":"ugaPMht-E7YC"},"source":["# The true output is fake, but we label them real!\r\n","fake_pred = # YOUR CODE HERE: To pass the output image from the generator to discriminator"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b0OLZhFdxxol"},"source":["### Combined network"]},{"cell_type":"markdown","metadata":{"id":"8kfxtQJPE-o4"},"source":["#### Build and compile the combined model\r\n","\r\n","Create a new model object called **combined model** which takes input a `noise` sample and produces the output prediction (fake)"]},{"cell_type":"code","metadata":{"id":"nC-vBiQgFDhr"},"source":["combined_model = # YOUR CODE HERE: To create the combined model by passing noise and fake_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IYhk16-_FEnd"},"source":["# Display the summary representation of the model\r\n","combined_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HrEpMsQzBE-t"},"source":["# YOUR CODE HERE: To compile the combined model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YaPflL5lcwMW"},"source":["### Train the Model\n","\n","\n","We train the discriminator and the generator in turn in a loop as follows:\n","\n","1. Set the discriminator trainable\n","2. Train the discriminator with the real digit images and the images generated by the generator to classify the real and fake images.\n","3. Set the discriminator non-trainable\n","4. Train the generator as part of the GAN. We feed latent samples into the GAN and let the generator to produce digit images and use the discriminator to classify the image."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-06-18T17:50:25.368754Z","start_time":"2018-06-18T17:17:32.678615Z"},"id":"W1nDkgMyxxom"},"source":["epochs = 150\n","batch_size = 64\n","\n","# Smoothed labels to the discriminator network\n","# This means we can have decimal values such as 0.9 (true), 0.8 (true), 0.1 (fake), or 0.2 (fake), \n","# instead of labeling every example as either 1 (true) or 0 (fake)\n","smooth = 0.1\n","\n","# YOUR CODE HERE: To initialize the Labels for generated (with zeros) and real data (with ones) while training\n","\n","d_loss = []\n","combined_model_loss = []\n","\n","for e in range(epochs + 1):\n","    for i in range(len(X_train) // batch_size):\n","        \n","        # YOUR CODE HERE: To train the discriminator weights by setting trainable parameter to True\n","        \n","        # Real samples\n","        X_batch = X_train[i*batch_size:(i+1)*batch_size]\n","        # Return the real loss \n","        d_loss_real = discriminator.train_on_batch(x=X_batch, y=real * (1 - smooth))\n","        \n","        # Fake Samples\n","        # To train the generator we need fake images only\n","        z = np.random.normal(loc=0, scale=1, size=(batch_size, latent_dim))\n","        X_fake = generator.predict_on_batch(z)\n","        d_loss_fake =  # YOUR CODE HERE: To train the discriminator on the fake data and store the loss\n","         \n","        # Discriminator loss\n","        # YOUR CODE HERE: To calculate the overall loss take the mean of the real and fake losses \n","\n","        # Train Generator weights\n","        # During the training of gan,\n","        # the weights of discriminator should be fixed.\n","        # We can enforce that by setting the trainable flag\n","        discriminator.trainable = False\n","        \n","        # The input is the noise and the target is our vector of ones\n","        # This is because we are trying to trick the discriminator into thinking that the images from the generator are real\n","        combined_model_loss_batch = combined_model.train_on_batch(x=z, y=real)\n","   \n","        print('epoch = %d/%d, batch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, i, len(X_train) // batch_size, d_loss_batch, combined_model_loss_batch[0]),100*' ',end='\\r')\n","    \n","    # Save the losses (Append both losses to the lists of losses)\n","    d_loss.append(d_loss_batch)\n","    combined_model_loss.append(combined_model_loss_batch[0])\n","    print('epoch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, d_loss[-1], combined_model_loss[-1]), 100*' ')\n","\n","    if e % 10 == 0:\n","        samples = 10\n","        # Generate fake MNIST images from noised input\n","        x_fake = generator.predict(np.random.normal(loc=0, scale=1, size=(samples, latent_dim)))\n","\n","        for k in range(samples):\n","            plt.subplot(2, 5, k+1)\n","            plt.imshow(x_fake[k].reshape(28, 28), cmap='gray')\n","            plt.xticks([])\n","            plt.yticks([])\n","\n","        plt.tight_layout()\n","        plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"giNdCc9at8-1"},"source":["### Please answer the questions below to complete the experiment:"]},{"cell_type":"code","metadata":{"id":"eMJFxr5YskFs","cellView":"form"},"source":["#@title State True or False: The generator model in GANs takes random noise as input data and generates a new image\n","Answer = \"\" #@param [\"\",\"TRUE\", \"FALSE\"] \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMzKSbLIgFzQ"},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjcH1VWSFI2l"},"source":["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VBk_4VTAxCM"},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r35isHfTVGKc"},"source":["#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Walkthrough = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH91cL1JWH7m"},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8xLqj7VWIKW"},"source":["#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"FzAZHt1zw-Y-"},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id = return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":null,"outputs":[]}]}