{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BOW_Sentiment_Analysis_Text_Classification.ipynb","provenance":[],"mount_file_id":"1EPbopwnor7kdwvXHZyw-xZ5Xy72pVW6i","authorship_tag":"ABX9TyMbeKxLKs8Z3mQHLpHbN2CR"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"0aAsbZx325TK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SEEPFwtf3NX9"},"source":["Movie reviews can be classified as either favorable or not.\n","\n","The evaluation of movie review text is a classification problem often called sentiment analysis. A popular technique for developing sentiment analysis models is to use a bag-of-words model that transforms documents into vectors where each word in the document is assigned a score.\n","\n","develop a deep learning predictive model using the bag-of-words representation for movie review sentiment classification."]},{"cell_type":"markdown","metadata":{"id":"TdCKQziW4doU"},"source":["**Movie Review Dataset**"]},{"cell_type":"markdown","metadata":{"id":"BUWk7B4q68bP"},"source":["**Data Preparation**\n","\n","Separation of data into training and test sets.\n","Loading and cleaning the data to remove punctuation and numbers.\n","Defining a vocabulary of preferred words.\n","\n","\n","\n","1.   Split into Train and Test Sets\n","\n","we are developing a system that can predict the sentiment of a textual movie review as either positive or negative. **This means that after the model is developed, we will need to make predictions on new textual reviews.**  This will require all of the same data preparation to be performed on those new reviews as is performed on the training data for the model. **That being said, we will use the last 100 positive reviews and the last 100 negative reviews as a test set (100 reviews) and the remaining 1,800 reviews as the training dataset.**\n","\n","\n","This is a 90% train, 10% split of the data.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DkPFkdXH9Gq7"},"source":["**Loading and Cleaning Reviews**\n","\n","The text data is already pretty clean, so not much preparation is required.\n","\n","Split tokens on white space.\n","Remove all punctuation from words.\n","Remove all words that are not purely comprised of alphabetical characters.\n","Remove all words that are known stop words.\n","Remove all words that have a length <= 1 character.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"DSxjhikS-cf2","executionInfo":{"status":"ok","timestamp":1601516950523,"user_tz":240,"elapsed":8672,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"a03dc99a-2ba0-47e2-f350-553febbc84a5","colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["from nltk.corpus import stopwords\n","import string\n","import nltk\n","nltk.download('stopwords')\n"," \n","# load doc into memory\n","def load_doc(filename):\n","\t# open the file as read only\n","\tfile = open(filename, 'r')\n","\t# read all text\n","\ttext = file.read()\n","\t# close the file\n","\tfile.close()\n","\treturn text\n"," \n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","\t# split into tokens by white space\n","\ttokens = doc.split()\n","\t# remove punctuation from each token\n","\ttable = str.maketrans('', '', string.punctuation)\n","\ttokens = [w.translate(table) for w in tokens]\n","\t# remove remaining tokens that are not alphabetic\n","\ttokens = [word for word in tokens if word.isalpha()]\n","\t# filter out stop words\n","\tstop_words = set(stopwords.words('english'))\n","\ttokens = [w for w in tokens if not w in stop_words]\n","\t# filter out short tokens\n","\ttokens = [word for word in tokens if len(word) > 1]\n","\treturn tokens\n"," \n","# load the document\n","filename = '/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/neg/cv099_11189.txt'\n","text = load_doc(filename)\n","tokens = clean_doc(text)\n","print(tokens)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","['whether', 'like', 'beatles', 'nobody', 'wants', 'see', 'bee', 'gees', 'take', 'fab', 'fours', 'best', 'known', 'songs', 'well', 'maybe', 'thats', 'true', 'maybe', 'youre', 'curious', 'way', 'look', 'hanky', 'blow', 'nose', 'know', 'bad', 'bad', 'thats', 'case', 'rejoice', 'twenty', 'years', 'ago', 'today', 'sgt', 'peppers', 'lonely', 'hearts', 'club', 'band', 'released', 'unleashed', 'world', 'thanks', 'modern', 'technological', 'advances', 'find', 'retched', 'piece', 'filmmaking', 'vhs', 'derived', 'lyrics', 'various', 'beatles', 'songs', 'sgt', 'peppers', 'tells', 'story', 'fictitious', 'band', 'made', 'popular', 'song', 'album', 'name', 'released', 'course', 'movie', 'made', 'eleven', 'years', 'later', 'gibbs', 'three', 'become', 'lonely', 'hearts', 'peter', 'frampton', 'one', 'billy', 'shears', 'aside', 'rock', 'band', 'story', 'doesnt', 'correlate', 'song', 'oh', 'joy', 'lovely', 'audience', 'theyd', 'like', 'take', 'home', 'dont', 'think', 'least', 'characters', 'actually', 'people', 'beatles', 'song', 'whereas', 'characters', 'strawberry', 'fields', 'sandy', 'farina', 'gets', 'name', 'song', 'place', 'called', 'strawberry', 'fields', 'debate', 'really', 'quite', 'futile', 'comes', 'film', 'really', 'offer', 'feast', 'horrid', 'cover', 'tunes', 'embarrassing', 'cameo', 'appearances', 'george', 'burns', 'steve', 'martin', 'alice', 'cooper', 'uuuuuuggggggglllllllyyyyy', 'fashion', 'faces', 'check', 'please', 'plot', 'bit', 'unclear', 'people', 'bad', 'hair', 'run', 'around', 'leisure', 'suits', 'engaging', 'music', 'video', 'sequences', 'look', 'like', 'sick', 'twisted', 'world', 'makebelieve', 'overly', 'demented', 'mr', 'rogers', 'mean', 'mr', 'mustard', 'frankie', 'howerd', 'somehow', 'gets', 'hold', 'billy', 'co', 'instruments', 'calling', 'dr', 'maxwell', 'edison', 'steve', 'martin', 'silver', 'hammer', 'outofkey', 'singing', 'voice', 'sun', 'king', 'marvin', 'sunk', 'alice', 'cooper', 'couple', 'creepy', 'robots', 'aid', 'supposedly', 'horrible', 'thing', 'guess', 'heartland', 'talent', 'pretty', 'nonexistent', 'meanwhile', 'lonely', 'hearts', 'classic', 'sex', 'drugs', 'rock', 'roll', 'thing', 'leaving', 'poor', 'strawberry', 'fields', 'without', 'true', 'love', 'billy', 'sets', 'find', 'leaving', 'poor', 'dad', 'mom', 'mrs', 'fields', 'hey', 'wanna', 'cookie', 'alone', 'sing', 'horrible', 'rendition', 'shes', 'leaving', 'home', 'accompanied', 'creepy', 'robots', 'billy', 'getting', 'lucy', 'dianne', 'steinberg', 'ya', 'know', 'diamond', 'possessing', 'girl', 'hangs', 'sky', 'well', 'theres', 'crazy', 'chick', 'singing', 'soprano', 'roof', 'building', 'next', 'bus', 'stop', 'assume', 'thats', 'movies', 'like', 'make', 'ya', 'sit', 'back', 'ask', 'unanswerable', 'question', 'hell', 'thinking', 'nobody', 'ever', 'know', 'novelty', 'sgt', 'peppers', 'one', 'examine', 'carol', 'channing', 'robert', 'palmer', 'keith', 'carradine', 'theyre', 'knows', 'irrelevant', 'theres', 'much', 'meaning', 'found', 'found', 'bellybutton', 'lint', 'although', 'latter', 'may', 'interesting', 'recent', 'onslaught', 'nostalgia', 'movie', 'world', 'ice', 'storm', 'boogie', 'nights', 'reissues', 'star', 'wars', 'trilogy', 'etc', 'lets', 'pray', 'doesnt', 'get', 'special', 'anniversary', 'secondchance', 'theaters', 'words', 'paul', 'mccartney', 'live', 'let', 'die', 'fact', 'bury', 'one', 'still']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bWkmla0N_jgF"},"source":[" **Define a Vocabulary**\n","\n"," The more words, the larger the representation of documents, therefore it is important to constrain the words to only those believed to be predictive. This is difficult to know beforehand and often it is important to test different hypotheses about how to construct a useful vocabulary.\n"]},{"cell_type":"markdown","metadata":{"id":"663tFoJE_r_a"},"source":["We can develop a vocabulary as a Counter, which is a dictionary mapping of words and their count that allows us to easily update and query.\n","\n","Each document can be added to the counter (a new function called add_doc_to_vocab()) and we can step over all of the reviews in the negative directory and then the positive directory (a new function called process_docs()).\n","\n"]},{"cell_type":"code","metadata":{"id":"FrGPp6COBmvx","executionInfo":{"status":"ok","timestamp":1601518015464,"user_tz":240,"elapsed":1050344,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"f1e5a6c3-1b43-4cb7-d6c7-02bfc9860ccf","colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["from string import punctuation\n","from os import listdir\n","from collections import Counter\n","from nltk.corpus import stopwords\n"," \n","# load doc into memory\n","def load_doc(filename):\n","\t# open the file as read only\n","\tfile = open(filename, 'r')\n","\t# read all text\n","\ttext = file.read()\n","\t# close the file\n","\tfile.close()\n","\treturn text\n"," \n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","\t# split into tokens by white space\n","\ttokens = doc.split()\n","\t# remove punctuation from each token\n","\ttable = str.maketrans('', '', punctuation)\n","\ttokens = [w.translate(table) for w in tokens]\n","\t# remove remaining tokens that are not alphabetic\n","\ttokens = [word for word in tokens if word.isalpha()]\n","\t# filter out stop words\n","\tstop_words = set(stopwords.words('english'))\n","\ttokens = [w for w in tokens if not w in stop_words]\n","\t# filter out short tokens\n","\ttokens = [word for word in tokens if len(word) > 1]\n","\treturn tokens\n"," \n","# load doc and add to vocab\n","def add_doc_to_vocab(filename, vocab):\n","\t# load doc\n","\tdoc = load_doc(filename)\n","\t# clean doc\n","\ttokens = clean_doc(doc)\n","\t# update counts\n","\tvocab.update(tokens)\n"," \n","# load all docs in a directory\n","def process_docs(directory, vocab):\n","\t# walk through all files in the folder\n","\tfor filename in listdir(directory):\n","\t\t# skip any reviews in the test set\n","\t\tif filename.startswith('cv9'):\n","\t\t\tcontinue\n","\t\t# create the full path of the file to open\n","\t\tpath = directory + '/' + filename\n","\t\t# add doc to vocab\n","\t\tadd_doc_to_vocab(path, vocab)\n"," \n","# define vocab\n","vocab = Counter()\n","# add all docs to vocab\n","process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/pos', vocab)\n","process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/neg', vocab)\n","# print the size of the vocab\n","print(len(vocab))\n","# print the top words in the vocab\n","print(vocab.most_common(50))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["44276\n","[('film', 7983), ('one', 4946), ('movie', 4826), ('like', 3201), ('even', 2262), ('good', 2080), ('time', 2041), ('story', 1907), ('films', 1873), ('would', 1844), ('much', 1824), ('also', 1757), ('characters', 1735), ('get', 1724), ('character', 1703), ('two', 1643), ('first', 1588), ('see', 1557), ('way', 1515), ('well', 1511), ('make', 1418), ('really', 1407), ('little', 1351), ('life', 1334), ('plot', 1288), ('people', 1269), ('bad', 1248), ('could', 1248), ('scene', 1241), ('movies', 1238), ('never', 1201), ('best', 1179), ('new', 1140), ('scenes', 1135), ('man', 1131), ('many', 1130), ('doesnt', 1118), ('know', 1092), ('dont', 1086), ('hes', 1024), ('great', 1014), ('another', 992), ('action', 985), ('love', 977), ('us', 967), ('go', 952), ('director', 948), ('end', 946), ('something', 945), ('still', 936)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a51IgWbCCWn8"},"source":["Running the example shows that we have a vocabulary of 44,276 words.\n","\n","Note that this vocabulary was constructed based on only those reviews in the training dataset.\n","\n","We can step through the vocabulary and remove all words that have a low occurrence, such as only being used once or twice in all reviews.\n","\n"]},{"cell_type":"code","metadata":{"id":"t0gMqZxyCpcj","executionInfo":{"status":"ok","timestamp":1601369979111,"user_tz":240,"elapsed":296,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"ee27b5bf-bb1a-4d95-c6ba-6b56c3e87315","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["\n","# keep tokens with a min occurrence\n","min_occurane = 2\n","tokens = [k for k,c in vocab.items() if c >= min_occurane]\n","print(len(tokens))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["25767\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GRu36HPaDAz8"},"source":["Finally, the vocabulary can be saved to a new file called vocab.txt that we can later load and use to filter movie reviews prior to encoding them for modeling. We define a new function called save_list() that saves the vocabulary to file, with one word per file.\n","\n"]},{"cell_type":"code","metadata":{"id":"ePe_fXLgDO9w","executionInfo":{"status":"error","timestamp":1601414653414,"user_tz":240,"elapsed":449,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"c4ad0ee3-5ec4-41ba-c28b-c4d1b8c020cf","colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["\n","# save list to file\n","def save_list(lines, filename):\n","\t# convert lines to a single blob of text\n","\tdata = '\\n'.join(lines)\n","\t# open file\n","\tfile = open(filename, 'w')\n","\t# write text\n","\tfile.write(data)\n","\t# close file\n","\tfile.close()\n"," \n","# save tokens to a vocabulary file\n","save_list(tokens, '/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/vocab.txt')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-8c5cf75b2da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# save tokens to a vocabulary file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msave_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/vocab.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"XgNdVeirDyhl"},"source":["Running the min occurrence filter on the vocabulary and saving it to file, you should now have a new file called vocab.txt with only the words we are interested in.\n","\n"]},{"cell_type":"code","metadata":{"id":"y0HllXnWD4wa"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Lmzp3K7D_4S"},"source":["**Bag-of-Words Representation**\n","\n","convert each review into a representation that we can provide to a Multilayer Perceptron model. A bag-of-words model is a way of extracting features from text so the text input can be used with machine learning algorithms like neural networks.\n","\n","Each document, in this case a review, is **converted into a vector representation**. The number of items in the vector representing a document corresponds to the number of words in the vocabulary. **The larger the vocabulary, the longer the vector representation,** hence the preference for smaller vocabularies in the previous section.\n","\n","Words in a document are** scored and the scores are placed in the corresponding location in the representation**. We will look at different word scoring methods in the next section.\n","\n","In this section, we are concerned with converting reviews into vectors ready for training a first neural network model.\n","\n","This section is divided into 2 steps:\n","\n","Converting reviews to lines of tokens.\n","Encoding reviews with a bag-of-words model representation.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Dp8j2r4jHRf9"},"source":["**Reviews to Lines of Tokens**\n","\n","Before we can convert reviews to vectors for modeling, we must first clean them up.\n","\n","This involves loading them, performing the cleaning operation developed above, filtering out words not in the chosen vocabulary, and converting the remaining tokens into a single string or line ready for encoding.\n","\n","First, we need a function to prepare one document. Below lists the function doc_to_line() that will load a document, clean it, filter out tokens not in the vocabulary, then return the document as a string of white space separated tokens.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"mxQY4fkQESbo"},"source":["\n","# load doc, clean and return line of tokens\n","def doc_to_line(filename, vocab):\n","\t# load the doc\n","\tdoc = load_doc(filename)\n","\t# clean doc\n","\ttokens = clean_doc(doc)\n","\t# filter by vocab\n","\ttokens = [w for w in tokens if w in vocab]\n","\treturn ' '.join(tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6XV6k4l7Iaz8"},"source":["Next, we need a function to work through all documents in a directory (such as ‘pos‘ and ‘neg‘) to convert the documents into lines.\n","\n","Below lists the process_docs() function that does just this, expecting a directory name and a vocabulary set as input arguments and returning a list of processed documents."]},{"cell_type":"code","metadata":{"id":"KJCOsrLHIcQ3"},"source":["\n","# load all docs in a directory\n","def process_docs(directory, vocab):\n","\tlines = list()\n","\t# walk through all files in the folder\n","\tfor filename in listdir(directory):\n","\t\t# skip any reviews in the test set\n","\t\tif filename.startswith('cv9'):\n","\t\t\tcontinue\n","\t\t# create the full path of the file to open\n","\t\tpath = directory + '/' + filename\n","\t\t# load and clean the doc\n","\t\tline = doc_to_line(path, vocab)\n","\t\t# add to list\n","\t\tlines.append(line)\n","\treturn lines"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"79r8HglWIjg7"},"source":["Finally, we need to load the vocabulary and turn it into a set for use in cleaning reviews.\n","\n"]},{"cell_type":"code","metadata":{"id":"NQjd2SuOImpg"},"source":["\n","# load the vocabulary\n","vocab_filename = '/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = vocab.split()\n","vocab = set(vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IhR0j7kFJE1b"},"source":["demonstrating how to prepare the positive and negative reviews from the training dataset."]},{"cell_type":"code","metadata":{"id":"QiSGTcQFJF5N","executionInfo":{"status":"ok","timestamp":1601371070976,"user_tz":240,"elapsed":289,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"6206a6b1-378b-4fba-ceb7-9b342c6f41e0","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# load all training reviews\n","positive_lines=('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/pos', vocab)\n","negative_lines=('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/neg', vocab)\n","# summarize what we have\n","print(len(positive_lines), len(negative_lines))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WA9SRvIpKKsT","executionInfo":{"status":"ok","timestamp":1601371339037,"user_tz":240,"elapsed":3888,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"bfaf6ec7-44ff-40d4-ead3-0e611f4d9567","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["\n","from string import punctuation\n","from os import listdir\n","from collections import Counter\n","from nltk.corpus import stopwords\n"," \n","# load doc into memory\n","def load_doc(filename):\n","\t# open the file as read only\n","\tfile = open(filename, 'r')\n","\t# read all text\n","\ttext = file.read()\n","\t# close the file\n","\tfile.close()\n","\treturn text\n"," \n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","\t# split into tokens by white space\n","\ttokens = doc.split()\n","\t# remove punctuation from each token\n","\ttable = str.maketrans('', '', punctuation)\n","\ttokens = [w.translate(table) for w in tokens]\n","\t# remove remaining tokens that are not alphabetic\n","\ttokens = [word for word in tokens if word.isalpha()]\n","\t# filter out stop words\n","\tstop_words = set(stopwords.words('english'))\n","\ttokens = [w for w in tokens if not w in stop_words]\n","\t# filter out short tokens\n","\ttokens = [word for word in tokens if len(word) > 1]\n","\treturn tokens\n"," \n","# load doc, clean and return line of tokens\n","def doc_to_line(filename, vocab):\n","\t# load the doc\n","\tdoc = load_doc(filename)\n","\t# clean doc\n","\ttokens = clean_doc(doc)\n","\t# filter by vocab\n","\ttokens = [w for w in tokens if w in vocab]\n","\treturn ' '.join(tokens)\n"," \n","# load all docs in a directory\n","def process_docs(directory, vocab):\n","\tlines = list()\n","\t# walk through all files in the folder\n","\tfor filename in listdir(directory):\n","\t\t# skip any reviews in the test set\n","\t\tif filename.startswith('cv9'):\n","\t\t\tcontinue\n","\t\t# create the full path of the file to open\n","\t\tpath = directory + '/' + filename\n","\t\t# load and clean the doc\n","\t\tline = doc_to_line(path, vocab)\n","\t\t# add to list\n","\t\tlines.append(line)\n","\treturn lines\n"," \n","# load the vocabulary\n","vocab_filename = '/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = vocab.split()\n","vocab = set(vocab)\n","# load all training reviews\n","positive_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/pos', vocab)\n","negative_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/neg', vocab)\n","# summarize what we have\n","print(len(positive_lines), len(negative_lines))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["900 900\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Eqanpj_gK8CE"},"source":["**Movie Reviews to Bag-of-Words Vectors**\n","\n","Keras provides the Tokenize class that can do some of the cleaning and vocab definition tasks that we took care of in the previous section.\n","\n","It is better to do this ourselves to know exactly what was done and why. Nevertheless, the Tokenizer class is convenient and will easily transform documents into encoded vectors.\n","\n","**First, the Tokenizer must be created, then fit on the text documents in the training dataset.**\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"lK5W7qtNLjDD"},"source":["from keras.preprocessing.text import Tokenizer\n","\n","# create the tokenizer\n","tokenizer = Tokenizer()\n","# fit the tokenizer on the documents\n","docs = positive_lines + negative_lines\n","tokenizer.fit_on_texts(docs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KnAwqxfkL6kg"},"source":["This process determines a consistent way to convert the vocabulary to a fixed-length vector with 25,768 elements, which is the total number of words in the vocabulary file vocab.txt.\n","\n","Next, documents can then be encoded using the Tokenizer by calling texts_to_matrix(). The function takes both a list of documents to encode and an encoding mode, which is the method used to score words in the document. Here we specify ‘freq‘ to score words based on their frequency in the document.\n","\n"," "]},{"cell_type":"code","metadata":{"id":"jrCzLMUyNHu2","executionInfo":{"status":"ok","timestamp":1601371939337,"user_tz":240,"elapsed":1306,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"5f1fce34-7504-4d46-e4b9-53789fc797e0","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["\n","# encode training data set\n","Xtrain = tokenizer.texts_to_matrix(docs, mode='freq')\n","print(Xtrain.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1800, 25768)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8_2eCBrTNPae"},"source":["This encodes all of the positive and negative reviews in the training dataset and prints the shape of the resulting matrix as 1,800 documents each with the length of 25,768 elements. It is ready to use as training data for a model.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RciPuRcINiDj"},"source":["**We can encode the test data in a similar way.**\n","\n","First, the process_docs() function from the previous section needs to be modified to only process reviews in the test dataset, not the training dataset.\n","\n","We support the loading of both the training and test datasets by adding an is_trian argument and using that to decide what review file names to skip\n","\n"]},{"cell_type":"code","metadata":{"id":"yEJSt2B9NxRY"},"source":["\n","# load all docs in a directory\n","def process_docs(directory, vocab, is_trian):\n","\tlines = list()\n","\t# walk through all files in the folder\n","\tfor filename in listdir(directory):\n","\t\t# skip any reviews in the test set\n","\t\tif is_trian and filename.startswith('cv9'):\n","\t\t\tcontinue\n","\t\tif not is_trian and not filename.startswith('cv9'):\n","\t\t\tcontinue\n","\t\t# create the full path of the file to open\n","\t\tpath = directory + '/' + filename\n","\t\t# load and clean the doc\n","\t\tline = doc_to_line(path, vocab)\n","\t\t# add to list\n","\t\tlines.append(line)\n","\treturn lines"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z8h-0Fq3OFJh"},"source":["Next, we can load and encode positive and negative reviews in the test set in the same way as we did for the training set.\n","\n"]},{"cell_type":"code","metadata":{"id":"S83YW_-GOJNt","executionInfo":{"status":"ok","timestamp":1601372332933,"user_tz":240,"elapsed":95265,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"9702af4b-7a3a-4026-dfb2-32aa28043dc0","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["\n","# load all test reviews\n","positive_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/pos', vocab, False)\n","negative_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/neg', vocab, False)\n","docs = negative_lines + positive_lines\n","# encode training data set\n","Xtest = tokenizer.texts_to_matrix(docs, mode='freq')\n","print(Xtest.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(200, 25768)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s249oeUTOWK5"},"source":["**We can put all of this together in a single example.**\n","\n","*italicized text*"]},{"cell_type":"code","metadata":{"id":"p3tEjGqaOf0W","executionInfo":{"status":"ok","timestamp":1601378272016,"user_tz":240,"elapsed":5554,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"780588b5-221a-40f2-dedd-e0463f864e56","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["from string import punctuation\n","from os import listdir\n","from collections import Counter\n","from nltk.corpus import stopwords\n","from keras.preprocessing.text import Tokenizer\n"," \n","# load doc into memory\n","def load_doc(filename):\n","\t# open the file as read only\n","\tfile = open(filename, 'r')\n","\t# read all text\n","\ttext = file.read()\n","\t# close the file\n","\tfile.close()\n","\treturn text\n"," \n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","\t# split into tokens by white space\n","\ttokens = doc.split()\n","\t# remove punctuation from each token\n","\ttable = str.maketrans('', '', punctuation)\n","\ttokens = [w.translate(table) for w in tokens]\n","\t# remove remaining tokens that are not alphabetic\n","\ttokens = [word for word in tokens if word.isalpha()]\n","\t# filter out stop words\n","\tstop_words = set(stopwords.words('english'))\n","\ttokens = [w for w in tokens if not w in stop_words]\n","\t# filter out short tokens\n","\ttokens = [word for word in tokens if len(word) > 1]\n","\treturn tokens\n"," \n","# load doc, clean and return line of tokens\n","def doc_to_line(filename, vocab):\n","\t# load the doc\n","\tdoc = load_doc(filename)\n","\t# clean doc\n","\ttokens = clean_doc(doc)\n","\t# filter by vocab\n","\ttokens = [w for w in tokens if w in vocab]\n","\treturn ' '.join(tokens)\n"," \n","# load all docs in a directory\n","def process_docs(directory, vocab, is_trian):\n","\tlines = list()\n","\t# walk through all files in the folder\n","\tfor filename in listdir(directory):\n","\t\t# skip any reviews in the test set\n","\t\tif is_trian and filename.startswith('cv9'):\n","\t\t\tcontinue\n","\t\tif not is_trian and not filename.startswith('cv9'):\n","\t\t\tcontinue\n","\t\t# create the full path of the file to open\n","\t\tpath = directory + '/' + filename\n","\t\t# load and clean the doc\n","\t\tline = doc_to_line(path, vocab)\n","\t\t# add to list\n","\t\tlines.append(line)\n","\treturn lines\n"," \n","# load the vocabulary\n","vocab_filename = '/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = vocab.split()\n","vocab = set(vocab)\n"," \n","# load all training reviews\n","positive_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/pos', vocab, True)\n","negative_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/neg', vocab, True)\n"," \n","# create the tokenizer\n","tokenizer = Tokenizer()\n","# fit the tokenizer on the documents\n","docs = negative_lines + positive_lines\n","tokenizer.fit_on_texts(docs)\n"," \n","# encode training data set\n","Xtrain = tokenizer.texts_to_matrix(docs, mode='freq')\n","print(Xtrain.shape)\n"," \n","# load all test reviews\n","positive_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/pos', vocab, False)\n","negative_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/neg', vocab, False)\n","docs = negative_lines + positive_lines\n","# encode training data set\n","Xtest = tokenizer.texts_to_matrix(docs, mode='freq')\n","print(Xtest.shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1800, 25768)\n","(200, 25768)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8JZEn2s9lYBw"},"source":["Running the example prints both the shape of the encoded training dataset and test dataset with 1,800 and 200 documents respectively, each with the same sized encoding vocabulary (vector length).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-97GgVtJlljn"},"source":["**Sentiment Analysis Models**\n","\n","In this section, we will develop Multilayer Perceptron (MLP) models to classify encoded documents as either positive or negative.\n","\n","The models will be simple feedforward network models with fully connected layers called Dense in the Keras deep learning library.\n","\n","This section is divided into 3 sections:\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-QxF0dLkl4_4"},"source":["**First Sentiment Analysis Model**\n","\n","develop a simple MLP model to predict the sentiment of encoded reviews.\n","\n","The model will have an input layer that equals the number of words in the vocabulary, and in turn the length of the input documents.\n","\n"]},{"cell_type":"code","metadata":{"id":"S3l2KylROC1h","executionInfo":{"status":"ok","timestamp":1601378655934,"user_tz":240,"elapsed":295,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"eadd504b-fa68-4650-df26-707ae2d3e5f1","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["\n","n_words = Xtest.shape[1]\n","n_words\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["25768"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"1WIo4A-wm07z"},"source":["We also need class labels for all of the training and test review data. We loaded and encoded these the reviews deterministically (negative, then positive), so we can specify the labels directly, as follows:"]},{"cell_type":"code","metadata":{"id":"hWh_EOP6nEGU","executionInfo":{"status":"ok","timestamp":1601378897539,"user_tz":240,"elapsed":260,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"f7a7168f-14b5-4b5b-c145-f41130e92e05","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import numpy as np\n","ytrain = np.array([0 for _ in range(900)] + [1 for _ in range(900)])\n","ytest = np.array([0 for _ in range(100)] + [1 for _ in range(100)])\n","ytrain.shape, ytest.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1800,), (200,))"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"hZ93gAeRnv8J"},"source":["We can now define the network.\n","\n","All model configuration was found with very little trial and error and should not be considered tuned for this problem.\n","\n","We will use a single hidden layer with 50 neurons and a rectified linear activation function. The output layer is a single neuron with a sigmoid activation function for predicting 0 for negative and 1 for positive reviews.\n","\n","The network will be trained using the efficient Adam implementation of gradient descent and the binary cross entropy loss function, suited to binary classification problems. We will keep track of accuracy when training and evaluating the model.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"NMM6uIyznxAX"},"source":["from keras.models import Sequential\n","from keras.layers import Activation, Dense\n","\n","# define network\n","model = Sequential()\n","model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","# compile network\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"swnMR0yWo9Su"},"source":["Next, we can fit the model on the training data; in this case, the model is small and is easily fit in 50 epochs.\n","\n"]},{"cell_type":"code","metadata":{"id":"oXqOgNtAo-R-","executionInfo":{"status":"ok","timestamp":1601379294589,"user_tz":240,"elapsed":35043,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"db07e6bc-4f68-459b-927e-eae78d8a13a9","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# fit network\n","model.fit(Xtrain, ytrain, epochs=50, verbose=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","57/57 - 1s - loss: 0.6922 - accuracy: 0.5111\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6858 - accuracy: 0.8750\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6718 - accuracy: 0.8694\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6481 - accuracy: 0.8639\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6176 - accuracy: 0.9278\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5817 - accuracy: 0.9372\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5414 - accuracy: 0.9478\n","Epoch 8/50\n","57/57 - 1s - loss: 0.5002 - accuracy: 0.9522\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4600 - accuracy: 0.9544\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4206 - accuracy: 0.9611\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3832 - accuracy: 0.9650\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3488 - accuracy: 0.9706\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3177 - accuracy: 0.9761\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2896 - accuracy: 0.9789\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2630 - accuracy: 0.9828\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2404 - accuracy: 0.9856\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2191 - accuracy: 0.9878\n","Epoch 18/50\n","57/57 - 1s - loss: 0.2003 - accuracy: 0.9911\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1828 - accuracy: 0.9917\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1673 - accuracy: 0.9928\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1531 - accuracy: 0.9944\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1405 - accuracy: 0.9950\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1293 - accuracy: 0.9956\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1190 - accuracy: 0.9961\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1098 - accuracy: 0.9978\n","Epoch 26/50\n","57/57 - 1s - loss: 0.1009 - accuracy: 0.9972\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0931 - accuracy: 0.9978\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0860 - accuracy: 0.9989\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0797 - accuracy: 0.9989\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0739 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0684 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0634 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0591 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0549 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0511 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0477 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0445 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0416 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0389 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0365 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0341 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0320 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0300 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0283 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0266 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0250 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0236 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0222 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0209 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0198 - accuracy: 1.0000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fbd6f03b588>"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"vOsCwslgpQUC"},"source":["Finally, once the model is trained, we can evaluate its performance by making predictions in the test dataset and printing the accuracy.\n","\n"]},{"cell_type":"code","metadata":{"id":"vtYlDvH4pVEP","executionInfo":{"status":"ok","timestamp":1601379369558,"user_tz":240,"elapsed":444,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"019efbf5-2442-47a2-8ff8-edcbd49a4290","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# evaluate\n","loss, acc = model.evaluate(Xtest, ytest, verbose=0)\n","print('Test Accuracy: %f' % (acc*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test Accuracy: 91.000003\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dTfliWR5qKmM","executionInfo":{"status":"ok","timestamp":1601379679483,"user_tz":240,"elapsed":40872,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"9e98d034-e998-4018-8726-683197e7f978","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from numpy import array\n","from string import punctuation\n","from os import listdir\n","from collections import Counter\n","from nltk.corpus import stopwords\n","from keras.preprocessing.text import Tokenizer\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n"," \n","# load doc into memory\n","def load_doc(filename):\n","\t# open the file as read only\n","\tfile = open(filename, 'r')\n","\t# read all text\n","\ttext = file.read()\n","\t# close the file\n","\tfile.close()\n","\treturn text\n"," \n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","\t# split into tokens by white space\n","\ttokens = doc.split()\n","\t# remove punctuation from each token\n","\ttable = str.maketrans('', '', punctuation)\n","\ttokens = [w.translate(table) for w in tokens]\n","\t# remove remaining tokens that are not alphabetic\n","\ttokens = [word for word in tokens if word.isalpha()]\n","\t# filter out stop words\n","\tstop_words = set(stopwords.words('english'))\n","\ttokens = [w for w in tokens if not w in stop_words]\n","\t# filter out short tokens\n","\ttokens = [word for word in tokens if len(word) > 1]\n","\treturn tokens\n"," \n","# load doc, clean and return line of tokens\n","def doc_to_line(filename, vocab):\n","\t# load the doc\n","\tdoc = load_doc(filename)\n","\t# clean doc\n","\ttokens = clean_doc(doc)\n","\t# filter by vocab\n","\ttokens = [w for w in tokens if w in vocab]\n","\treturn ' '.join(tokens)\n"," \n","# load all docs in a directory\n","def process_docs(directory, vocab, is_trian):\n","\tlines = list()\n","\t# walk through all files in the folder\n","\tfor filename in listdir(directory):\n","\t\t# skip any reviews in the test set\n","\t\tif is_trian and filename.startswith('cv9'):\n","\t\t\tcontinue\n","\t\tif not is_trian and not filename.startswith('cv9'):\n","\t\t\tcontinue\n","\t\t# create the full path of the file to open\n","\t\tpath = directory + '/' + filename\n","\t\t# load and clean the doc\n","\t\tline = doc_to_line(path, vocab)\n","\t\t# add to list\n","\t\tlines.append(line)\n","\treturn lines\n"," \n","# load the vocabulary\n","vocab_filename = '/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = vocab.split()\n","vocab = set(vocab)\n","# load all training reviews\n","positive_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/pos', vocab, True)\n","negative_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/neg', vocab, True)\n"," \n","# create the tokenizer\n","tokenizer = Tokenizer()\n","# fit the tokenizer on the documents\n","docs = negative_lines + positive_lines\n","tokenizer.fit_on_texts(docs)\n","# encode training data set\n","Xtrain = tokenizer.texts_to_matrix(docs, mode='freq')\n","ytrain = array([0 for _ in range(900)] + [1 for _ in range(900)])\n"," \n","# load all test reviews\n","positive_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/pos', vocab, False)\n","negative_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/neg', vocab, False)\n","docs = negative_lines + positive_lines\n","# encode training data set\n","Xtest = tokenizer.texts_to_matrix(docs, mode='freq')\n","ytest = array([0 for _ in range(100)] + [1 for _ in range(100)])\n"," \n","n_words = Xtest.shape[1]\n","# define network\n","model = Sequential()\n","model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","# compile network\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","# fit network\n","model.fit(Xtrain, ytrain, epochs=50, verbose=2)\n","# evaluate\n","loss, acc = model.evaluate(Xtest, ytest, verbose=0)\n","print('Test Accuracy: %f' % (acc*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","57/57 - 1s - loss: 0.6917 - accuracy: 0.5533\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6822 - accuracy: 0.5872\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6656 - accuracy: 0.7189\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6395 - accuracy: 0.8250\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6043 - accuracy: 0.9172\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5636 - accuracy: 0.9450\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5181 - accuracy: 0.9500\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4725 - accuracy: 0.9556\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4277 - accuracy: 0.9628\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3865 - accuracy: 0.9678\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3492 - accuracy: 0.9683\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3136 - accuracy: 0.9767\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2820 - accuracy: 0.9817\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2540 - accuracy: 0.9856\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2292 - accuracy: 0.9894\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2065 - accuracy: 0.9911\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1867 - accuracy: 0.9922\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1689 - accuracy: 0.9939\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1535 - accuracy: 0.9933\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1385 - accuracy: 0.9956\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1269 - accuracy: 0.9983\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1152 - accuracy: 0.9972\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1051 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0962 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0877 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0805 - accuracy: 0.9989\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0740 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0680 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0625 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0579 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0537 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0494 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0459 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0424 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0393 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0366 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0342 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0318 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0297 - accuracy: 1.0000\n","Epoch 40/50\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0260 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0243 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0228 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0214 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0202 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0189 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0178 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0168 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0158 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0150 - accuracy: 1.0000\n","Test Accuracy: 90.499997\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SLmwwDEkq3gp"},"source":["Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n","\n","Running the example, we can see that the model easily fits the training data within the 50 epochs, achieving 100% accuracy.\n","\n","\n","Evaluating the model on the test dataset, we can see that model does well, achieving an accuracy of above 90%, well within the ballpark of low-to-mid 80s seen in the original paper.\n","\n","Although, it is important to note that this is not an apples-to-apples comparison, as the original paper used 10-fold cross-validation to estimate model skill instead of a single train/test split.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"K_vzJQLEri1l"},"source":["**Comparing Word Scoring Methods**\n","\n","The texts_to_matrix() function for the Tokenizer in the Keras API provides 4 different methods for scoring words; they are:\n","\n","**“binary” Where words are marked as present (1) or absent (0)**.\n","\n","**“count” Where the occurrence count for each word is marked as an integer.**\n","\n","**“tfidf” Where each word is scored based on their frequency, where words that are common across all documents are penalized.**\n","\n","**“freq” Where words are scored based on their frequency of occurrence within the document.**\n","\n","We can evaluate the skill of the model developed in the previous section fit using each of the 4 supported word scoring modes.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PgRZRyBPsiFh"},"source":["This first involves the development of a function to create an encoding of the loaded documents based on a chosen scoring model. The function creates the tokenizer, fits it on the training documents, then creates the train and test encodings using the chosen model. The function prepare_data() implements this behavior given lists of train and test documents.\n","\n"]},{"cell_type":"code","metadata":{"id":"9hXQN2REs1xk"},"source":["# prepare bag of words encoding of docs\n","def prepare_data(train_docs, test_docs, mode):\n","\t# create the tokenizer\n","\ttokenizer = Tokenizer()\n","\t# fit the tokenizer on the documents\n","\ttokenizer.fit_on_texts(train_docs)\n","\t# encode training data set\n","\tXtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n","\t# encode training data set\n","\tXtest = tokenizer.texts_to_matrix(test_docs, mode=mode)\n","\treturn Xtrain, Xtest"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vKEpmm1ws_5q"},"source":["We also need a function to evaluate the MLP given a specific encoding of the data.\n","\n","\n","Because** neural networks are stochastic**, they *can produce different results when the same model is fit on the same data*. This **is mainly because of the random initial weights and the shuffling of patterns during mini-batch gradient descent**. Th*is means that any one scoring of a model is unreliable and we should estimate model skill based on an average of multiple runs.*\n","\n","\n","\n","The function below, named evaluate_mode(), takes encoded documents and evaluates the MLP by training it on the train set and estimating skill **on the test set 30 times and returns a list of the accuracy scores** across all of these runs.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"AyZAZoyAtEPj"},"source":["# evaluate a neural network model\n","def evaluate_mode(Xtrain, ytrain, Xtest, ytest):\n","\tscores = list()\n","\tn_repeats = 30\n","\tn_words = Xtest.shape[1]\n","\tfor i in range(n_repeats):\n","\t\t# define network\n","\t\tmodel = Sequential()\n","\t\tmodel.add(Dense(50, input_shape=(n_words,), activation='relu'))\n","\t\tmodel.add(Dense(1, activation='sigmoid'))\n","\t\t# compile network\n","\t\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\t\t# fit network\n","\t\tmodel.fit(Xtrain, ytrain, epochs=50, verbose=2)\n","\t\t# evaluate\n","\t\tloss, acc = model.evaluate(Xtest, ytest, verbose=0)\n","\t\tscores.append(acc)\n","\t\tprint('%d accuracy: %s' % ((i+1), acc))\n","\treturn scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7tn8eyxytEZ4","executionInfo":{"status":"ok","timestamp":1601381715680,"user_tz":240,"elapsed":950421,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"b0f115a4-d96a-472b-d912-b5039478d104","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["evaluate_mode(Xtrain, ytrain, Xtest, ytest)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","57/57 - 1s - loss: 0.6916 - accuracy: 0.5928\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6819 - accuracy: 0.7683\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6629 - accuracy: 0.9022\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6344 - accuracy: 0.8878\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5972 - accuracy: 0.9272\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5554 - accuracy: 0.9378\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5097 - accuracy: 0.9417\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4651 - accuracy: 0.9561\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4213 - accuracy: 0.9572\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3809 - accuracy: 0.9639\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3435 - accuracy: 0.9711\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3095 - accuracy: 0.9733\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2790 - accuracy: 0.9811\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2512 - accuracy: 0.9856\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2268 - accuracy: 0.9878\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2048 - accuracy: 0.9906\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1853 - accuracy: 0.9906\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1680 - accuracy: 0.9928\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1524 - accuracy: 0.9950\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1386 - accuracy: 0.9950\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1260 - accuracy: 0.9967\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1147 - accuracy: 0.9972\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1049 - accuracy: 0.9967\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0957 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0876 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0804 - accuracy: 0.9989\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0737 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0679 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0629 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0576 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0536 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0492 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0457 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0423 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0393 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0365 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0341 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0317 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0297 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0278 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0259 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0243 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0227 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0213 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0201 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0189 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0178 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0168 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0158 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0149 - accuracy: 1.0000\n","1 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6922 - accuracy: 0.5644\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6852 - accuracy: 0.7189\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6701 - accuracy: 0.8717\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6460 - accuracy: 0.8544\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6151 - accuracy: 0.9072\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5774 - accuracy: 0.9417\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5369 - accuracy: 0.9444\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4946 - accuracy: 0.9517\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4544 - accuracy: 0.9517\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4138 - accuracy: 0.9594\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3766 - accuracy: 0.9644\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3423 - accuracy: 0.9689\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3105 - accuracy: 0.9744\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2819 - accuracy: 0.9789\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2562 - accuracy: 0.9839\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2330 - accuracy: 0.9872\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2121 - accuracy: 0.9883\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1930 - accuracy: 0.9900\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1766 - accuracy: 0.9928\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1607 - accuracy: 0.9928\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1469 - accuracy: 0.9944\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1346 - accuracy: 0.9961\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1233 - accuracy: 0.9961\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1133 - accuracy: 0.9972\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1040 - accuracy: 0.9978\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0956 - accuracy: 0.9983\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0880 - accuracy: 0.9983\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0814 - accuracy: 0.9994\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0753 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0698 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0646 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0600 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0554 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0515 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0480 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0448 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0416 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0389 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0363 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0341 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0318 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0299 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0280 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0263 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0247 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0233 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0219 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0206 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0195 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0184 - accuracy: 1.0000\n","2 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6926 - accuracy: 0.4989\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6875 - accuracy: 0.5933\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6778 - accuracy: 0.5989\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6619 - accuracy: 0.6544\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6407 - accuracy: 0.7678\n","Epoch 6/50\n","57/57 - 1s - loss: 0.6152 - accuracy: 0.8178\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5864 - accuracy: 0.8633\n","Epoch 8/50\n","57/57 - 1s - loss: 0.5553 - accuracy: 0.9128\n","Epoch 9/50\n","57/57 - 1s - loss: 0.5227 - accuracy: 0.9361\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4891 - accuracy: 0.9450\n","Epoch 11/50\n","57/57 - 1s - loss: 0.4561 - accuracy: 0.9650\n","Epoch 12/50\n","57/57 - 1s - loss: 0.4238 - accuracy: 0.9667\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3923 - accuracy: 0.9717\n","Epoch 14/50\n","57/57 - 1s - loss: 0.3638 - accuracy: 0.9750\n","Epoch 15/50\n","57/57 - 1s - loss: 0.3353 - accuracy: 0.9794\n","Epoch 16/50\n","57/57 - 1s - loss: 0.3090 - accuracy: 0.9844\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2845 - accuracy: 0.9867\n","Epoch 18/50\n","57/57 - 1s - loss: 0.2621 - accuracy: 0.9889\n","Epoch 19/50\n","57/57 - 1s - loss: 0.2415 - accuracy: 0.9889\n","Epoch 20/50\n","57/57 - 1s - loss: 0.2226 - accuracy: 0.9922\n","Epoch 21/50\n","57/57 - 1s - loss: 0.2057 - accuracy: 0.9933\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1898 - accuracy: 0.9933\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1753 - accuracy: 0.9939\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1620 - accuracy: 0.9950\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1500 - accuracy: 0.9961\n","Epoch 26/50\n","57/57 - 1s - loss: 0.1388 - accuracy: 0.9961\n","Epoch 27/50\n","57/57 - 1s - loss: 0.1287 - accuracy: 0.9967\n","Epoch 28/50\n","57/57 - 1s - loss: 0.1194 - accuracy: 0.9983\n","Epoch 29/50\n","57/57 - 1s - loss: 0.1109 - accuracy: 0.9983\n","Epoch 30/50\n","57/57 - 1s - loss: 0.1031 - accuracy: 0.9989\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0960 - accuracy: 0.9994\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0895 - accuracy: 0.9994\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0833 - accuracy: 0.9994\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0777 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0726 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0679 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0637 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0594 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0558 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0522 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0491 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0461 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0433 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0408 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0385 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0362 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0341 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0322 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0304 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0288 - accuracy: 1.0000\n","3 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6911 - accuracy: 0.6617\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6782 - accuracy: 0.7928\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6544 - accuracy: 0.9033\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6192 - accuracy: 0.9061\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5736 - accuracy: 0.9394\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5262 - accuracy: 0.9406\n","Epoch 7/50\n","57/57 - 1s - loss: 0.4743 - accuracy: 0.9511\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4254 - accuracy: 0.9578\n","Epoch 9/50\n","57/57 - 1s - loss: 0.3796 - accuracy: 0.9617\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3381 - accuracy: 0.9694\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3008 - accuracy: 0.9739\n","Epoch 12/50\n","57/57 - 1s - loss: 0.2673 - accuracy: 0.9828\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2385 - accuracy: 0.9856\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2124 - accuracy: 0.9883\n","Epoch 15/50\n","57/57 - 1s - loss: 0.1897 - accuracy: 0.9906\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1700 - accuracy: 0.9922\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1524 - accuracy: 0.9933\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1365 - accuracy: 0.9950\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1229 - accuracy: 0.9967\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1108 - accuracy: 0.9978\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1005 - accuracy: 0.9978\n","Epoch 22/50\n","57/57 - 1s - loss: 0.0906 - accuracy: 0.9978\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0820 - accuracy: 0.9989\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0744 - accuracy: 0.9994\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0679 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0622 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0568 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0519 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0476 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0438 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0403 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0371 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0344 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0318 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0295 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0275 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0256 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0237 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0221 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0206 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0193 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0180 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0169 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0159 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0149 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0140 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0132 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0124 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0117 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0110 - accuracy: 1.0000\n","4 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6918 - accuracy: 0.5717\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6824 - accuracy: 0.8233\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6649 - accuracy: 0.9050\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6385 - accuracy: 0.9072\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6044 - accuracy: 0.9144\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5649 - accuracy: 0.9306\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5219 - accuracy: 0.9478\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4774 - accuracy: 0.9528\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4343 - accuracy: 0.9606\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3934 - accuracy: 0.9628\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3557 - accuracy: 0.9656\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3211 - accuracy: 0.9750\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2903 - accuracy: 0.9750\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2616 - accuracy: 0.9828\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2365 - accuracy: 0.9850\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2140 - accuracy: 0.9883\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1951 - accuracy: 0.9906\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1765 - accuracy: 0.9922\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1599 - accuracy: 0.9933\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1459 - accuracy: 0.9944\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1327 - accuracy: 0.9950\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1213 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1104 - accuracy: 0.9961\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1013 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0928 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0852 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0783 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0720 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0666 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0613 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0567 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0524 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0487 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0451 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0421 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0392 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0363 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0339 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0317 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0296 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0276 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0260 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0244 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0228 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0214 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0202 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0190 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0179 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0169 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0159 - accuracy: 1.0000\n","5 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6918 - accuracy: 0.5811\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6838 - accuracy: 0.8639\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6668 - accuracy: 0.8544\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6399 - accuracy: 0.9144\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6049 - accuracy: 0.9394\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5649 - accuracy: 0.9383\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5213 - accuracy: 0.9444\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4764 - accuracy: 0.9522\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4333 - accuracy: 0.9594\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3938 - accuracy: 0.9617\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3555 - accuracy: 0.9644\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3212 - accuracy: 0.9761\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2908 - accuracy: 0.9767\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2630 - accuracy: 0.9817\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2374 - accuracy: 0.9850\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2153 - accuracy: 0.9878\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1956 - accuracy: 0.9894\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1775 - accuracy: 0.9911\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1612 - accuracy: 0.9939\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1464 - accuracy: 0.9944\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1337 - accuracy: 0.9950\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1219 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1121 - accuracy: 0.9967\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1022 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0937 - accuracy: 0.9978\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0860 - accuracy: 0.9983\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0792 - accuracy: 0.9994\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0729 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0671 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0619 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0574 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0532 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0491 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0457 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0424 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0394 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0368 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0343 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0320 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0299 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0280 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0263 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0247 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0231 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0217 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0204 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0192 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0181 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0171 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0162 - accuracy: 1.0000\n","6 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6918 - accuracy: 0.5528\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6828 - accuracy: 0.8267\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6660 - accuracy: 0.7644\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6388 - accuracy: 0.8806\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6048 - accuracy: 0.9106\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5636 - accuracy: 0.9456\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5193 - accuracy: 0.9517\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4751 - accuracy: 0.9544\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4320 - accuracy: 0.9594\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3913 - accuracy: 0.9644\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3539 - accuracy: 0.9689\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3195 - accuracy: 0.9767\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2886 - accuracy: 0.9794\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2600 - accuracy: 0.9839\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2350 - accuracy: 0.9872\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2128 - accuracy: 0.9894\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1925 - accuracy: 0.9906\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1752 - accuracy: 0.9928\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1588 - accuracy: 0.9939\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1443 - accuracy: 0.9950\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1312 - accuracy: 0.9967\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1201 - accuracy: 0.9961\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1098 - accuracy: 0.9972\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1003 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0919 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0843 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0777 - accuracy: 0.9994\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0714 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0659 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0607 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0562 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0521 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0481 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0447 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0415 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0387 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0361 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0335 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0314 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0293 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0275 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0258 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0241 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0226 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0213 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0200 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0189 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0178 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0168 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0158 - accuracy: 1.0000\n","7 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6915 - accuracy: 0.5383\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6827 - accuracy: 0.7589\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6651 - accuracy: 0.8656\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6398 - accuracy: 0.8983\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6067 - accuracy: 0.9267\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5679 - accuracy: 0.9372\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5256 - accuracy: 0.9456\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4832 - accuracy: 0.9506\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4415 - accuracy: 0.9578\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4010 - accuracy: 0.9600\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3626 - accuracy: 0.9661\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3304 - accuracy: 0.9706\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2979 - accuracy: 0.9789\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2698 - accuracy: 0.9839\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2453 - accuracy: 0.9817\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2226 - accuracy: 0.9844\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2017 - accuracy: 0.9889\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1833 - accuracy: 0.9911\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1667 - accuracy: 0.9928\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1520 - accuracy: 0.9939\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1385 - accuracy: 0.9944\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1265 - accuracy: 0.9956\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1163 - accuracy: 0.9972\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1064 - accuracy: 0.9967\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0975 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0896 - accuracy: 0.9978\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0826 - accuracy: 0.9983\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0759 - accuracy: 0.9983\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0699 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0648 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0597 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0554 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0513 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0477 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0443 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0412 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0385 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0358 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0336 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0313 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0293 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0274 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0258 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0242 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0227 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0214 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0201 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0190 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0179 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0169 - accuracy: 1.0000\n","8 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6923 - accuracy: 0.4950\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6864 - accuracy: 0.5994\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6747 - accuracy: 0.6889\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6551 - accuracy: 0.8000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6272 - accuracy: 0.9100\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5937 - accuracy: 0.9144\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5561 - accuracy: 0.9461\n","Epoch 8/50\n","57/57 - 1s - loss: 0.5171 - accuracy: 0.9483\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4769 - accuracy: 0.9578\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4390 - accuracy: 0.9600\n","Epoch 11/50\n","57/57 - 1s - loss: 0.4016 - accuracy: 0.9667\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3667 - accuracy: 0.9739\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3355 - accuracy: 0.9756\n","Epoch 14/50\n","57/57 - 1s - loss: 0.3057 - accuracy: 0.9783\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2793 - accuracy: 0.9828\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2550 - accuracy: 0.9844\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2338 - accuracy: 0.9872\n","Epoch 18/50\n","57/57 - 1s - loss: 0.2133 - accuracy: 0.9900\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1954 - accuracy: 0.9917\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1792 - accuracy: 0.9911\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1644 - accuracy: 0.9933\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1508 - accuracy: 0.9956\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1387 - accuracy: 0.9961\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1277 - accuracy: 0.9967\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1177 - accuracy: 0.9967\n","Epoch 26/50\n","57/57 - 1s - loss: 0.1087 - accuracy: 0.9967\n","Epoch 27/50\n","57/57 - 1s - loss: 0.1007 - accuracy: 0.9983\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0930 - accuracy: 0.9989\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0861 - accuracy: 0.9989\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0801 - accuracy: 0.9989\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0741 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0690 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0640 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0597 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0557 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0519 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0485 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0454 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0424 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0398 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0373 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0350 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0329 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0309 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0290 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0273 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0258 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0243 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0229 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0217 - accuracy: 1.0000\n","9 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6918 - accuracy: 0.5411\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6820 - accuracy: 0.7572\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6641 - accuracy: 0.8994\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6363 - accuracy: 0.9117\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5980 - accuracy: 0.9328\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5544 - accuracy: 0.9411\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5074 - accuracy: 0.9478\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4610 - accuracy: 0.9489\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4156 - accuracy: 0.9600\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3741 - accuracy: 0.9650\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3356 - accuracy: 0.9689\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3004 - accuracy: 0.9778\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2698 - accuracy: 0.9828\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2424 - accuracy: 0.9861\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2175 - accuracy: 0.9867\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1963 - accuracy: 0.9906\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1768 - accuracy: 0.9911\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1597 - accuracy: 0.9922\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1444 - accuracy: 0.9944\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1311 - accuracy: 0.9950\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1188 - accuracy: 0.9967\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1078 - accuracy: 0.9972\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0981 - accuracy: 0.9983\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0894 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0818 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0751 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0688 - accuracy: 0.9994\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0630 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0580 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0535 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0492 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0454 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0420 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0389 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0362 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0336 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0312 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0291 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0272 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0253 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0237 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0223 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0208 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0195 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0184 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0172 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0162 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0153 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0144 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0136 - accuracy: 1.0000\n","10 accuracy: 0.9150000214576721\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6912 - accuracy: 0.5917\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6803 - accuracy: 0.5733\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6598 - accuracy: 0.8567\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6279 - accuracy: 0.8761\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5877 - accuracy: 0.9244\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5418 - accuracy: 0.9333\n","Epoch 7/50\n","57/57 - 1s - loss: 0.4956 - accuracy: 0.9439\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4477 - accuracy: 0.9533\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4042 - accuracy: 0.9583\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3616 - accuracy: 0.9661\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3234 - accuracy: 0.9722\n","Epoch 12/50\n","57/57 - 1s - loss: 0.2898 - accuracy: 0.9789\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2596 - accuracy: 0.9850\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2326 - accuracy: 0.9850\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2085 - accuracy: 0.9889\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1878 - accuracy: 0.9917\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1689 - accuracy: 0.9928\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1523 - accuracy: 0.9950\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1377 - accuracy: 0.9956\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1241 - accuracy: 0.9967\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1133 - accuracy: 0.9972\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1027 - accuracy: 0.9983\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0934 - accuracy: 0.9989\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0850 - accuracy: 0.9994\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0780 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0709 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0653 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0598 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0548 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0507 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0467 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0432 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0399 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0370 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0343 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0320 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0297 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0277 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0258 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0241 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0225 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0211 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0198 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0186 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0175 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0164 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0155 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0146 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0138 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0129 - accuracy: 1.0000\n","11 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6914 - accuracy: 0.5583\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6810 - accuracy: 0.8494\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6612 - accuracy: 0.8344\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6317 - accuracy: 0.8889\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5941 - accuracy: 0.9394\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5512 - accuracy: 0.9411\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5069 - accuracy: 0.9483\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4614 - accuracy: 0.9511\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4181 - accuracy: 0.9567\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3780 - accuracy: 0.9622\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3405 - accuracy: 0.9683\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3064 - accuracy: 0.9783\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2760 - accuracy: 0.9822\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2488 - accuracy: 0.9856\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2246 - accuracy: 0.9878\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2023 - accuracy: 0.9894\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1834 - accuracy: 0.9911\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1661 - accuracy: 0.9933\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1507 - accuracy: 0.9944\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1367 - accuracy: 0.9956\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1242 - accuracy: 0.9972\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1136 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1035 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0945 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0867 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0792 - accuracy: 0.9989\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0728 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0671 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0616 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0568 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0525 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0484 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0449 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0417 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0387 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0360 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0335 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0312 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0291 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0272 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0255 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0238 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0224 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0210 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0198 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0186 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0175 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0164 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0155 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0146 - accuracy: 1.0000\n","12 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6923 - accuracy: 0.5600\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6870 - accuracy: 0.5994\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6752 - accuracy: 0.7194\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6539 - accuracy: 0.9233\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6256 - accuracy: 0.9006\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5912 - accuracy: 0.9117\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5543 - accuracy: 0.9400\n","Epoch 8/50\n","57/57 - 1s - loss: 0.5149 - accuracy: 0.9494\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4756 - accuracy: 0.9544\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4382 - accuracy: 0.9583\n","Epoch 11/50\n","57/57 - 1s - loss: 0.4022 - accuracy: 0.9628\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3678 - accuracy: 0.9728\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3376 - accuracy: 0.9717\n","Epoch 14/50\n","57/57 - 1s - loss: 0.3084 - accuracy: 0.9772\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2823 - accuracy: 0.9817\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2581 - accuracy: 0.9856\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2365 - accuracy: 0.9867\n","Epoch 18/50\n","57/57 - 1s - loss: 0.2172 - accuracy: 0.9878\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1988 - accuracy: 0.9906\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1828 - accuracy: 0.9928\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1679 - accuracy: 0.9933\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1552 - accuracy: 0.9939\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1425 - accuracy: 0.9961\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1313 - accuracy: 0.9956\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1211 - accuracy: 0.9967\n","Epoch 26/50\n","57/57 - 1s - loss: 0.1120 - accuracy: 0.9972\n","Epoch 27/50\n","57/57 - 1s - loss: 0.1035 - accuracy: 0.9972\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0960 - accuracy: 0.9978\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0889 - accuracy: 0.9983\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0827 - accuracy: 0.9983\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0767 - accuracy: 0.9994\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0713 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0664 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0619 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0576 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0537 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0504 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0471 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0440 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0412 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0387 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0363 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0342 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0320 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0302 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0285 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0268 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0252 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0239 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0225 - accuracy: 1.0000\n","13 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6914 - accuracy: 0.5567\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6814 - accuracy: 0.8000\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6618 - accuracy: 0.9106\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6310 - accuracy: 0.9172\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5886 - accuracy: 0.9189\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5403 - accuracy: 0.9400\n","Epoch 7/50\n","57/57 - 1s - loss: 0.4889 - accuracy: 0.9450\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4396 - accuracy: 0.9500\n","Epoch 9/50\n","57/57 - 1s - loss: 0.3921 - accuracy: 0.9594\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3497 - accuracy: 0.9672\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3111 - accuracy: 0.9717\n","Epoch 12/50\n","57/57 - 1s - loss: 0.2773 - accuracy: 0.9794\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2466 - accuracy: 0.9850\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2202 - accuracy: 0.9883\n","Epoch 15/50\n","57/57 - 1s - loss: 0.1975 - accuracy: 0.9878\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1758 - accuracy: 0.9922\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1582 - accuracy: 0.9928\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1421 - accuracy: 0.9944\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1278 - accuracy: 0.9961\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1154 - accuracy: 0.9961\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1046 - accuracy: 0.9972\n","Epoch 22/50\n","57/57 - 1s - loss: 0.0946 - accuracy: 0.9983\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0856 - accuracy: 0.9989\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0781 - accuracy: 0.9994\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0710 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0648 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0593 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0544 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0500 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0459 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0422 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0390 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0360 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0335 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0309 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0287 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0268 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0249 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0232 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0216 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0203 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0189 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0178 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0166 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0156 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0147 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0138 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0130 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0123 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0116 - accuracy: 1.0000\n","14 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6920 - accuracy: 0.5717\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6842 - accuracy: 0.8406\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6697 - accuracy: 0.8817\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6464 - accuracy: 0.9239\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6163 - accuracy: 0.9194\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5799 - accuracy: 0.9400\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5394 - accuracy: 0.9439\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4996 - accuracy: 0.9456\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4577 - accuracy: 0.9550\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4186 - accuracy: 0.9622\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3814 - accuracy: 0.9644\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3474 - accuracy: 0.9672\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3162 - accuracy: 0.9750\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2874 - accuracy: 0.9783\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2625 - accuracy: 0.9833\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2382 - accuracy: 0.9844\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2173 - accuracy: 0.9883\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1983 - accuracy: 0.9911\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1817 - accuracy: 0.9911\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1658 - accuracy: 0.9922\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1518 - accuracy: 0.9928\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1391 - accuracy: 0.9939\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1278 - accuracy: 0.9956\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1179 - accuracy: 0.9961\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1083 - accuracy: 0.9972\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0997 - accuracy: 0.9967\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0919 - accuracy: 0.9983\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0849 - accuracy: 0.9983\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0786 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0726 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0674 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0625 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0579 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0539 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0503 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0468 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0437 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0407 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0381 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0357 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0334 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0313 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0294 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0277 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0259 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0244 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0230 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0217 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0205 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0193 - accuracy: 1.0000\n","15 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6915 - accuracy: 0.5861\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6813 - accuracy: 0.8106\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6620 - accuracy: 0.9039\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6329 - accuracy: 0.9222\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5942 - accuracy: 0.9367\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5514 - accuracy: 0.9417\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5043 - accuracy: 0.9456\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4596 - accuracy: 0.9522\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4139 - accuracy: 0.9606\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3734 - accuracy: 0.9650\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3360 - accuracy: 0.9717\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3014 - accuracy: 0.9750\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2716 - accuracy: 0.9739\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2444 - accuracy: 0.9839\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2201 - accuracy: 0.9872\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1979 - accuracy: 0.9894\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1793 - accuracy: 0.9900\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1616 - accuracy: 0.9939\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1462 - accuracy: 0.9950\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1327 - accuracy: 0.9956\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1206 - accuracy: 0.9967\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1097 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1000 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0913 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0835 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0767 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0700 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0647 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0593 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0546 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0505 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0466 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0432 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0400 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0371 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0347 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0322 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0299 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0280 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0261 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0244 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0229 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0215 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0201 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0190 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0178 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0168 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0158 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0149 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0141 - accuracy: 1.0000\n","16 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6913 - accuracy: 0.6122\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6803 - accuracy: 0.7922\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6601 - accuracy: 0.8639\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6285 - accuracy: 0.9256\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5883 - accuracy: 0.9233\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5426 - accuracy: 0.9400\n","Epoch 7/50\n","57/57 - 1s - loss: 0.4941 - accuracy: 0.9472\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4474 - accuracy: 0.9528\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4031 - accuracy: 0.9600\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3609 - accuracy: 0.9667\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3250 - accuracy: 0.9694\n","Epoch 12/50\n","57/57 - 1s - loss: 0.2907 - accuracy: 0.9778\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2603 - accuracy: 0.9828\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2337 - accuracy: 0.9861\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2100 - accuracy: 0.9894\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1890 - accuracy: 0.9917\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1702 - accuracy: 0.9933\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1538 - accuracy: 0.9939\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1387 - accuracy: 0.9956\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1257 - accuracy: 0.9961\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1139 - accuracy: 0.9967\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1039 - accuracy: 0.9978\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0943 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0859 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0784 - accuracy: 0.9994\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0719 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0658 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0603 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0556 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0511 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0470 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0436 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0402 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0372 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0347 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0321 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0299 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0278 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0260 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0242 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0226 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0212 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0199 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0186 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0175 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0165 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0155 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0146 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0138 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0130 - accuracy: 1.0000\n","17 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6919 - accuracy: 0.5489\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6845 - accuracy: 0.7822\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6691 - accuracy: 0.8311\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6428 - accuracy: 0.9206\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6089 - accuracy: 0.9311\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5700 - accuracy: 0.9394\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5284 - accuracy: 0.9489\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4853 - accuracy: 0.9489\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4441 - accuracy: 0.9517\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4037 - accuracy: 0.9594\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3670 - accuracy: 0.9644\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3328 - accuracy: 0.9722\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3020 - accuracy: 0.9778\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2738 - accuracy: 0.9817\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2484 - accuracy: 0.9839\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2260 - accuracy: 0.9872\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2052 - accuracy: 0.9900\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1868 - accuracy: 0.9900\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1707 - accuracy: 0.9922\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1554 - accuracy: 0.9933\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1423 - accuracy: 0.9944\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1300 - accuracy: 0.9956\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1191 - accuracy: 0.9967\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1090 - accuracy: 0.9967\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1003 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0925 - accuracy: 0.9983\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0851 - accuracy: 0.9994\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0784 - accuracy: 0.9994\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0723 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0668 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0620 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0572 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0533 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0495 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0458 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0429 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0399 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0372 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0347 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0325 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0304 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0285 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0268 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0252 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0236 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0222 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0209 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0197 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0187 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0176 - accuracy: 1.0000\n","18 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6916 - accuracy: 0.5611\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6825 - accuracy: 0.7344\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6658 - accuracy: 0.8539\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6378 - accuracy: 0.9200\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6016 - accuracy: 0.9211\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5593 - accuracy: 0.9450\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5145 - accuracy: 0.9478\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4696 - accuracy: 0.9556\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4272 - accuracy: 0.9583\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3860 - accuracy: 0.9661\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3485 - accuracy: 0.9722\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3143 - accuracy: 0.9772\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2840 - accuracy: 0.9806\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2558 - accuracy: 0.9828\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2313 - accuracy: 0.9878\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2091 - accuracy: 0.9894\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1899 - accuracy: 0.9900\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1718 - accuracy: 0.9928\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1561 - accuracy: 0.9944\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1422 - accuracy: 0.9944\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1294 - accuracy: 0.9956\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1182 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1076 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0988 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0904 - accuracy: 0.9978\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0829 - accuracy: 0.9989\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0762 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0699 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0648 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0596 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0552 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0510 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0473 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0438 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0408 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0380 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0354 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0329 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0307 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0287 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0268 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0252 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0236 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0222 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0209 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0196 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0184 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0174 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0164 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0155 - accuracy: 1.0000\n","19 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6913 - accuracy: 0.5406\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6809 - accuracy: 0.6078\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6624 - accuracy: 0.7133\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6354 - accuracy: 0.8333\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5990 - accuracy: 0.8928\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5586 - accuracy: 0.9433\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5155 - accuracy: 0.9450\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4709 - accuracy: 0.9606\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4279 - accuracy: 0.9683\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3878 - accuracy: 0.9689\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3496 - accuracy: 0.9783\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3155 - accuracy: 0.9783\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2843 - accuracy: 0.9844\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2566 - accuracy: 0.9856\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2312 - accuracy: 0.9883\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2090 - accuracy: 0.9900\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1891 - accuracy: 0.9928\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1711 - accuracy: 0.9950\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1553 - accuracy: 0.9944\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1412 - accuracy: 0.9956\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1285 - accuracy: 0.9961\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1172 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1073 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0981 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0896 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0822 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0757 - accuracy: 0.9994\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0697 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0642 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0595 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0548 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0507 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0470 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0435 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0406 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0377 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0351 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0328 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0307 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0286 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0268 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0251 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0235 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0221 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0208 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0195 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0184 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0173 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0164 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0155 - accuracy: 1.0000\n","20 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6915 - accuracy: 0.5394\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6808 - accuracy: 0.7900\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6596 - accuracy: 0.8517\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6277 - accuracy: 0.9183\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5864 - accuracy: 0.9356\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5408 - accuracy: 0.9372\n","Epoch 7/50\n","57/57 - 1s - loss: 0.4944 - accuracy: 0.9383\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4458 - accuracy: 0.9550\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4005 - accuracy: 0.9628\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3592 - accuracy: 0.9661\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3212 - accuracy: 0.9733\n","Epoch 12/50\n","57/57 - 1s - loss: 0.2875 - accuracy: 0.9806\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2584 - accuracy: 0.9828\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2317 - accuracy: 0.9839\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2087 - accuracy: 0.9878\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1860 - accuracy: 0.9906\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1675 - accuracy: 0.9933\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1509 - accuracy: 0.9939\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1370 - accuracy: 0.9950\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1238 - accuracy: 0.9967\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1124 - accuracy: 0.9967\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1019 - accuracy: 0.9978\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0928 - accuracy: 0.9983\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0845 - accuracy: 0.9994\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0773 - accuracy: 0.9994\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0705 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0647 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0594 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0546 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0502 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0465 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0427 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0397 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0366 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0342 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0315 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0295 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0274 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0256 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0239 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0223 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0210 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0196 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0184 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0173 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0163 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0153 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0144 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0136 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0128 - accuracy: 1.0000\n","21 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6917 - accuracy: 0.5956\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6836 - accuracy: 0.7022\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6672 - accuracy: 0.6783\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6419 - accuracy: 0.9078\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6109 - accuracy: 0.9183\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5737 - accuracy: 0.9322\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5335 - accuracy: 0.9489\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4917 - accuracy: 0.9533\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4508 - accuracy: 0.9550\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4117 - accuracy: 0.9633\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3747 - accuracy: 0.9644\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3404 - accuracy: 0.9728\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3093 - accuracy: 0.9772\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2805 - accuracy: 0.9828\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2552 - accuracy: 0.9861\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2316 - accuracy: 0.9872\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2110 - accuracy: 0.9900\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1920 - accuracy: 0.9917\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1750 - accuracy: 0.9928\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1600 - accuracy: 0.9939\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1463 - accuracy: 0.9956\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1337 - accuracy: 0.9961\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1226 - accuracy: 0.9972\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1127 - accuracy: 0.9967\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1035 - accuracy: 0.9978\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0951 - accuracy: 0.9983\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0877 - accuracy: 0.9989\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0810 - accuracy: 0.9994\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0748 - accuracy: 0.9994\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0691 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0642 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0594 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0550 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0513 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0478 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0444 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0414 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0388 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0363 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0338 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0318 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0297 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0279 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0262 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0246 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0232 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0218 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0206 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0194 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0183 - accuracy: 1.0000\n","22 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6915 - accuracy: 0.6478\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6824 - accuracy: 0.6833\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6643 - accuracy: 0.8722\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6351 - accuracy: 0.9089\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5982 - accuracy: 0.9300\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5558 - accuracy: 0.9350\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5101 - accuracy: 0.9439\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4646 - accuracy: 0.9500\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4205 - accuracy: 0.9583\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3801 - accuracy: 0.9611\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3422 - accuracy: 0.9700\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3078 - accuracy: 0.9767\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2770 - accuracy: 0.9800\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2503 - accuracy: 0.9833\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2252 - accuracy: 0.9856\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2037 - accuracy: 0.9906\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1841 - accuracy: 0.9917\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1664 - accuracy: 0.9928\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1513 - accuracy: 0.9939\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1371 - accuracy: 0.9944\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1248 - accuracy: 0.9961\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1141 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1039 - accuracy: 0.9972\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0948 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0866 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0800 - accuracy: 0.9989\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0731 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0672 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0618 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0570 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0529 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0486 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0453 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0418 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0389 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0362 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0336 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0314 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0294 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0274 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0257 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0240 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0225 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0211 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0198 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0186 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0175 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0165 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0156 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0147 - accuracy: 1.0000\n","23 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6914 - accuracy: 0.5811\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6812 - accuracy: 0.7467\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6625 - accuracy: 0.8911\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6354 - accuracy: 0.9050\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6007 - accuracy: 0.9339\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5615 - accuracy: 0.9428\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5194 - accuracy: 0.9489\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4768 - accuracy: 0.9550\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4351 - accuracy: 0.9578\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3962 - accuracy: 0.9628\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3590 - accuracy: 0.9694\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3261 - accuracy: 0.9711\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2953 - accuracy: 0.9794\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2679 - accuracy: 0.9806\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2429 - accuracy: 0.9856\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2205 - accuracy: 0.9894\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2005 - accuracy: 0.9900\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1828 - accuracy: 0.9917\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1663 - accuracy: 0.9933\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1519 - accuracy: 0.9956\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1386 - accuracy: 0.9967\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1267 - accuracy: 0.9961\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1162 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1065 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0979 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0902 - accuracy: 0.9983\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0827 - accuracy: 0.9989\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0765 - accuracy: 0.9989\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0706 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0652 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0603 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0560 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0519 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0482 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0449 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0419 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0390 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0364 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0340 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0318 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0298 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0280 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0263 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0247 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0232 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0219 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0205 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0194 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0183 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0173 - accuracy: 1.0000\n","24 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6922 - accuracy: 0.4989\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6861 - accuracy: 0.6900\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6725 - accuracy: 0.7422\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6503 - accuracy: 0.8983\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6207 - accuracy: 0.9067\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5863 - accuracy: 0.9300\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5477 - accuracy: 0.9350\n","Epoch 8/50\n","57/57 - 1s - loss: 0.5090 - accuracy: 0.9472\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4691 - accuracy: 0.9561\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4316 - accuracy: 0.9600\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3960 - accuracy: 0.9622\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3611 - accuracy: 0.9683\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3295 - accuracy: 0.9744\n","Epoch 14/50\n","57/57 - 1s - loss: 0.3013 - accuracy: 0.9778\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2756 - accuracy: 0.9789\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2510 - accuracy: 0.9856\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2300 - accuracy: 0.9872\n","Epoch 18/50\n","57/57 - 1s - loss: 0.2102 - accuracy: 0.9878\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1923 - accuracy: 0.9917\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1763 - accuracy: 0.9922\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1625 - accuracy: 0.9928\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1485 - accuracy: 0.9944\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1367 - accuracy: 0.9956\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1259 - accuracy: 0.9961\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1165 - accuracy: 0.9972\n","Epoch 26/50\n","57/57 - 1s - loss: 0.1070 - accuracy: 0.9978\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0990 - accuracy: 0.9972\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0914 - accuracy: 0.9983\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0849 - accuracy: 0.9989\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0786 - accuracy: 0.9994\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0729 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0678 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0630 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0588 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0546 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0510 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0476 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0445 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0416 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0390 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0366 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0343 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0322 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0303 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0284 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0268 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0253 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0239 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0224 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0213 - accuracy: 1.0000\n","25 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6921 - accuracy: 0.5339\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6841 - accuracy: 0.7283\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6664 - accuracy: 0.9039\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6370 - accuracy: 0.9194\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5999 - accuracy: 0.9128\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5561 - accuracy: 0.9428\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5093 - accuracy: 0.9428\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4637 - accuracy: 0.9550\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4193 - accuracy: 0.9561\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3776 - accuracy: 0.9639\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3399 - accuracy: 0.9694\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3065 - accuracy: 0.9728\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2754 - accuracy: 0.9817\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2481 - accuracy: 0.9839\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2236 - accuracy: 0.9861\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2018 - accuracy: 0.9883\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1830 - accuracy: 0.9911\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1653 - accuracy: 0.9922\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1498 - accuracy: 0.9939\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1361 - accuracy: 0.9961\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1236 - accuracy: 0.9956\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1129 - accuracy: 0.9972\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1026 - accuracy: 0.9972\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0938 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0856 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0788 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0723 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0665 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0611 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0564 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0521 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0482 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0446 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0415 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0384 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0358 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0332 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0310 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0290 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0270 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0253 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0237 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0222 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0209 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0196 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0184 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0173 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0163 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0154 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0145 - accuracy: 1.0000\n","26 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6914 - accuracy: 0.5950\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6811 - accuracy: 0.7800\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6615 - accuracy: 0.8267\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6318 - accuracy: 0.8622\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5927 - accuracy: 0.9311\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5494 - accuracy: 0.9394\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5040 - accuracy: 0.9461\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4590 - accuracy: 0.9544\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4156 - accuracy: 0.9594\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3756 - accuracy: 0.9656\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3378 - accuracy: 0.9728\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3040 - accuracy: 0.9772\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2738 - accuracy: 0.9794\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2459 - accuracy: 0.9861\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2218 - accuracy: 0.9900\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2010 - accuracy: 0.9917\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1809 - accuracy: 0.9922\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1639 - accuracy: 0.9922\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1487 - accuracy: 0.9961\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1346 - accuracy: 0.9967\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1225 - accuracy: 0.9961\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1119 - accuracy: 0.9972\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1017 - accuracy: 0.9983\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0933 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0852 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0780 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0715 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0659 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0605 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0560 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0518 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0478 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0444 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0409 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0381 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0354 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0329 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0307 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0287 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0268 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0251 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0235 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0220 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0207 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0194 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0183 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0172 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0162 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0153 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0144 - accuracy: 1.0000\n","27 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6916 - accuracy: 0.5361\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6815 - accuracy: 0.5939\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6634 - accuracy: 0.7494\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6359 - accuracy: 0.8156\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6009 - accuracy: 0.8939\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5599 - accuracy: 0.9328\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5158 - accuracy: 0.9478\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4712 - accuracy: 0.9550\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4275 - accuracy: 0.9617\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3859 - accuracy: 0.9667\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3476 - accuracy: 0.9744\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3130 - accuracy: 0.9822\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2810 - accuracy: 0.9833\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2528 - accuracy: 0.9889\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2275 - accuracy: 0.9911\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2047 - accuracy: 0.9922\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1848 - accuracy: 0.9939\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1666 - accuracy: 0.9944\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1508 - accuracy: 0.9950\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1368 - accuracy: 0.9972\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1247 - accuracy: 0.9972\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1128 - accuracy: 0.9983\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1029 - accuracy: 0.9983\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0937 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0857 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0784 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0718 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0663 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0607 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0560 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0516 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0478 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0442 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0409 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0380 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0353 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0328 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0307 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0285 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0267 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0250 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0234 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0219 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0206 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0193 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0181 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0171 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0161 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0152 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0143 - accuracy: 1.0000\n","28 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6916 - accuracy: 0.5206\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6819 - accuracy: 0.7167\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6646 - accuracy: 0.7950\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6383 - accuracy: 0.8589\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6042 - accuracy: 0.9122\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5662 - accuracy: 0.9300\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5234 - accuracy: 0.9511\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4811 - accuracy: 0.9522\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4398 - accuracy: 0.9578\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3988 - accuracy: 0.9644\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3618 - accuracy: 0.9733\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3275 - accuracy: 0.9789\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2968 - accuracy: 0.9817\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2686 - accuracy: 0.9828\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2434 - accuracy: 0.9867\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2212 - accuracy: 0.9911\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2009 - accuracy: 0.9900\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1821 - accuracy: 0.9900\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1663 - accuracy: 0.9933\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1514 - accuracy: 0.9950\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1381 - accuracy: 0.9961\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1261 - accuracy: 0.9961\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1157 - accuracy: 0.9967\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1060 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0972 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0895 - accuracy: 0.9989\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0822 - accuracy: 0.9994\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0759 - accuracy: 0.9994\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0700 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0647 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0600 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0554 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0516 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0479 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0445 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0416 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0387 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0361 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0337 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0316 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0295 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0277 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0260 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0244 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0229 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0216 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0203 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0192 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0181 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0171 - accuracy: 1.0000\n","29 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6912 - accuracy: 0.5456\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6790 - accuracy: 0.8122\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6595 - accuracy: 0.8894\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6295 - accuracy: 0.9106\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5907 - accuracy: 0.9100\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5453 - accuracy: 0.9417\n","Epoch 7/50\n","57/57 - 1s - loss: 0.4991 - accuracy: 0.9389\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4528 - accuracy: 0.9539\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4067 - accuracy: 0.9622\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3652 - accuracy: 0.9672\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3273 - accuracy: 0.9728\n","Epoch 12/50\n","57/57 - 1s - loss: 0.2932 - accuracy: 0.9767\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2628 - accuracy: 0.9817\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2361 - accuracy: 0.9833\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2122 - accuracy: 0.9883\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1906 - accuracy: 0.9906\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1719 - accuracy: 0.9922\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1546 - accuracy: 0.9933\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1401 - accuracy: 0.9944\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1271 - accuracy: 0.9961\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1148 - accuracy: 0.9961\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1043 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0951 - accuracy: 0.9983\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0866 - accuracy: 0.9989\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0793 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0720 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0664 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0609 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0559 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0516 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0475 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0439 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0406 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0376 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0349 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0324 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0302 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0281 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0263 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0245 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0229 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0215 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0201 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0189 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0177 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0168 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0157 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0148 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0139 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0131 - accuracy: 1.0000\n","30 accuracy: 0.9150000214576721\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.9049999713897705,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9049999713897705,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9150000214576721,\n"," 0.9049999713897705,\n"," 0.9100000262260437,\n"," 0.9049999713897705,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9049999713897705,\n"," 0.9100000262260437,\n"," 0.9049999713897705,\n"," 0.9049999713897705,\n"," 0.9100000262260437,\n"," 0.9049999713897705,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9100000262260437,\n"," 0.9150000214576721]"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"uJoOF-svu6WD"},"source":["We are now ready to evaluate the performance of the 4 different word scoring methods.\n","\n"]},{"cell_type":"code","metadata":{"id":"n8tkY8bBvCOU","executionInfo":{"status":"ok","timestamp":1601420739348,"user_tz":240,"elapsed":4000541,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"7af379e2-3feb-47fc-9225-242da2e8d2a5","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from numpy import array\n","from string import punctuation\n","from os import listdir\n","from collections import Counter\n","from nltk.corpus import stopwords\n","from keras.preprocessing.text import Tokenizer\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from pandas import DataFrame\n","from matplotlib import pyplot\n"," \n","# load doc into memory\n","def load_doc(filename):\n","\t# open the file as read only\n","\tfile = open(filename, 'r')\n","\t# read all text\n","\ttext = file.read()\n","\t# close the file\n","\tfile.close()\n","\treturn text\n"," \n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","\t# split into tokens by white space\n","\ttokens = doc.split()\n","\t# remove punctuation from each token\n","\ttable = str.maketrans('', '', punctuation)\n","\ttokens = [w.translate(table) for w in tokens]\n","\t# remove remaining tokens that are not alphabetic\n","\ttokens = [word for word in tokens if word.isalpha()]\n","\t# filter out stop words\n","\tstop_words = set(stopwords.words('english'))\n","\ttokens = [w for w in tokens if not w in stop_words]\n","\t# filter out short tokens\n","\ttokens = [word for word in tokens if len(word) > 1]\n","\treturn tokens\n"," \n","# load doc, clean and return line of tokens\n","def doc_to_line(filename, vocab):\n","\t# load the doc\n","\tdoc = load_doc(filename)\n","\t# clean doc\n","\ttokens = clean_doc(doc)\n","\t# filter by vocab\n","\ttokens = [w for w in tokens if w in vocab]\n","\treturn ' '.join(tokens)\n"," \n","# load all docs in a directory\n","def process_docs(directory, vocab, is_trian):\n","\tlines = list()\n","\t# walk through all files in the folder\n","\tfor filename in listdir(directory):\n","\t\t# skip any reviews in the test set\n","\t\tif is_trian and filename.startswith('cv9'):\n","\t\t\tcontinue\n","\t\tif not is_trian and not filename.startswith('cv9'):\n","\t\t\tcontinue\n","\t\t# create the full path of the file to open\n","\t\tpath = directory + '/' + filename\n","\t\t# load and clean the doc\n","\t\tline = doc_to_line(path, vocab)\n","\t\t# add to list\n","\t\tlines.append(line)\n","\treturn lines\n"," \n","# evaluate a neural network model\n","def evaluate_mode(Xtrain, ytrain, Xtest, ytest):\n","\tscores = list()\n","\tn_repeats = 30\n","\tn_words = Xtest.shape[1]\n","\tfor i in range(n_repeats):\n","\t\t# define network\n","\t\tmodel = Sequential()\n","\t\tmodel.add(Dense(50, input_shape=(n_words,), activation='relu'))\n","\t\tmodel.add(Dense(1, activation='sigmoid'))\n","\t\t# compile network\n","\t\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\t\t# fit network\n","\t\tmodel.fit(Xtrain, ytrain, epochs=50, verbose=2)\n","\t\t# evaluate\n","\t\tloss, acc = model.evaluate(Xtest, ytest, verbose=0)\n","\t\tscores.append(acc)\n","\t\tprint('%d accuracy: %s' % ((i+1), acc))\n","\treturn scores\n"," \n","# prepare bag of words encoding of docs\n","def prepare_data(train_docs, test_docs, mode):\n","\t# create the tokenizer\n","\ttokenizer = Tokenizer()\n","\t# fit the tokenizer on the documents\n","\ttokenizer.fit_on_texts(train_docs)\n","\t# encode training data set\n","\tXtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n","\t# encode training data set\n","\tXtest = tokenizer.texts_to_matrix(test_docs, mode=mode)\n","\treturn Xtrain, Xtest\n"," \n","# load the vocabulary\n","vocab_filename = '/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/vocab.txt'\n","vocab = load_doc(vocab_filename)\n","vocab = vocab.split()\n","vocab = set(vocab)\n","# load all training reviews\n","positive_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/pos', vocab, True)\n","negative_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/neg', vocab, True)\n","train_docs = negative_lines + positive_lines\n","# load all test reviews\n","positive_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/pos', vocab, False)\n","negative_lines = process_docs('/content/drive/My Drive/AIML_IIT_exe/AIML_HYD_15/Unit 1/txt_sentoken/neg', vocab, False)\n","test_docs = negative_lines + positive_lines\n","# prepare labels\n","ytrain = array([0 for _ in range(900)] + [1 for _ in range(900)])\n","ytest = array([0 for _ in range(100)] + [1 for _ in range(100)])\n"," \n","modes = ['binary', 'count', 'tfidf', 'freq']\n","results = DataFrame()\n","for mode in modes:\n","\t# prepare data for mode\n","\tXtrain, Xtest = prepare_data(train_docs, test_docs, mode)\n","\t# evaluate model on data for mode\n","\tresults[mode] = evaluate_mode(Xtrain, ytrain, Xtest, ytest)\n","# summarize results\n","print(results.describe())\n","# plot results\n","results.boxplot()\n","pyplot.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 31/50\n","57/57 - 1s - loss: 2.4776e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 2.3153e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 2.1557e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 2.0196e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.8847e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.7721e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.6669e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.5674e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.4721e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.3875e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.3108e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.2405e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 1.1744e-05 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 1.1119e-05 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 1.0542e-05 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 1.0012e-05 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 9.5110e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 9.0574e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 8.6067e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 8.2009e-06 - accuracy: 1.0000\n","11 accuracy: 0.8450000286102295\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4979 - accuracy: 0.7644\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0187 - accuracy: 1.0000\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0042 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0020 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 7.7319e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 5.2232e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 3.7284e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 2.7617e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.0773e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 1.6688e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.3146e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.0610e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 8.7598e-05 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 7.4083e-05 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 6.1941e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 5.4488e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 4.7438e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 4.2142e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 3.7182e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 3.2442e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 2.8872e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 2.5979e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 2.3567e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 2.1468e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 1.9688e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 1.8056e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 1.6598e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 1.5354e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 1.4182e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 1.3197e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 1.2270e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 1.1464e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.0720e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.0042e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 9.4276e-06 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 8.8703e-06 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 8.3563e-06 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 7.8971e-06 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 7.4612e-06 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 7.0585e-06 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 6.6888e-06 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 6.3383e-06 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 6.0147e-06 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 5.7165e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 5.4273e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 5.1595e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 4.9040e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 4.5145e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 4.2567e-06 - accuracy: 1.0000\n","12 accuracy: 0.8550000190734863\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4786 - accuracy: 0.7717\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0177 - accuracy: 0.9994\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0041 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 9.2482e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 6.7621e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 5.0420e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.9300e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 3.1333e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.5184e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 2.0693e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.7456e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.4897e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.2854e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 1.1375e-04 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 9.7511e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 8.6267e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 7.6941e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 6.8666e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 6.1695e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 5.5437e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 5.0281e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 4.5672e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 4.1746e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 3.8388e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 3.5204e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 3.2647e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.9910e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.7640e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 2.5805e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 2.3761e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 2.2102e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 2.0603e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.9239e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.8010e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.6829e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.5761e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.4807e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.3941e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.3079e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.2241e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 1.1500e-05 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 1.0792e-05 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 1.0119e-05 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 9.4484e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 8.8650e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 8.3109e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 7.7991e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 7.3196e-06 - accuracy: 1.0000\n","13 accuracy: 0.8600000143051147\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4716 - accuracy: 0.7744\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0181 - accuracy: 1.0000\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0047 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 8.7544e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 6.3444e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.8670e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.8101e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 3.0977e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.4593e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 2.0478e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.7284e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.4749e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.2692e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 1.0975e-04 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 9.5927e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 8.4116e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 7.4329e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 6.6219e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 5.9802e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 5.3293e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 4.7821e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 4.3258e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.9531e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 3.6134e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 3.3024e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.9826e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.7537e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.5506e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 2.3624e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 2.1995e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 2.0508e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.9174e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.7953e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.6857e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.5829e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.4869e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.4009e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.3190e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.2404e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.1714e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 1.1083e-05 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 1.0513e-05 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 9.9436e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 9.4478e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 8.9661e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 8.5129e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 8.1216e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 7.7026e-06 - accuracy: 1.0000\n","14 accuracy: 0.8600000143051147\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4596 - accuracy: 0.7733\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0125 - accuracy: 0.9989\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0031 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 7.7466e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 5.5615e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.1405e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.2168e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.5749e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.1067e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.7547e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.4733e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.2570e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.0888e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 9.5760e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 8.3696e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 7.4140e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 6.6022e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 5.8563e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 5.2624e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.7735e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 4.3216e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 3.9548e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.6053e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 3.3199e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 3.0676e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.8309e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.6268e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.4550e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 2.2811e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 2.1338e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 1.9953e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.8726e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.7582e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.6402e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.5374e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.4452e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.3620e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.2839e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.2122e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.1470e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 1.0865e-05 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 1.0270e-05 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 9.7474e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 9.2431e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 8.7785e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 8.3423e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 7.9346e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 7.5488e-06 - accuracy: 1.0000\n","15 accuracy: 0.8500000238418579\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4656 - accuracy: 0.7700\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0156 - accuracy: 0.9994\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0036 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0018 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 7.7746e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 5.5610e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.2095e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.2644e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.5777e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.0668e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.7244e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.4614e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.2536e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.0830e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 9.4418e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 8.3698e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 7.3991e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 6.6130e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 5.9142e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 5.3606e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.8092e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 4.3888e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 4.0189e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.6868e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 3.3689e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 3.1039e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.8658e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.6513e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.4513e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 2.2757e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 2.1181e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 1.9721e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.8355e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.7160e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.6094e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.5076e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.4168e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.3423e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.2552e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.1868e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.1183e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 1.0573e-05 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 1.0013e-05 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 9.4887e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 8.9953e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 8.5381e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 8.1252e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 7.7008e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 7.3319e-06 - accuracy: 1.0000\n","16 accuracy: 0.8299999833106995\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4526 - accuracy: 0.7783\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0117 - accuracy: 1.0000\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0036 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0019 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 7.6258e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 5.4089e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.1089e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.2013e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.5603e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.0845e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.7274e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.4465e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.2370e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.0714e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 9.3234e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 8.1923e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 7.2646e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 6.4615e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 5.7817e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 5.2065e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.6871e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 4.1992e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 3.8253e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.4961e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 3.2032e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 2.9500e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.7252e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.5277e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.3424e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 2.1792e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 2.0282e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 1.8883e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.7598e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.6440e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.5406e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.4471e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.3554e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.2761e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.2009e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.1286e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.0660e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 1.0070e-05 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 9.5358e-06 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 9.0416e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 8.5770e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 8.1481e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 7.7483e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 7.3793e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 7.0022e-06 - accuracy: 1.0000\n","17 accuracy: 0.8550000190734863\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4870 - accuracy: 0.7639\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0238 - accuracy: 0.9967\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0045 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0020 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 7.9434e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 5.6348e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.1377e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.1448e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.4677e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.0014e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.6636e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.3963e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.1854e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.0239e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 8.8789e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 7.7238e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 6.7330e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 5.8115e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 5.1360e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 4.5637e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.0701e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 3.6349e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 3.2747e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 2.9584e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 2.6856e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 2.4610e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.2382e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.0540e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 1.8910e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 1.7478e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 1.6182e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 1.5052e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.3960e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.2906e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.1974e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.1192e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.0492e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 9.8469e-06 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 9.2627e-06 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 8.7174e-06 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 8.2236e-06 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 7.7658e-06 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 7.3307e-06 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 6.9429e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 6.5699e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 6.2221e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 5.9221e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 5.6072e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 5.3282e-06 - accuracy: 1.0000\n","18 accuracy: 0.875\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4743 - accuracy: 0.7800\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0142 - accuracy: 0.9994\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0036 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0019 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 7.6778e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 5.4603e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.0684e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.1388e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.4263e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 1.9489e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.6154e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.3599e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.1641e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.0028e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 8.7520e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 7.7139e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 6.8089e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 6.0544e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 5.4322e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 4.8981e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.4440e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 4.0472e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 3.6952e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.3882e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 3.1217e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 2.8801e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.6663e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.4717e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.2949e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 2.1400e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 1.9932e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 1.8662e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.7452e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.6381e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.5406e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.4502e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.3663e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.2882e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.2159e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.1496e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.0860e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 1.0282e-05 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 9.7500e-06 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 9.2470e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 8.7861e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 8.3431e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 7.9327e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 7.5468e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 7.1915e-06 - accuracy: 1.0000\n","19 accuracy: 0.8500000238418579\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4786 - accuracy: 0.7656\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0148 - accuracy: 1.0000\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0037 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0019 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 7.9823e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 5.7708e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.3524e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.3474e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.6561e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.1762e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.8031e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.5164e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.2711e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.1001e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 9.6310e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 8.5372e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 7.5789e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 6.7470e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 6.0475e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 5.4380e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.9071e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 4.4589e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 4.0570e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.7251e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 3.4178e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 3.1434e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.9058e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.6870e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.4962e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 2.3131e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 2.1469e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 2.0053e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.8794e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.7559e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.6483e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.5503e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.4617e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.3790e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.3061e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.2338e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.1687e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 1.1084e-05 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 1.0507e-05 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 1.0017e-05 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 9.4871e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 8.9951e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 8.5483e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 8.1266e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 7.7560e-06 - accuracy: 1.0000\n","20 accuracy: 0.8500000238418579\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4806 - accuracy: 0.7611\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0139 - accuracy: 0.9994\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0039 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0020 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 8.7433e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 6.3039e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.7417e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.6404e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.8995e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.3210e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.9038e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.5810e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.3093e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.1143e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 9.6651e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 8.4824e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 7.4355e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 6.6036e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 5.9254e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 5.3228e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.8209e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 4.3617e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 3.8831e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.5192e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 3.2126e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 2.9431e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.7220e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.4798e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.2901e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 2.1289e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 1.9777e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 1.8431e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.7174e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.6142e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.5080e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.4164e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.3332e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.2573e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.1870e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.1221e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.0626e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 9.8136e-06 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 9.1921e-06 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 8.6566e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 8.2193e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 7.7508e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 7.3536e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 6.9871e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 6.6546e-06 - accuracy: 1.0000\n","21 accuracy: 0.8550000190734863\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4591 - accuracy: 0.7906\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0133 - accuracy: 0.9989\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0036 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0018 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 7.7630e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 5.5303e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.0637e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.1197e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.4941e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.0167e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.6627e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.3941e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.1910e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.0313e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 8.9991e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 7.9123e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 6.9453e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 6.1584e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 5.4911e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 4.9426e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.4745e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 4.0556e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 3.7190e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.3880e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 3.1164e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 2.8685e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.6661e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.4375e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.2538e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 2.0870e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 1.9425e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 1.8107e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.6918e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.5493e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.4510e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.3620e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.2774e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.1984e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.1268e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.0026e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 9.4468e-06 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 8.9448e-06 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 8.4756e-06 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 8.0383e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 7.6394e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 7.2631e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 6.8856e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 6.5431e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 6.2033e-06 - accuracy: 1.0000\n","22 accuracy: 0.8550000190734863\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4752 - accuracy: 0.7722\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0152 - accuracy: 0.9994\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0039 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 8.4855e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 5.7612e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.2090e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.1802e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.4689e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 1.9480e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.5801e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.2983e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.0861e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 9.1430e-05 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 7.8080e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 6.8257e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 5.8738e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 5.1743e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 4.5806e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 4.0923e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 3.6594e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 3.2999e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 2.9926e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 2.7195e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 2.4869e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 2.2813e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.0976e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 1.9378e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 1.7906e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 1.6597e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 1.5270e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 1.4176e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.3082e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.2250e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.1459e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.0135e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 9.5264e-06 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 8.9977e-06 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 8.4944e-06 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 8.0367e-06 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 7.5853e-06 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 7.1760e-06 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 6.8108e-06 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 6.4518e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 6.1292e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 5.8263e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 5.5407e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 5.2753e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 5.0271e-06 - accuracy: 1.0000\n","23 accuracy: 0.8450000286102295\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4704 - accuracy: 0.7678\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0154 - accuracy: 0.9983\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0039 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0020 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 8.7149e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 6.2445e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.6644e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.5915e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.8277e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.2452e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.8238e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.5207e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.2755e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.0697e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 9.1488e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 7.9566e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 6.9410e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 6.1291e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 5.4341e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 4.8206e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.3113e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 3.8687e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 3.5061e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.1927e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 2.9172e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 2.6797e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.4663e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.2740e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.1064e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 1.9551e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 1.8145e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 1.6898e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.5790e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.4778e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.3818e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.2964e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.2144e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.1385e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.0741e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.0097e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 9.5286e-06 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 8.9954e-06 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 8.5168e-06 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 8.0516e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 7.6438e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 7.2345e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 6.8757e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 6.5293e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 6.2069e-06 - accuracy: 1.0000\n","24 accuracy: 0.875\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4703 - accuracy: 0.7717\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0116 - accuracy: 1.0000\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0034 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0018 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 7.8646e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 5.6811e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.2624e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.3161e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.6451e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.1198e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.7534e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.4599e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.2308e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.0439e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 8.9652e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 7.8122e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 6.8895e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 6.1016e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 5.4436e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 4.9004e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.4084e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 4.0199e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 3.6058e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.2950e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 3.0247e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 2.7659e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.5513e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.3517e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.1837e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 2.0352e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 1.8997e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 1.7763e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.6652e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.5681e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.4676e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.3790e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.2993e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.2188e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.1435e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.0737e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.0134e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 9.5894e-06 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 9.0991e-06 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 8.6292e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 8.1991e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 7.8049e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 7.4193e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 7.0604e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 6.7145e-06 - accuracy: 1.0000\n","25 accuracy: 0.8650000095367432\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4550 - accuracy: 0.7733\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0161 - accuracy: 0.9978\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0036 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0018 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 8.1589e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 6.0925e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.7490e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.7971e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 3.0912e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.5736e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 2.1667e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.8528e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.5899e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.3863e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 1.2199e-04 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 1.0780e-04 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 9.6164e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 8.5645e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 7.7027e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 6.9541e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 6.2634e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 5.6975e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 5.2120e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 4.7861e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 4.4152e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 4.0782e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 3.7826e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 3.5136e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 3.2694e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 3.0451e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 2.8382e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 2.6457e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 2.4687e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 2.3092e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 2.1661e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 2.0383e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.9168e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.8032e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.7019e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.6042e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.5305e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 1.4314e-05 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 1.3545e-05 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 1.2779e-05 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 1.2069e-05 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 1.1432e-05 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 1.0854e-05 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 1.0302e-05 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 9.8012e-06 - accuracy: 1.0000\n","26 accuracy: 0.8500000238418579\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4664 - accuracy: 0.7700\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0155 - accuracy: 0.9989\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0032 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 9.4667e-04 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 6.4662e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 4.7051e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 3.5875e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 2.7972e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.2257e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 1.7961e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.5011e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.2622e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.0800e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 9.3378e-05 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 8.1543e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 7.1786e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 6.3759e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 5.6790e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 5.0876e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 4.5604e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.1317e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 3.7756e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 3.4576e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.1805e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 2.9322e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 2.7097e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.5126e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.3330e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.1751e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 1.9997e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 1.8619e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 1.7410e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.6319e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.5324e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.4400e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.3551e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.2766e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.2044e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.1385e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.0764e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.0032e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 9.4365e-06 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 8.9139e-06 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 8.4367e-06 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 8.0077e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 7.5961e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 7.2174e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 6.8573e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 6.5224e-06 - accuracy: 1.0000\n","27 accuracy: 0.8650000095367432\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4509 - accuracy: 0.7783\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0179 - accuracy: 0.9983\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0043 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 9.0555e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 6.6669e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 5.0548e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.9697e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 3.1873e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.6189e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 2.1820e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.8535e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.6020e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.3978e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 1.2332e-04 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 1.0946e-04 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 9.6982e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 8.6480e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 7.7540e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 7.0250e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 6.3720e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 5.8012e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 5.3346e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 4.8861e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 4.5190e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 4.1596e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 3.8485e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 3.5688e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 3.3114e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 3.0437e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 2.8528e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 2.6538e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 2.3879e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 2.2395e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 2.1068e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.9855e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.8738e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.7723e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.6769e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.5892e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.5076e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 1.4184e-05 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 1.3387e-05 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 1.2669e-05 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 1.2006e-05 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 1.1462e-05 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 1.0885e-05 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 1.0295e-05 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 9.7946e-06 - accuracy: 1.0000\n","28 accuracy: 0.8550000190734863\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4696 - accuracy: 0.7750\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0153 - accuracy: 0.9989\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0041 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 8.1381e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 5.8884e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.3663e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.4131e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.6464e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.1458e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.7834e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.4981e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.2739e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.1030e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 9.6046e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 8.4793e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 7.5558e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 6.7816e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 6.0982e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 5.5070e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.9952e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 4.5726e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 4.1970e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.8661e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 3.5765e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 3.3155e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 3.0776e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.8742e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.6796e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 2.5078e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 2.3479e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 2.2055e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 2.0734e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.9555e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.8414e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.7374e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.6425e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.5588e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.4711e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.3923e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.3203e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 1.2532e-05 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 1.1821e-05 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 1.1220e-05 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 1.0695e-05 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 1.0180e-05 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 9.7010e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 9.2155e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 8.8044e-06 - accuracy: 1.0000\n","29 accuracy: 0.8600000143051147\n","Epoch 1/50\n","57/57 - 1s - loss: 0.4651 - accuracy: 0.7844\n","Epoch 2/50\n","57/57 - 1s - loss: 0.0145 - accuracy: 0.9994\n","Epoch 3/50\n","57/57 - 1s - loss: 0.0037 - accuracy: 1.0000\n","Epoch 4/50\n","57/57 - 1s - loss: 0.0020 - accuracy: 1.0000\n","Epoch 5/50\n","57/57 - 1s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 6/50\n","57/57 - 1s - loss: 8.6017e-04 - accuracy: 1.0000\n","Epoch 7/50\n","57/57 - 1s - loss: 6.1303e-04 - accuracy: 1.0000\n","Epoch 8/50\n","57/57 - 1s - loss: 4.4772e-04 - accuracy: 1.0000\n","Epoch 9/50\n","57/57 - 1s - loss: 3.3878e-04 - accuracy: 1.0000\n","Epoch 10/50\n","57/57 - 1s - loss: 2.6569e-04 - accuracy: 1.0000\n","Epoch 11/50\n","57/57 - 1s - loss: 2.1358e-04 - accuracy: 1.0000\n","Epoch 12/50\n","57/57 - 1s - loss: 1.7633e-04 - accuracy: 1.0000\n","Epoch 13/50\n","57/57 - 1s - loss: 1.4922e-04 - accuracy: 1.0000\n","Epoch 14/50\n","57/57 - 1s - loss: 1.2796e-04 - accuracy: 1.0000\n","Epoch 15/50\n","57/57 - 1s - loss: 1.0904e-04 - accuracy: 1.0000\n","Epoch 16/50\n","57/57 - 1s - loss: 9.5579e-05 - accuracy: 1.0000\n","Epoch 17/50\n","57/57 - 1s - loss: 8.4688e-05 - accuracy: 1.0000\n","Epoch 18/50\n","57/57 - 1s - loss: 7.5321e-05 - accuracy: 1.0000\n","Epoch 19/50\n","57/57 - 1s - loss: 6.7421e-05 - accuracy: 1.0000\n","Epoch 20/50\n","57/57 - 1s - loss: 6.0785e-05 - accuracy: 1.0000\n","Epoch 21/50\n","57/57 - 1s - loss: 5.4318e-05 - accuracy: 1.0000\n","Epoch 22/50\n","57/57 - 1s - loss: 4.9419e-05 - accuracy: 1.0000\n","Epoch 23/50\n","57/57 - 1s - loss: 4.5129e-05 - accuracy: 1.0000\n","Epoch 24/50\n","57/57 - 1s - loss: 4.1281e-05 - accuracy: 1.0000\n","Epoch 25/50\n","57/57 - 1s - loss: 3.7925e-05 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 3.4946e-05 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 3.2271e-05 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 2.9983e-05 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 2.7886e-05 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 2.5950e-05 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 2.4077e-05 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 2.2582e-05 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 2.1091e-05 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 1.9773e-05 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 1.8583e-05 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 1.7484e-05 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 1.6483e-05 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 1.4966e-05 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 1.3979e-05 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 1.3237e-05 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 1.2547e-05 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 1.1904e-05 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 1.1340e-05 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 1.0756e-05 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 1.0220e-05 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 9.7098e-06 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 9.2676e-06 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 8.7333e-06 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 8.2964e-06 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 7.9307e-06 - accuracy: 1.0000\n","30 accuracy: 0.8550000190734863\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6913 - accuracy: 0.5350\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6807 - accuracy: 0.6250\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6589 - accuracy: 0.7461\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6247 - accuracy: 0.8850\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5833 - accuracy: 0.9300\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5371 - accuracy: 0.9450\n","Epoch 7/50\n","57/57 - 1s - loss: 0.4883 - accuracy: 0.9539\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4415 - accuracy: 0.9572\n","Epoch 9/50\n","57/57 - 1s - loss: 0.3965 - accuracy: 0.9656\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3549 - accuracy: 0.9667\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3167 - accuracy: 0.9761\n","Epoch 12/50\n","57/57 - 1s - loss: 0.2829 - accuracy: 0.9806\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2532 - accuracy: 0.9833\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2279 - accuracy: 0.9889\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2033 - accuracy: 0.9900\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1824 - accuracy: 0.9922\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1642 - accuracy: 0.9933\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1480 - accuracy: 0.9950\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1336 - accuracy: 0.9967\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1208 - accuracy: 0.9972\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1092 - accuracy: 0.9983\n","Epoch 22/50\n","57/57 - 1s - loss: 0.0992 - accuracy: 0.9978\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0904 - accuracy: 0.9989\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0822 - accuracy: 0.9989\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0751 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0685 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0628 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0576 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0530 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0488 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0450 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0415 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0386 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0355 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0330 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0307 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0285 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0266 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0248 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0232 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0217 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0203 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0191 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0179 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0168 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0158 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0148 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0140 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0132 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0125 - accuracy: 1.0000\n","1 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6923 - accuracy: 0.6261\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6860 - accuracy: 0.8494\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6719 - accuracy: 0.7967\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6480 - accuracy: 0.9172\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6155 - accuracy: 0.9289\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5761 - accuracy: 0.9400\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5330 - accuracy: 0.9444\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4899 - accuracy: 0.9456\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4456 - accuracy: 0.9528\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4053 - accuracy: 0.9572\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3668 - accuracy: 0.9633\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3321 - accuracy: 0.9739\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3009 - accuracy: 0.9761\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2724 - accuracy: 0.9800\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2464 - accuracy: 0.9833\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2236 - accuracy: 0.9872\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2029 - accuracy: 0.9906\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1848 - accuracy: 0.9917\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1680 - accuracy: 0.9928\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1535 - accuracy: 0.9944\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1402 - accuracy: 0.9944\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1276 - accuracy: 0.9956\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1170 - accuracy: 0.9967\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1071 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0983 - accuracy: 0.9972\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0905 - accuracy: 0.9978\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0831 - accuracy: 0.9983\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0764 - accuracy: 0.9994\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0708 - accuracy: 0.9994\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0653 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0603 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0558 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0520 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0481 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0447 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0417 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0388 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0361 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0339 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0316 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0296 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0277 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0260 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0244 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0229 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0216 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0203 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0192 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0181 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0171 - accuracy: 1.0000\n","2 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6917 - accuracy: 0.5250\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6824 - accuracy: 0.7922\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6654 - accuracy: 0.8928\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6393 - accuracy: 0.9161\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6044 - accuracy: 0.9311\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5645 - accuracy: 0.9344\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5206 - accuracy: 0.9433\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4757 - accuracy: 0.9522\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4315 - accuracy: 0.9589\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3908 - accuracy: 0.9639\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3524 - accuracy: 0.9694\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3180 - accuracy: 0.9756\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2866 - accuracy: 0.9794\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2592 - accuracy: 0.9822\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2343 - accuracy: 0.9867\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2118 - accuracy: 0.9889\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1913 - accuracy: 0.9906\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1737 - accuracy: 0.9917\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1577 - accuracy: 0.9933\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1431 - accuracy: 0.9944\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1306 - accuracy: 0.9961\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1192 - accuracy: 0.9978\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1092 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0995 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0911 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0837 - accuracy: 0.9989\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0770 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0707 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0652 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0602 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0557 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0514 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0476 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0442 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0410 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0383 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0357 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0333 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0310 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0290 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0272 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0254 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0239 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0226 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0210 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0198 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0187 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0176 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0166 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0156 - accuracy: 1.0000\n","3 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6910 - accuracy: 0.5972\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6792 - accuracy: 0.7250\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6573 - accuracy: 0.9061\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6234 - accuracy: 0.9250\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5807 - accuracy: 0.9150\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5327 - accuracy: 0.9467\n","Epoch 7/50\n","57/57 - 1s - loss: 0.4836 - accuracy: 0.9544\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4351 - accuracy: 0.9539\n","Epoch 9/50\n","57/57 - 1s - loss: 0.3904 - accuracy: 0.9611\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3479 - accuracy: 0.9650\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3095 - accuracy: 0.9778\n","Epoch 12/50\n","57/57 - 1s - loss: 0.2755 - accuracy: 0.9789\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2457 - accuracy: 0.9833\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2194 - accuracy: 0.9872\n","Epoch 15/50\n","57/57 - 1s - loss: 0.1966 - accuracy: 0.9889\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1762 - accuracy: 0.9911\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1587 - accuracy: 0.9933\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1419 - accuracy: 0.9944\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1279 - accuracy: 0.9961\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1154 - accuracy: 0.9972\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1044 - accuracy: 0.9978\n","Epoch 22/50\n","57/57 - 1s - loss: 0.0948 - accuracy: 0.9983\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0858 - accuracy: 0.9989\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0786 - accuracy: 0.9994\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0712 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0651 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0595 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0545 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0501 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0461 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0425 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0391 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0362 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0334 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0310 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0288 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0268 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0249 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0233 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0217 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0203 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0190 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0178 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0167 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0157 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0148 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0139 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0131 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0123 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0116 - accuracy: 1.0000\n","4 accuracy: 0.9150000214576721\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6920 - accuracy: 0.5567\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6842 - accuracy: 0.8439\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6691 - accuracy: 0.7761\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6460 - accuracy: 0.8550\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6141 - accuracy: 0.9000\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5770 - accuracy: 0.9411\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5374 - accuracy: 0.9467\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4951 - accuracy: 0.9539\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4547 - accuracy: 0.9578\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4137 - accuracy: 0.9639\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3766 - accuracy: 0.9694\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3413 - accuracy: 0.9739\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3107 - accuracy: 0.9767\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2813 - accuracy: 0.9844\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2560 - accuracy: 0.9856\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2320 - accuracy: 0.9883\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2111 - accuracy: 0.9889\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1920 - accuracy: 0.9911\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1755 - accuracy: 0.9933\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1603 - accuracy: 0.9928\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1461 - accuracy: 0.9944\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1342 - accuracy: 0.9956\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1224 - accuracy: 0.9967\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1124 - accuracy: 0.9967\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1036 - accuracy: 0.9978\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0950 - accuracy: 0.9983\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0874 - accuracy: 0.9983\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0809 - accuracy: 0.9989\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0746 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0692 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0639 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0592 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0550 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0513 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0476 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0444 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0413 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0386 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0361 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0337 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0317 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0296 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0278 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0263 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0245 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0231 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0218 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0205 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0194 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0183 - accuracy: 1.0000\n","5 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6913 - accuracy: 0.5000\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6810 - accuracy: 0.5372\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6637 - accuracy: 0.5839\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6400 - accuracy: 0.6839\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6122 - accuracy: 0.7561\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5819 - accuracy: 0.7950\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5496 - accuracy: 0.8278\n","Epoch 8/50\n","57/57 - 1s - loss: 0.5175 - accuracy: 0.8667\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4863 - accuracy: 0.9061\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4561 - accuracy: 0.9172\n","Epoch 11/50\n","57/57 - 1s - loss: 0.4276 - accuracy: 0.9411\n","Epoch 12/50\n","57/57 - 1s - loss: 0.4013 - accuracy: 0.9561\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3749 - accuracy: 0.9650\n","Epoch 14/50\n","57/57 - 1s - loss: 0.3517 - accuracy: 0.9711\n","Epoch 15/50\n","57/57 - 1s - loss: 0.3293 - accuracy: 0.9794\n","Epoch 16/50\n","57/57 - 1s - loss: 0.3090 - accuracy: 0.9833\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2902 - accuracy: 0.9878\n","Epoch 18/50\n","57/57 - 1s - loss: 0.2722 - accuracy: 0.9894\n","Epoch 19/50\n","57/57 - 1s - loss: 0.2564 - accuracy: 0.9944\n","Epoch 20/50\n","57/57 - 1s - loss: 0.2415 - accuracy: 0.9950\n","Epoch 21/50\n","57/57 - 1s - loss: 0.2276 - accuracy: 0.9950\n","Epoch 22/50\n","57/57 - 1s - loss: 0.2149 - accuracy: 0.9961\n","Epoch 23/50\n","57/57 - 1s - loss: 0.2031 - accuracy: 0.9967\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1919 - accuracy: 0.9967\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1819 - accuracy: 0.9978\n","Epoch 26/50\n","57/57 - 1s - loss: 0.1725 - accuracy: 0.9983\n","Epoch 27/50\n","57/57 - 1s - loss: 0.1635 - accuracy: 0.9989\n","Epoch 28/50\n","57/57 - 1s - loss: 0.1555 - accuracy: 0.9994\n","Epoch 29/50\n","57/57 - 1s - loss: 0.1479 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.1409 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.1342 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.1282 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.1223 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.1168 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.1117 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.1069 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.1023 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0981 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0941 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0903 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0868 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0834 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0803 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0772 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0743 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0716 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0690 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0665 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0641 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0619 - accuracy: 1.0000\n","6 accuracy: 0.8399999737739563\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6914 - accuracy: 0.5200\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6808 - accuracy: 0.7189\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6605 - accuracy: 0.8583\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6304 - accuracy: 0.8683\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5919 - accuracy: 0.9328\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5466 - accuracy: 0.9450\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5008 - accuracy: 0.9517\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4534 - accuracy: 0.9561\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4092 - accuracy: 0.9594\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3678 - accuracy: 0.9672\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3303 - accuracy: 0.9733\n","Epoch 12/50\n","57/57 - 1s - loss: 0.2959 - accuracy: 0.9783\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2662 - accuracy: 0.9822\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2389 - accuracy: 0.9850\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2145 - accuracy: 0.9900\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1941 - accuracy: 0.9906\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1744 - accuracy: 0.9933\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1578 - accuracy: 0.9928\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1429 - accuracy: 0.9950\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1299 - accuracy: 0.9967\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1176 - accuracy: 0.9967\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1073 - accuracy: 0.9978\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0976 - accuracy: 0.9983\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0892 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0818 - accuracy: 0.9994\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0748 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0687 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0632 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0580 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0536 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0493 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0456 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0423 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0394 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0364 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0340 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0316 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0294 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0274 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0257 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0239 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0225 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0211 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0198 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0186 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0175 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0165 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0155 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0146 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0138 - accuracy: 1.0000\n","7 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6916 - accuracy: 0.5050\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6828 - accuracy: 0.5439\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6674 - accuracy: 0.5889\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6450 - accuracy: 0.6667\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6178 - accuracy: 0.7394\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5875 - accuracy: 0.7756\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5558 - accuracy: 0.8267\n","Epoch 8/50\n","57/57 - 1s - loss: 0.5242 - accuracy: 0.8556\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4931 - accuracy: 0.8978\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4633 - accuracy: 0.9122\n","Epoch 11/50\n","57/57 - 1s - loss: 0.4339 - accuracy: 0.9394\n","Epoch 12/50\n","57/57 - 1s - loss: 0.4074 - accuracy: 0.9517\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3819 - accuracy: 0.9622\n","Epoch 14/50\n","57/57 - 1s - loss: 0.3580 - accuracy: 0.9728\n","Epoch 15/50\n","57/57 - 1s - loss: 0.3360 - accuracy: 0.9772\n","Epoch 16/50\n","57/57 - 1s - loss: 0.3156 - accuracy: 0.9828\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2962 - accuracy: 0.9867\n","Epoch 18/50\n","57/57 - 1s - loss: 0.2788 - accuracy: 0.9867\n","Epoch 19/50\n","57/57 - 1s - loss: 0.2618 - accuracy: 0.9922\n","Epoch 20/50\n","57/57 - 1s - loss: 0.2466 - accuracy: 0.9944\n","Epoch 21/50\n","57/57 - 1s - loss: 0.2325 - accuracy: 0.9950\n","Epoch 22/50\n","57/57 - 1s - loss: 0.2196 - accuracy: 0.9961\n","Epoch 23/50\n","57/57 - 1s - loss: 0.2075 - accuracy: 0.9967\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1961 - accuracy: 0.9967\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1857 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.1760 - accuracy: 0.9983\n","Epoch 27/50\n","57/57 - 1s - loss: 0.1669 - accuracy: 0.9989\n","Epoch 28/50\n","57/57 - 1s - loss: 0.1587 - accuracy: 0.9989\n","Epoch 29/50\n","57/57 - 1s - loss: 0.1507 - accuracy: 0.9994\n","Epoch 30/50\n","57/57 - 1s - loss: 0.1435 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.1368 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.1305 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.1247 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.1190 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.1137 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.1090 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.1043 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.1000 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0959 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0921 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0884 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0850 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0817 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0786 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0757 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0729 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0702 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0677 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0653 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0630 - accuracy: 1.0000\n","8 accuracy: 0.8399999737739563\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6916 - accuracy: 0.5883\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6824 - accuracy: 0.8783\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6643 - accuracy: 0.9150\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6354 - accuracy: 0.9333\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5982 - accuracy: 0.9250\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5551 - accuracy: 0.9433\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5107 - accuracy: 0.9489\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4651 - accuracy: 0.9539\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4224 - accuracy: 0.9589\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3818 - accuracy: 0.9633\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3451 - accuracy: 0.9700\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3113 - accuracy: 0.9744\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2818 - accuracy: 0.9767\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2532 - accuracy: 0.9856\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2292 - accuracy: 0.9861\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2071 - accuracy: 0.9889\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1875 - accuracy: 0.9906\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1696 - accuracy: 0.9939\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1544 - accuracy: 0.9944\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1403 - accuracy: 0.9944\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1278 - accuracy: 0.9950\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1164 - accuracy: 0.9972\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1063 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0974 - accuracy: 0.9972\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0892 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0819 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0752 - accuracy: 0.9994\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0693 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0637 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0587 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0542 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0501 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0465 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0431 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0400 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0372 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0347 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0323 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0302 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0282 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0264 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0248 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0233 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0217 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0205 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0192 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0181 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0170 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0161 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0152 - accuracy: 1.0000\n","9 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6921 - accuracy: 0.5828\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6851 - accuracy: 0.6644\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6695 - accuracy: 0.8989\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6448 - accuracy: 0.9050\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6116 - accuracy: 0.9306\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5725 - accuracy: 0.9383\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5297 - accuracy: 0.9472\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4870 - accuracy: 0.9500\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4446 - accuracy: 0.9572\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4039 - accuracy: 0.9600\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3664 - accuracy: 0.9667\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3315 - accuracy: 0.9728\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3004 - accuracy: 0.9772\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2726 - accuracy: 0.9806\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2466 - accuracy: 0.9828\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2237 - accuracy: 0.9889\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2034 - accuracy: 0.9889\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1853 - accuracy: 0.9917\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1680 - accuracy: 0.9922\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1536 - accuracy: 0.9928\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1400 - accuracy: 0.9950\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1280 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1174 - accuracy: 0.9961\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1078 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0990 - accuracy: 0.9972\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0908 - accuracy: 0.9978\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0834 - accuracy: 0.9983\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0771 - accuracy: 0.9994\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0709 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0656 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0607 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0561 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0522 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0485 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0450 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0420 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0391 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0365 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0340 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0319 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0298 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0280 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0262 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0246 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0231 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0218 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0204 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0194 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0182 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0172 - accuracy: 1.0000\n","10 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6917 - accuracy: 0.5056\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6814 - accuracy: 0.5850\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6626 - accuracy: 0.6561\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6343 - accuracy: 0.8061\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5984 - accuracy: 0.8811\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5567 - accuracy: 0.9122\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5107 - accuracy: 0.9483\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4627 - accuracy: 0.9567\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4169 - accuracy: 0.9661\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3747 - accuracy: 0.9717\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3359 - accuracy: 0.9794\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3002 - accuracy: 0.9817\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2690 - accuracy: 0.9861\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2406 - accuracy: 0.9883\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2165 - accuracy: 0.9906\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1942 - accuracy: 0.9922\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1752 - accuracy: 0.9928\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1577 - accuracy: 0.9939\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1423 - accuracy: 0.9967\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1292 - accuracy: 0.9967\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1176 - accuracy: 0.9983\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1062 - accuracy: 0.9989\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0966 - accuracy: 0.9989\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0882 - accuracy: 0.9989\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0805 - accuracy: 1.0000\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0736 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0674 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0618 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0571 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0523 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0483 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0447 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0414 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0382 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0355 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0330 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0308 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0286 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0267 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0250 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0233 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0218 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0205 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0192 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0181 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0170 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0160 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0150 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0143 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0135 - accuracy: 1.0000\n","11 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6918 - accuracy: 0.6239\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6836 - accuracy: 0.7194\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6658 - accuracy: 0.8044\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6389 - accuracy: 0.8500\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6026 - accuracy: 0.9139\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5616 - accuracy: 0.9422\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5177 - accuracy: 0.9489\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4725 - accuracy: 0.9544\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4282 - accuracy: 0.9583\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3871 - accuracy: 0.9611\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3500 - accuracy: 0.9644\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3154 - accuracy: 0.9767\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2837 - accuracy: 0.9783\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2559 - accuracy: 0.9828\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2317 - accuracy: 0.9850\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2092 - accuracy: 0.9894\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1891 - accuracy: 0.9906\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1712 - accuracy: 0.9922\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1559 - accuracy: 0.9928\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1411 - accuracy: 0.9956\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1287 - accuracy: 0.9956\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1172 - accuracy: 0.9961\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1074 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0979 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0897 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0821 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0756 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0693 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0639 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0589 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0543 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0506 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0468 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0433 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0404 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0373 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0348 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0325 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0303 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0283 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0266 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0248 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0233 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0219 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0205 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0193 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0181 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0171 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0161 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0153 - accuracy: 1.0000\n","12 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6913 - accuracy: 0.5056\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6803 - accuracy: 0.6567\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6607 - accuracy: 0.6711\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6317 - accuracy: 0.8311\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5951 - accuracy: 0.8733\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5536 - accuracy: 0.9328\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5105 - accuracy: 0.9444\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4648 - accuracy: 0.9572\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4215 - accuracy: 0.9667\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3804 - accuracy: 0.9739\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3417 - accuracy: 0.9789\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3072 - accuracy: 0.9822\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2758 - accuracy: 0.9850\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2486 - accuracy: 0.9872\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2229 - accuracy: 0.9900\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2011 - accuracy: 0.9917\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1803 - accuracy: 0.9928\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1638 - accuracy: 0.9944\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1485 - accuracy: 0.9939\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1340 - accuracy: 0.9967\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1217 - accuracy: 0.9967\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1109 - accuracy: 0.9972\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1010 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0921 - accuracy: 0.9989\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0843 - accuracy: 0.9994\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0772 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0707 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0650 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0598 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0551 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0508 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0470 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0434 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0404 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0373 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0347 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0324 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0302 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0282 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0263 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0246 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0230 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0216 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0203 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0191 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0179 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0169 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0160 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0150 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0141 - accuracy: 1.0000\n","13 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6919 - accuracy: 0.6233\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6841 - accuracy: 0.8733\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6683 - accuracy: 0.8644\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6422 - accuracy: 0.9217\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6078 - accuracy: 0.9256\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5670 - accuracy: 0.9389\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5236 - accuracy: 0.9450\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4798 - accuracy: 0.9500\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4376 - accuracy: 0.9533\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3972 - accuracy: 0.9606\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3597 - accuracy: 0.9656\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3264 - accuracy: 0.9733\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2948 - accuracy: 0.9783\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2674 - accuracy: 0.9811\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2420 - accuracy: 0.9850\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2193 - accuracy: 0.9878\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1994 - accuracy: 0.9889\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1812 - accuracy: 0.9906\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1652 - accuracy: 0.9933\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1505 - accuracy: 0.9933\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1376 - accuracy: 0.9950\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1254 - accuracy: 0.9956\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1149 - accuracy: 0.9967\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1054 - accuracy: 0.9967\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0966 - accuracy: 0.9978\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0887 - accuracy: 0.9983\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0816 - accuracy: 0.9989\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0752 - accuracy: 0.9994\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0693 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0643 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0593 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0550 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0512 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0473 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0440 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0410 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0382 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0356 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0332 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0311 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0291 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0273 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0255 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0240 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0225 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0212 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0200 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0188 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0177 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0167 - accuracy: 1.0000\n","14 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6918 - accuracy: 0.4939\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6829 - accuracy: 0.5750\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6675 - accuracy: 0.6694\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6445 - accuracy: 0.7594\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6134 - accuracy: 0.8611\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5767 - accuracy: 0.9361\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5351 - accuracy: 0.9411\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4907 - accuracy: 0.9561\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4477 - accuracy: 0.9578\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4061 - accuracy: 0.9656\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3677 - accuracy: 0.9717\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3317 - accuracy: 0.9783\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3016 - accuracy: 0.9794\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2708 - accuracy: 0.9828\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2453 - accuracy: 0.9867\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2218 - accuracy: 0.9906\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2009 - accuracy: 0.9917\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1827 - accuracy: 0.9939\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1658 - accuracy: 0.9933\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1510 - accuracy: 0.9950\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1374 - accuracy: 0.9967\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1261 - accuracy: 0.9972\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1150 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1053 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0968 - accuracy: 0.9978\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0885 - accuracy: 0.9983\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0815 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0752 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0693 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0640 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0592 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0549 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0508 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0472 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0442 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0410 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0382 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0356 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0332 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0311 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0291 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0273 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0256 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0240 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0226 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0213 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0201 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0188 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0178 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0168 - accuracy: 1.0000\n","15 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6921 - accuracy: 0.5139\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6836 - accuracy: 0.5900\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6675 - accuracy: 0.7883\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6412 - accuracy: 0.8267\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6062 - accuracy: 0.9139\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5660 - accuracy: 0.9306\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5216 - accuracy: 0.9433\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4789 - accuracy: 0.9511\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4358 - accuracy: 0.9617\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3940 - accuracy: 0.9694\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3560 - accuracy: 0.9750\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3223 - accuracy: 0.9794\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2904 - accuracy: 0.9806\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2618 - accuracy: 0.9839\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2365 - accuracy: 0.9872\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2139 - accuracy: 0.9894\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1934 - accuracy: 0.9906\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1752 - accuracy: 0.9922\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1594 - accuracy: 0.9956\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1446 - accuracy: 0.9950\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1319 - accuracy: 0.9967\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1199 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1096 - accuracy: 0.9983\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1002 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0917 - accuracy: 0.9994\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0843 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0774 - accuracy: 0.9994\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0714 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0656 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0606 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0559 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0517 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0480 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0444 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0413 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0385 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0359 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0334 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0312 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0292 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0273 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0256 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0240 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0225 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0213 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0199 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0188 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0176 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0167 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0157 - accuracy: 1.0000\n","16 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6916 - accuracy: 0.5822\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6822 - accuracy: 0.7194\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6636 - accuracy: 0.8350\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6335 - accuracy: 0.9267\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5943 - accuracy: 0.9311\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5507 - accuracy: 0.9344\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5042 - accuracy: 0.9456\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4578 - accuracy: 0.9506\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4135 - accuracy: 0.9633\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3726 - accuracy: 0.9678\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3360 - accuracy: 0.9672\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3013 - accuracy: 0.9750\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2706 - accuracy: 0.9778\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2441 - accuracy: 0.9822\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2197 - accuracy: 0.9844\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1978 - accuracy: 0.9911\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1782 - accuracy: 0.9917\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1628 - accuracy: 0.9933\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1464 - accuracy: 0.9944\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1333 - accuracy: 0.9967\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1208 - accuracy: 0.9972\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1103 - accuracy: 0.9972\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1004 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0915 - accuracy: 0.9989\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0839 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0769 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0705 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0651 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0598 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0551 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0508 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0470 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0435 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0404 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0375 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0349 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0324 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0303 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0283 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0264 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0247 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0232 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0217 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0203 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0191 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0180 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0169 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0160 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0151 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0142 - accuracy: 1.0000\n","17 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6916 - accuracy: 0.5317\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6818 - accuracy: 0.7267\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6627 - accuracy: 0.8522\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6334 - accuracy: 0.9106\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5954 - accuracy: 0.9317\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5524 - accuracy: 0.9394\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5068 - accuracy: 0.9506\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4599 - accuracy: 0.9556\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4157 - accuracy: 0.9611\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3737 - accuracy: 0.9661\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3363 - accuracy: 0.9694\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3022 - accuracy: 0.9767\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2707 - accuracy: 0.9844\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2435 - accuracy: 0.9850\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2192 - accuracy: 0.9894\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1975 - accuracy: 0.9900\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1783 - accuracy: 0.9933\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1610 - accuracy: 0.9933\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1459 - accuracy: 0.9944\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1321 - accuracy: 0.9956\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1200 - accuracy: 0.9967\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1092 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0995 - accuracy: 0.9983\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0911 - accuracy: 0.9972\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0831 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0761 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0698 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0642 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0590 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0546 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0502 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0465 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0431 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0399 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0373 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0344 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0321 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0299 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0279 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0261 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0244 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0229 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0214 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0201 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0189 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0178 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0167 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0158 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0149 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0140 - accuracy: 1.0000\n","18 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6918 - accuracy: 0.5072\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6842 - accuracy: 0.5533\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6696 - accuracy: 0.7300\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6481 - accuracy: 0.7428\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6181 - accuracy: 0.8867\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5837 - accuracy: 0.8972\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5455 - accuracy: 0.9317\n","Epoch 8/50\n","57/57 - 1s - loss: 0.5045 - accuracy: 0.9556\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4629 - accuracy: 0.9606\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4227 - accuracy: 0.9667\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3843 - accuracy: 0.9722\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3482 - accuracy: 0.9756\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3159 - accuracy: 0.9806\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2859 - accuracy: 0.9839\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2589 - accuracy: 0.9856\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2346 - accuracy: 0.9889\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2136 - accuracy: 0.9894\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1943 - accuracy: 0.9928\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1768 - accuracy: 0.9928\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1612 - accuracy: 0.9922\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1468 - accuracy: 0.9950\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1342 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1228 - accuracy: 0.9961\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1127 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1034 - accuracy: 0.9978\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0953 - accuracy: 0.9978\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0875 - accuracy: 0.9989\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0807 - accuracy: 0.9994\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0745 - accuracy: 0.9994\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0689 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0637 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0592 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0549 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0509 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0474 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0441 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0412 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0384 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0358 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0336 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0316 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0295 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0277 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0259 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0244 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0229 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0216 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0204 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0192 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0181 - accuracy: 1.0000\n","19 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6922 - accuracy: 0.4939\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6854 - accuracy: 0.5528\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6707 - accuracy: 0.5944\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6459 - accuracy: 0.7822\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6131 - accuracy: 0.8700\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5750 - accuracy: 0.9056\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5336 - accuracy: 0.9328\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4908 - accuracy: 0.9517\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4477 - accuracy: 0.9639\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4061 - accuracy: 0.9672\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3673 - accuracy: 0.9728\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3320 - accuracy: 0.9794\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2991 - accuracy: 0.9839\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2700 - accuracy: 0.9867\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2433 - accuracy: 0.9856\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2198 - accuracy: 0.9894\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1989 - accuracy: 0.9917\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1802 - accuracy: 0.9922\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1635 - accuracy: 0.9933\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1483 - accuracy: 0.9956\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1357 - accuracy: 0.9956\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1231 - accuracy: 0.9967\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1122 - accuracy: 0.9978\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1024 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0940 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0860 - accuracy: 0.9989\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0793 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0727 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0669 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0618 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0574 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0529 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0489 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0454 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0421 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0394 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0365 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0340 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0318 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0298 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0278 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0261 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0245 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0229 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0216 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0203 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0191 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0180 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0170 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0160 - accuracy: 1.0000\n","20 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6916 - accuracy: 0.5800\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6827 - accuracy: 0.7039\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6656 - accuracy: 0.7511\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6379 - accuracy: 0.9233\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6019 - accuracy: 0.9228\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5599 - accuracy: 0.9406\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5160 - accuracy: 0.9489\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4722 - accuracy: 0.9500\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4288 - accuracy: 0.9600\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3880 - accuracy: 0.9628\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3509 - accuracy: 0.9700\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3168 - accuracy: 0.9717\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2858 - accuracy: 0.9800\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2579 - accuracy: 0.9844\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2333 - accuracy: 0.9856\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2111 - accuracy: 0.9883\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1912 - accuracy: 0.9922\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1733 - accuracy: 0.9917\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1573 - accuracy: 0.9933\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1429 - accuracy: 0.9950\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1304 - accuracy: 0.9956\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1190 - accuracy: 0.9961\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1088 - accuracy: 0.9972\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0995 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0912 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0838 - accuracy: 0.9989\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0770 - accuracy: 0.9994\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0708 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0651 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0602 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0556 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0514 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0479 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0443 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0412 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0383 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0357 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0333 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0311 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0290 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0271 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0254 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0239 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0224 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0211 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0198 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0186 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0176 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0166 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0157 - accuracy: 1.0000\n","21 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6917 - accuracy: 0.5189\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6816 - accuracy: 0.6922\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6617 - accuracy: 0.8856\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6311 - accuracy: 0.9228\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5921 - accuracy: 0.9278\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5475 - accuracy: 0.9444\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5002 - accuracy: 0.9467\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4538 - accuracy: 0.9506\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4085 - accuracy: 0.9578\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3670 - accuracy: 0.9672\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3292 - accuracy: 0.9722\n","Epoch 12/50\n","57/57 - 1s - loss: 0.2952 - accuracy: 0.9722\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2648 - accuracy: 0.9811\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2378 - accuracy: 0.9872\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2135 - accuracy: 0.9889\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1923 - accuracy: 0.9917\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1733 - accuracy: 0.9928\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1562 - accuracy: 0.9939\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1413 - accuracy: 0.9944\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1279 - accuracy: 0.9967\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1161 - accuracy: 0.9961\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1056 - accuracy: 0.9983\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0962 - accuracy: 0.9983\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0876 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0802 - accuracy: 0.9994\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0734 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0673 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0615 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0568 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0524 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0483 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0446 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0412 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0382 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0354 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0329 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0306 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0285 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0266 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0249 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0232 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0217 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0204 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0191 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0180 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0169 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0160 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0150 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0142 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0133 - accuracy: 1.0000\n","22 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6920 - accuracy: 0.5100\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6845 - accuracy: 0.8344\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6701 - accuracy: 0.7600\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6428 - accuracy: 0.9139\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6051 - accuracy: 0.9267\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5604 - accuracy: 0.9389\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5133 - accuracy: 0.9456\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4653 - accuracy: 0.9517\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4197 - accuracy: 0.9594\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3774 - accuracy: 0.9617\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3381 - accuracy: 0.9683\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3037 - accuracy: 0.9728\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2723 - accuracy: 0.9828\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2449 - accuracy: 0.9839\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2202 - accuracy: 0.9861\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1982 - accuracy: 0.9906\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1789 - accuracy: 0.9911\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1614 - accuracy: 0.9933\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1459 - accuracy: 0.9939\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1323 - accuracy: 0.9956\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1205 - accuracy: 0.9972\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1091 - accuracy: 0.9978\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0995 - accuracy: 0.9972\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0908 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0828 - accuracy: 0.9989\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0759 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0697 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0640 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0586 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0541 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0500 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0461 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0427 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0396 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0367 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0343 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0318 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0296 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0276 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0258 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0241 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0226 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0212 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0199 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0187 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0176 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0165 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0155 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0146 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0138 - accuracy: 1.0000\n","23 accuracy: 0.9049999713897705\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6922 - accuracy: 0.5633\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6843 - accuracy: 0.7939\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6670 - accuracy: 0.8594\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6405 - accuracy: 0.9244\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6078 - accuracy: 0.9106\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5681 - accuracy: 0.9383\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5275 - accuracy: 0.9411\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4844 - accuracy: 0.9528\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4425 - accuracy: 0.9578\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4038 - accuracy: 0.9583\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3666 - accuracy: 0.9678\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3328 - accuracy: 0.9717\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3018 - accuracy: 0.9756\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2741 - accuracy: 0.9828\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2487 - accuracy: 0.9856\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2265 - accuracy: 0.9861\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2057 - accuracy: 0.9878\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1874 - accuracy: 0.9911\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1709 - accuracy: 0.9928\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1559 - accuracy: 0.9939\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1423 - accuracy: 0.9944\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1303 - accuracy: 0.9950\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1195 - accuracy: 0.9967\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1093 - accuracy: 0.9978\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1007 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0925 - accuracy: 0.9983\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0848 - accuracy: 0.9994\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0786 - accuracy: 0.9994\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0725 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0671 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0623 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0574 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0534 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0496 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0461 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0429 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0401 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0375 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0349 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0327 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0306 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0286 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0268 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0253 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0237 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0223 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0210 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0198 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0187 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0177 - accuracy: 1.0000\n","24 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6919 - accuracy: 0.5439\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6834 - accuracy: 0.8894\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6673 - accuracy: 0.8044\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6407 - accuracy: 0.8389\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6068 - accuracy: 0.9200\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5655 - accuracy: 0.9317\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5219 - accuracy: 0.9361\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4799 - accuracy: 0.9472\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4351 - accuracy: 0.9589\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3950 - accuracy: 0.9633\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3584 - accuracy: 0.9656\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3233 - accuracy: 0.9739\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2923 - accuracy: 0.9783\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2646 - accuracy: 0.9822\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2394 - accuracy: 0.9867\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2170 - accuracy: 0.9872\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1973 - accuracy: 0.9900\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1783 - accuracy: 0.9917\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1625 - accuracy: 0.9928\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1483 - accuracy: 0.9939\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1353 - accuracy: 0.9950\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1230 - accuracy: 0.9961\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1125 - accuracy: 0.9967\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1033 - accuracy: 0.9972\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0946 - accuracy: 0.9972\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0869 - accuracy: 0.9989\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0799 - accuracy: 0.9983\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0737 - accuracy: 0.9994\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0677 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0627 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0581 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0537 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0497 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0462 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0430 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0400 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0373 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0348 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0324 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0303 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0284 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0266 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0249 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0234 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0220 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0207 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0194 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0184 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0173 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0163 - accuracy: 1.0000\n","25 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6918 - accuracy: 0.5628\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6836 - accuracy: 0.7339\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6688 - accuracy: 0.8461\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6463 - accuracy: 0.8406\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6172 - accuracy: 0.9322\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5833 - accuracy: 0.9372\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5476 - accuracy: 0.9317\n","Epoch 8/50\n","57/57 - 1s - loss: 0.5082 - accuracy: 0.9472\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4681 - accuracy: 0.9544\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4302 - accuracy: 0.9600\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3944 - accuracy: 0.9622\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3603 - accuracy: 0.9706\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3292 - accuracy: 0.9739\n","Epoch 14/50\n","57/57 - 1s - loss: 0.3016 - accuracy: 0.9756\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2748 - accuracy: 0.9822\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2509 - accuracy: 0.9844\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2299 - accuracy: 0.9872\n","Epoch 18/50\n","57/57 - 1s - loss: 0.2100 - accuracy: 0.9889\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1924 - accuracy: 0.9900\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1762 - accuracy: 0.9906\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1618 - accuracy: 0.9933\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1488 - accuracy: 0.9939\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1365 - accuracy: 0.9950\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1259 - accuracy: 0.9961\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1160 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.1069 - accuracy: 0.9972\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0989 - accuracy: 0.9978\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0915 - accuracy: 0.9983\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0846 - accuracy: 0.9994\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0785 - accuracy: 0.9994\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0727 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0675 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0629 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0585 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0545 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0511 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0474 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0443 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0415 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0389 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0364 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0341 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0321 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0301 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0284 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0267 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0251 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0238 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0223 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0211 - accuracy: 1.0000\n","26 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6914 - accuracy: 0.4989\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6797 - accuracy: 0.5572\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6595 - accuracy: 0.6572\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6313 - accuracy: 0.7239\n","Epoch 5/50\n","57/57 - 1s - loss: 0.5979 - accuracy: 0.8133\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5565 - accuracy: 0.9033\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5122 - accuracy: 0.9417\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4679 - accuracy: 0.9533\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4233 - accuracy: 0.9667\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3828 - accuracy: 0.9700\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3434 - accuracy: 0.9783\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3070 - accuracy: 0.9844\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2754 - accuracy: 0.9878\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2467 - accuracy: 0.9911\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2211 - accuracy: 0.9922\n","Epoch 16/50\n","57/57 - 1s - loss: 0.1987 - accuracy: 0.9944\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1782 - accuracy: 0.9944\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1604 - accuracy: 0.9956\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1445 - accuracy: 0.9978\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1303 - accuracy: 0.9978\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1179 - accuracy: 0.9983\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1068 - accuracy: 0.9983\n","Epoch 23/50\n","57/57 - 1s - loss: 0.0973 - accuracy: 0.9994\n","Epoch 24/50\n","57/57 - 1s - loss: 0.0881 - accuracy: 0.9994\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0804 - accuracy: 0.9994\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0735 - accuracy: 1.0000\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0670 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0616 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0566 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0520 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0479 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0443 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0409 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0378 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0350 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0325 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0302 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0281 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0262 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0245 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0229 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0214 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0201 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0188 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0177 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0166 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0156 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0147 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0139 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0131 - accuracy: 1.0000\n","27 accuracy: 0.8999999761581421\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6921 - accuracy: 0.6656\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6852 - accuracy: 0.8328\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6720 - accuracy: 0.9144\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6505 - accuracy: 0.8939\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6219 - accuracy: 0.9206\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5874 - accuracy: 0.9350\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5500 - accuracy: 0.9428\n","Epoch 8/50\n","57/57 - 1s - loss: 0.5113 - accuracy: 0.9494\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4709 - accuracy: 0.9511\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4339 - accuracy: 0.9583\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3982 - accuracy: 0.9617\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3642 - accuracy: 0.9700\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3332 - accuracy: 0.9728\n","Epoch 14/50\n","57/57 - 1s - loss: 0.3046 - accuracy: 0.9728\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2785 - accuracy: 0.9817\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2543 - accuracy: 0.9856\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2328 - accuracy: 0.9878\n","Epoch 18/50\n","57/57 - 1s - loss: 0.2134 - accuracy: 0.9894\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1954 - accuracy: 0.9906\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1795 - accuracy: 0.9917\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1646 - accuracy: 0.9933\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1518 - accuracy: 0.9944\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1401 - accuracy: 0.9939\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1285 - accuracy: 0.9967\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1184 - accuracy: 0.9972\n","Epoch 26/50\n","57/57 - 1s - loss: 0.1094 - accuracy: 0.9972\n","Epoch 27/50\n","57/57 - 1s - loss: 0.1011 - accuracy: 0.9972\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0939 - accuracy: 0.9978\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0867 - accuracy: 0.9983\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0806 - accuracy: 0.9994\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0746 - accuracy: 0.9994\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0695 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0647 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0601 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0563 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0523 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0490 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0458 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0427 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0403 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0377 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0353 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0331 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0311 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0293 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0277 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0260 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0245 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0231 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0218 - accuracy: 1.0000\n","28 accuracy: 0.9100000262260437\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6916 - accuracy: 0.4978\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6827 - accuracy: 0.5472\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6669 - accuracy: 0.5778\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6438 - accuracy: 0.7256\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6147 - accuracy: 0.7983\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5812 - accuracy: 0.8639\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5445 - accuracy: 0.9050\n","Epoch 8/50\n","57/57 - 1s - loss: 0.5062 - accuracy: 0.9367\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4676 - accuracy: 0.9539\n","Epoch 10/50\n","57/57 - 1s - loss: 0.4305 - accuracy: 0.9583\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3933 - accuracy: 0.9700\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3590 - accuracy: 0.9767\n","Epoch 13/50\n","57/57 - 1s - loss: 0.3265 - accuracy: 0.9806\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2967 - accuracy: 0.9861\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2697 - accuracy: 0.9900\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2449 - accuracy: 0.9933\n","Epoch 17/50\n","57/57 - 1s - loss: 0.2223 - accuracy: 0.9933\n","Epoch 18/50\n","57/57 - 1s - loss: 0.2016 - accuracy: 0.9950\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1838 - accuracy: 0.9956\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1670 - accuracy: 0.9961\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1521 - accuracy: 0.9978\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1388 - accuracy: 0.9983\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1270 - accuracy: 0.9983\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1159 - accuracy: 0.9983\n","Epoch 25/50\n","57/57 - 1s - loss: 0.1062 - accuracy: 0.9983\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0973 - accuracy: 0.9994\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0894 - accuracy: 1.0000\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0824 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0759 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0699 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0647 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0598 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0554 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0514 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0478 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0444 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0413 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0387 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0360 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0336 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0314 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0295 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0276 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0259 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0244 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0229 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0216 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0204 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0192 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0181 - accuracy: 1.0000\n","29 accuracy: 0.8999999761581421\n","Epoch 1/50\n","57/57 - 1s - loss: 0.6918 - accuracy: 0.6344\n","Epoch 2/50\n","57/57 - 1s - loss: 0.6833 - accuracy: 0.6189\n","Epoch 3/50\n","57/57 - 1s - loss: 0.6657 - accuracy: 0.8450\n","Epoch 4/50\n","57/57 - 1s - loss: 0.6384 - accuracy: 0.9300\n","Epoch 5/50\n","57/57 - 1s - loss: 0.6044 - accuracy: 0.9272\n","Epoch 6/50\n","57/57 - 1s - loss: 0.5644 - accuracy: 0.9394\n","Epoch 7/50\n","57/57 - 1s - loss: 0.5209 - accuracy: 0.9444\n","Epoch 8/50\n","57/57 - 1s - loss: 0.4765 - accuracy: 0.9511\n","Epoch 9/50\n","57/57 - 1s - loss: 0.4337 - accuracy: 0.9544\n","Epoch 10/50\n","57/57 - 1s - loss: 0.3941 - accuracy: 0.9578\n","Epoch 11/50\n","57/57 - 1s - loss: 0.3560 - accuracy: 0.9656\n","Epoch 12/50\n","57/57 - 1s - loss: 0.3213 - accuracy: 0.9722\n","Epoch 13/50\n","57/57 - 1s - loss: 0.2904 - accuracy: 0.9767\n","Epoch 14/50\n","57/57 - 1s - loss: 0.2629 - accuracy: 0.9817\n","Epoch 15/50\n","57/57 - 1s - loss: 0.2372 - accuracy: 0.9850\n","Epoch 16/50\n","57/57 - 1s - loss: 0.2149 - accuracy: 0.9878\n","Epoch 17/50\n","57/57 - 1s - loss: 0.1945 - accuracy: 0.9894\n","Epoch 18/50\n","57/57 - 1s - loss: 0.1776 - accuracy: 0.9894\n","Epoch 19/50\n","57/57 - 1s - loss: 0.1610 - accuracy: 0.9933\n","Epoch 20/50\n","57/57 - 1s - loss: 0.1467 - accuracy: 0.9944\n","Epoch 21/50\n","57/57 - 1s - loss: 0.1339 - accuracy: 0.9944\n","Epoch 22/50\n","57/57 - 1s - loss: 0.1221 - accuracy: 0.9956\n","Epoch 23/50\n","57/57 - 1s - loss: 0.1113 - accuracy: 0.9967\n","Epoch 24/50\n","57/57 - 1s - loss: 0.1020 - accuracy: 0.9972\n","Epoch 25/50\n","57/57 - 1s - loss: 0.0937 - accuracy: 0.9978\n","Epoch 26/50\n","57/57 - 1s - loss: 0.0856 - accuracy: 0.9983\n","Epoch 27/50\n","57/57 - 1s - loss: 0.0789 - accuracy: 0.9994\n","Epoch 28/50\n","57/57 - 1s - loss: 0.0727 - accuracy: 1.0000\n","Epoch 29/50\n","57/57 - 1s - loss: 0.0668 - accuracy: 1.0000\n","Epoch 30/50\n","57/57 - 1s - loss: 0.0617 - accuracy: 1.0000\n","Epoch 31/50\n","57/57 - 1s - loss: 0.0571 - accuracy: 1.0000\n","Epoch 32/50\n","57/57 - 1s - loss: 0.0530 - accuracy: 1.0000\n","Epoch 33/50\n","57/57 - 1s - loss: 0.0490 - accuracy: 1.0000\n","Epoch 34/50\n","57/57 - 1s - loss: 0.0455 - accuracy: 1.0000\n","Epoch 35/50\n","57/57 - 1s - loss: 0.0423 - accuracy: 1.0000\n","Epoch 36/50\n","57/57 - 1s - loss: 0.0393 - accuracy: 1.0000\n","Epoch 37/50\n","57/57 - 1s - loss: 0.0368 - accuracy: 1.0000\n","Epoch 38/50\n","57/57 - 1s - loss: 0.0342 - accuracy: 1.0000\n","Epoch 39/50\n","57/57 - 1s - loss: 0.0319 - accuracy: 1.0000\n","Epoch 40/50\n","57/57 - 1s - loss: 0.0298 - accuracy: 1.0000\n","Epoch 41/50\n","57/57 - 1s - loss: 0.0279 - accuracy: 1.0000\n","Epoch 42/50\n","57/57 - 1s - loss: 0.0261 - accuracy: 1.0000\n","Epoch 43/50\n","57/57 - 1s - loss: 0.0245 - accuracy: 1.0000\n","Epoch 44/50\n","57/57 - 1s - loss: 0.0230 - accuracy: 1.0000\n","Epoch 45/50\n","57/57 - 1s - loss: 0.0216 - accuracy: 1.0000\n","Epoch 46/50\n","57/57 - 1s - loss: 0.0203 - accuracy: 1.0000\n","Epoch 47/50\n","57/57 - 1s - loss: 0.0191 - accuracy: 1.0000\n","Epoch 48/50\n","57/57 - 1s - loss: 0.0180 - accuracy: 1.0000\n","Epoch 49/50\n","57/57 - 1s - loss: 0.0170 - accuracy: 1.0000\n","Epoch 50/50\n","57/57 - 1s - loss: 0.0160 - accuracy: 1.0000\n","30 accuracy: 0.9049999713897705\n","          binary      count      tfidf       freq\n","count  30.000000  30.000000  30.000000  30.000000\n","mean    0.916500   0.893000   0.858833   0.903333\n","std     0.006842   0.010635   0.014895   0.017535\n","min     0.905000   0.870000   0.830000   0.840000\n","25%     0.910000   0.885000   0.850000   0.905000\n","50%     0.915000   0.895000   0.855000   0.910000\n","75%     0.920000   0.900000   0.868750   0.910000\n","max     0.930000   0.915000   0.890000   0.915000\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"v4iYfLpkwJlh"},"source":["Running the example may take a while (about an hour on modern hardware with CPUs, not GPUs).\n","\n","Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n","\n","At the end of the run, summary statistics for each word scoring method are provided, summarizing the distribution of model skill scores across each of the 30 runs per mode.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AnPDSi-pwLHl"},"source":["**We can see that the mean score of both the ‘freq‘ and ‘binary‘ methods appear to be better than ‘count‘ and ‘tfidf‘.**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dlJ2SjD_wz2q"},"source":["A box and whisker plot of the results is also presented, summarizing the accuracy distributions per configuration.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BMVITVtrxShq"},"source":["**Making a Prediction for New Reviews**\n","\n","Finally, we can use the final model to make predictions for new textual reviews.\n","\n","This is why we wanted the model in the first place.\n","\n","**Predicting the sentiment of new reviews involves following the same steps used to prepare the test data. Specifically, loading the text, cleaning the document, filtering tokens by the chosen vocabulary, converting the remaining tokens to a line, encoding it using the Tokenizer, and making a prediction**.\n","\n","We can make a prediction of a class value directly with the fit model by calling predict() that will return a value that can be rounded to an integer of 0 for a negative review and 1 for a positive review.\n","\n"]},{"cell_type":"code","metadata":{"id":"4Nq5EPje0ujf"},"source":["# classify a review as negative (0) or positive (1)\n","from keras.preprocessing.text import Tokenizer\n","\n","def predict_sentiment(review, vocab, tokenizer, model):\n","\t# clean\n","\ttokens = clean_doc(review)\n","\t# filter by vocab\n","\ttokens = [w for w in tokens if w in vocab]\n","\t# convert to line\n","\tline = ' '.join(tokens)\n","\t# encode\n","\tencoded = tokenizer.texts_to_matrix([line], mode='freq')\n","\t# prediction\n","\tyhat = model.predict(encoded, verbose=0)\n","\treturn round(yhat[0,0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u-lu6PbE0995"},"source":["We can now make predictions for new review texts."]},{"cell_type":"code","metadata":{"id":"3jztC4Mr1StN","executionInfo":{"status":"error","timestamp":1601436077491,"user_tz":240,"elapsed":2492,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"5463e86a-d3d7-40ab-c432-368700e50c9f","colab":{"base_uri":"https://localhost:8080/","height":236}},"source":["# test positive text\n","from keras.preprocessing.text import Tokenizer\n","tokenizer = Tokenizer\n","text = 'Best movie ever!'\n","print(predict_sentiment(text, vocab, tokenizer, model))\n","# test negative text\n","text = 'This is a bad movie.'\n","print(predict_sentiment(text, vocab, tokenizer, model))\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0fd88bbdb58b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Best movie ever!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# test negative text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'This is a bad movie.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'predict_sentiment' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"YPpPCuGM1gfx"},"source":["Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fx3X6OyF1mIS"},"source":["Ideally, we would fit the model on all available data (train and test) to create a final model and save the model and tokenizer to file so that they can be loaded and used in new software.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iBgjdg_b1_Zf"},"source":["Manage Vocabulary. Explore using a larger or smaller vocabulary. Perhaps you can get better performance with a smaller set of words.\n","Tune the Network Topology. Explore alternate network topologies such as deeper or wider networks. Perhaps you can get better performance with a more suited network.\n","Use Regularization. Explore the use of regularization techniques, such as dropout. Perhaps you can delay the convergence of the model and achieve better test set performance.\n","\n","\n","[link text](https://machinelearningmastery.com/train-final-machine-learning-model/)\n"]},{"cell_type":"code","metadata":{"id":"dfD9PjFi185z"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rxzHzird4cro"},"source":["**What is a Final Model?**\n","\n","A final machine learning model is a model that you use to make predictions on new data.\n","\n","That is, given new examples of input data, you want to use the model to predict the expected output. This may be a **classification (assign a label)** or a **regression (a real value)**.\n","\n","For example, whether the **photo is a picture of a dog or a cat**, or the **estimated number of sales for tomorrow**.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NHwJPcma5QhA"},"source":["The goal of your machine learning project is to arrive at a final model that performs the best, where “best” is defined by:\n","\n","**Data**: the historical data that you have available.\n","**Time**: the time you have to spend on the project.\n","**Procedure**: the data preparation steps, algorithm or algorithms, and the chosen algorithm configurations.\n","\n","In your project, you gather the data, spend the time you have, and discover the data preparation procedures, algorithm to use, and how to configure it.\n","\n","The final model is the pinnacle of this process, the end you seek in order to start actually making predictions.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yvcQ9Dk_5udv"},"source":["**The Purpose of Train/Test Sets**\n","\n","Why do we use train and test sets?\n","Creating a train and test split of your dataset is one method to quickly evaluate the performance of an algorithm on your problem.\n","\n","The training dataset is used to prepare a model, to train it.\n","\n","**We pretend the test dataset is new data where the output values are withheld from the algorithm. We gather predictions from the trained model on the inputs from the test dataset and compare them to the withheld output values of the test se**t.\n","\n","Comparing the predictions and withheld outputs on the test dataset allows us to compute a performance measure for the model on the test dataset. This is an estimate of the skill of the algorithm trained on the problem when making predictions on unseen data.\n","\n","**Let’s unpack this further**\n","\n","When we evaluate an algorithm, we are in fact evaluating all steps in the procedure, including how the training data was prepared (e.g. scaling), the choice of algorithm (e.g. kNN), and how the chosen algorithm was configured (e.g. k=3).\n","\n","The performance measure calculated on the predictions is an estimate of the skill of the whole procedure.\n","\n","We *** generalize the performance measure from***:\n","\n","“the skill of the procedure on the test set“\n","to\n","\n","“the skill of the procedure on unseen data“.\n","\n","\n","This is quite a leap and requires that:\n","\n","The procedure is sufficiently robust that the estimate of skill is close to what we actually expect on unseen data.\n","The choice of performance measure accurately captures what we are interested in measuring in predictions on unseen data.\n","The choice of data preparation is well understood and repeatable on new data, and reversible if predictions need to be returned to their original scale or related to the original input values.\n","The choice of algorithm makes sense for its intended use and operational environment (e.g. complexity or chosen programming language).\n","\n","A lot rides on the estimated skill of the whole procedure on the test set.\n","\n","In fact, using the train/test method of estimating the skill of the procedure on unseen data often has a high variance (unless we have a heck of a lot of data to split). This means that when it is repeated, it gives different results, often very different results.\n","\n","The outcome is that we may be quite uncertain about how well the procedure actually performs on unseen data and how one procedure compares to another.\n","\n","Often, time permitting, we prefer to use k-fold cross-validation instead.\n","\n","**The Purpose of k-fold Cross Validation**\n","\n","Why do we use k-fold cross validation?\n","\n","Cross-validation is another method to estimate the skill of a method on unseen data. Like using a train-test split.\n","\n","Cross-validation systematically creates and evaluates multiple models on multiple subsets of the dataset.\n","\n","This, in turn, provides a population of performance measures.\n","\n","We can calculate the mean of these measures to get an idea of how well the procedure performs on average.\n","We can calculate the standard deviation of these measures to get an idea of how much the skill of the procedure is expected to vary in practice.\n","\n","\n","This is also helpful for providing a more nuanced comparison of one procedure to another when you are trying to choose which algorithm and data preparation procedures to use.\n","\n","Also, this information is invaluable as you can use the mean and spread to give a confidence interval on the expected performance on a machine learning procedure in practice.\n","\n","\n","\n","Both train-test splits and k-fold cross validation are examples of resampling methods.\n","\n","**Why do we use Resampling Methods?**\n","\n","The problem with applied machine learning is that we are trying to model the unknown.\n","\n","On a given predictive modeling problem, the ideal model is one that performs the best when making predictions on new data.\n","\n","We don’t have new data, so we have to pretend with statistical tricks.\n","\n","The train-test split and k-fold cross validation are called resampling methods. Resampling methods are statistical procedures for sampling a dataset and estimating an unknown quantity.\n","\n","In the case of applied machine learning, we are interested in estimating the skill of a machine learning procedure on unseen data. More specifically, the skill of the predictions made by a machine learning procedure.\n","\n","Once we have the estimated skill, we are finished with the resampling method.\n","\n","If you are using a train-test split, that means you can discard the split datasets and the trained model.\n","If you are using k-fold cross-validation, that means you can throw away all of the trained models.\n","They have served their purpose and are no longer needed.\n","\n","You are now ready to finalize your model.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9opWOToT-E5V"},"source":["**How to Finalize a Model?**\n","\n","You finalize a model by applying the chosen machine learning procedure on all of your data.\n","\n","That’s it.\n","\n","With the finalized model, you can:\n","\n","Save the model for later or operational use.\n","Make predictions on new data.\n","What about the cross-validation models or the train-test datasets?\n","\n","They’ve been discarded. They are no longer needed. They have served their purpose to help you choose a procedure to finalize.\n"]},{"cell_type":"markdown","metadata":{"id":"Db_-wEne-s6h"},"source":["**Common Questions**\n","This section lists some common questions you might have.\n","\n","Why not keep the model trained on the training dataset?\n","and\n","\n","Why not keep the best model from the cross-validation?\n","You can if you like.\n","\n","You may save time and effort by reusing one of the models trained during skill estimation.\n","\n","This can be a big deal if it takes days, weeks, or months to train a model.\n","\n","Your model will likely perform better when trained on all of the available data than just the subset used to estimate the performance of the model.\n","\n","This is why we prefer to train the final model on all available data.\n","\n","Won’t the performance of the model trained on all of the data be different?\n","I think this question drives most of the misunderstanding around model finalization.\n","\n","Put another way:\n","\n","If you train a model on all of the available data, then how do you know how well the model will perform?\n","You have already answered this question using the resampling procedure.\n","\n","If well designed, the performance measures you calculate using train-test or k-fold cross validation suitably describe how well the finalized model trained on all available historical data will perform in general.\n","\n","If you used k-fold cross validation, you will have an estimate of how “wrong” (or conversely, how “right”) the model will be on average, and the expected spread of that wrongness or rightness.\n","\n","This is why the careful design of your test harness is so absolutely critical in applied machine learning. A more robust test harness will allow you to lean on the estimated performance all the more.\n","\n","Each time I train the model, I get a different performance score; should I pick the model with the best score?\n","Machine learning algorithms are stochastic and this behavior of different performance on the same data is to be expected.\n","\n","Resampling methods like repeated train/test or repeated k-fold cross-validation will help to get a handle on how much variance there is in the method.\n","\n","If it is a real concern, you can create multiple final models and take the mean from an ensemble of predictions in order to reduce the variance.\n","\n","I talk more about this in the post:\n","\n","Embrace Randomness in Machine Learning\n","Summary\n","In this post, you discovered how to train a final machine learning model for operational use.\n","\n","You have overcome obstacles to finalizing your model, such as:\n","\n","Understanding the goal of resampling procedures such as train-test splits and k-fold cross validation.\n","Model finalization as training a new model on all available data.\n","Separating the concern of estimating performance from finalizing the model.\n","Do you have another question or concern about finalizing your model that I have not addressed?\n","Ask in the comments and I will do my best to help."]}]}