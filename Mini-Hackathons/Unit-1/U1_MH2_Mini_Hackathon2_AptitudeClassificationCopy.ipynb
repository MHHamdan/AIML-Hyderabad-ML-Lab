{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"U1_MH2_Mini_Hackathon2_AptitudeClassificationCopy.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PsKRUcQh27Dp"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"C3BQbYtN2-5L"},"source":["## Problem Statement"]},{"cell_type":"markdown","metadata":{"id":"DP5Nf6UZ3Ej1"},"source":["The problem is to identify the subcategory and classify the question based on the group it belongs to.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WeHg23di3oHF"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"27fwuBVS3tF3"},"source":["At the end of the experiment, you will be able to understand:\n","\n","*   Beautiful Soup\n","*   Use NLTK package\n","*   Text Representation\n","*   Classification"]},{"cell_type":"code","metadata":{"cellView":"form","id":"nYG9AXM_oe--","executionInfo":{"status":"ok","timestamp":1601729177392,"user_tz":240,"elapsed":1325,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"1490026d-fcfe-4ff6-f1ce-40fcc04054c7","colab":{"base_uri":"https://localhost:8080/","height":261}},"source":["#@title  Mini Hackathon Walkthrough\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"320\" height=\"240\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/aiml_batch_15/preview_videos/Mini_Hackathon_Aptitude_Classification.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<video width=\"320\" height=\"240\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/aiml_batch_15/preview_videos/Mini_Hackathon_Aptitude_Classification.mp4\" type=\"video/mp4\">\n","</video>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"FL0Ve1abn6YJ"},"source":["## Dataset\n","Being able to classify the questions will be difficult in natural language processing. The dataset is taken from the TalentSprint aptitude questions which contains more than 20K questions.\n","\n","## Description\n","This dataset has the following columns:\n","1. **Category:** Gives the high-level categorization of the question\n","2. **Sub-Category:** Determines the type of questions\n","3. **Article:** Gives the article name of the question\n","4. **Questions:** Questions are listed\n","5. **Answers:** Contains answers\n"]},{"cell_type":"markdown","metadata":{"id":"ndQNKsjS7c04"},"source":["### Grading = 20 Marks"]},{"cell_type":"code","metadata":{"id":"C7ATuq_4hzBv","cellView":"form","executionInfo":{"status":"ok","timestamp":1601813480768,"user_tz":240,"elapsed":5854,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"4bb511db-094e-4cf0-f81e-5246ba343565","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#@title Download the datasets\n","from IPython import get_ipython\n","\n","ipython = get_ipython()\n","\n","def setup(): \n","    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Aptitude_Classification_data.csv\")\n","    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Mentors_Test_Data.csv\")\n","    from IPython.display import HTML, display\n","    print(\"Setup completed successfully\")\n","    return\n","\n","setup()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WYyfIzohaMMC","executionInfo":{"status":"ok","timestamp":1601813841966,"user_tz":240,"elapsed":346,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"430971f9-7916-404e-cd1c-e49ee50f07a6","colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["# Import Python Libraries\n","from bs4 import BeautifulSoup\n","import nltk\n","import re\n","import string\n","import warnings\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from nltk.stem import WordNetLemmatizer \n","from nltk import word_tokenize\n","from nltk.corpus import stopwords\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","nltk.download('wordnet')\n","warnings.filterwarnings('ignore')\n","nltk.download('punkt')\n","nltk.download(\"stopwords\")\n","nltk.download('averaged_perceptron_tagger')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"J0fDm4l6cQHY","executionInfo":{"status":"ok","timestamp":1601813501473,"user_tz":240,"elapsed":307,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"817db2a7-a4de-419f-b2be-5fa5045a7530","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Aptitude_Classification_data.csv  Mentors_Test_Data.csv  sample_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2DKmejLMh2YH"},"source":["##   **Stage 1**:  Dataset Preparation\n","\n","### 1 Mark -> Load the data set and prepare the data based on group allocation. \n","\n","Each group should consider their respective sub-categories as mentioned below:\n","\n","> Team A = Groups 1, 4, 7, 10, 13, 16;   &nbsp; &nbsp;   Sub-Category = Misspell words, Algebra, Percentages, Mathematical operations, Probability\n","\n","> Team B = Groups 2, 5, 8, 11, 14, 17; &nbsp; &nbsp;   Sub-Category = Finding Errors, Ratio and Proportion, Logarithms, Time and Distance, Simple and Compound Interest\n","\n","> Team C = Groups 3, 6, 9, 12, 15, 18;  &nbsp; &nbsp;  Sub-Category =  Synonyms and Antonyms, Time and Work, Permutations and Combinations, LCM and HCF, Profit and Loss\n","\n","\n","**Hint:** &nbsp; To access Sub-Categories from given Data, refer [link](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isin.html)"]},{"cell_type":"code","metadata":{"id":"rZ1vto-DAAvZ","executionInfo":{"status":"ok","timestamp":1601813520626,"user_tz":240,"elapsed":321,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"78adbd8c-a6d1-485b-b8ac-e02f7ef058ea","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# YOUR CODE HERE TO LOAD THE APTITUDE CLASSIFICATION DATASET & EXTRACT THE DATA BASED ON YOUR SUB-CATEGORIES\n","# Team C: \n","data = pd.read_csv(\"/content/Aptitude_Classification_data.csv\")\n","data.shape\n","\n"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4631, 5)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"fkZmBGxbPBY1","executionInfo":{"status":"ok","timestamp":1601813539663,"user_tz":240,"elapsed":288,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"1beaa629-cfa5-44e9-d7bb-e1eecb2c15df","colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["data.head()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Sub-Category</th>\n","      <th>Article</th>\n","      <th>Questions</th>\n","      <th>Answers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Verbal</td>\n","      <td>Misspell words</td>\n","      <td>chapter 1</td>\n","      <td>Which of the following is correct?\\n\\n\\n\\n\\n</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Quantitative</td>\n","      <td>Time and Distance</td>\n","      <td>Time and Distance - Model 05</td>\n","      <td>Rohan leaves point A and reaches point B in 6 ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Verbal</td>\n","      <td>Finding Errors</td>\n","      <td>44054</td>\n","      <td>Read the sentence to find out whether there is...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Quantitative</td>\n","      <td>Time and Work</td>\n","      <td>tech mahindra_5th August</td>\n","      <td>4 men can check exam papers in 8 days working ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Quantitative</td>\n","      <td>Permutations and Combinations</td>\n","      <td>AX10DEPT01</td>\n","      <td>From 13 persons, how many ways of selection of...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Category  ... Answers\n","0        Verbal  ...       2\n","1  Quantitative  ...       2\n","2        Verbal  ...       2\n","3  Quantitative  ...       2\n","4  Quantitative  ...       2\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"u3LZ-WjpPQVD","executionInfo":{"status":"ok","timestamp":1601813743426,"user_tz":240,"elapsed":276,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["# Boolean Indexing in Pandas :  filter values of a column based on conditions from another set of columns from a Pandas Dataframe\n","TeamC = ['Synonyms and Antonyms', 'Time and Work', 'Permutations and Combinations', 'LCM and HCF', 'Profit and Loss']\n","DataC = data.loc[data['Sub-Category'].isin(TeamC)]\n","\n","\n"," "],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"J5Md4ePXWaKa","executionInfo":{"status":"ok","timestamp":1601814320031,"user_tz":240,"elapsed":334,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"947c24dd-da8a-4794-826c-593d474fc971","colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["DataC.head()"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Sub-Category</th>\n","      <th>Article</th>\n","      <th>Questions</th>\n","      <th>Answers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>Quantitative</td>\n","      <td>Time and Work</td>\n","      <td>tech mahindra_5th August</td>\n","      <td>4 men can check exam papers in 8 days working ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Quantitative</td>\n","      <td>Permutations and Combinations</td>\n","      <td>AX10DEPT01</td>\n","      <td>From 13 persons, how many ways of selection of...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Quantitative</td>\n","      <td>Time and Work</td>\n","      <td>2015</td>\n","      <td>&lt;span style=\\\"font-size: small;\\\"&gt;&lt;span lang=\\...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Quantitative</td>\n","      <td>Time and Work</td>\n","      <td>2015</td>\n","      <td>&lt;span style=\\\"font-size: small;\\\"&gt;&lt;span lang=\\...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Quantitative</td>\n","      <td>Profit and Loss</td>\n","      <td>PLT10</td>\n","      <td>The ratio between the sale price and the cost ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Category  ... Answers\n","3  Quantitative  ...       2\n","4  Quantitative  ...       2\n","6  Quantitative  ...       4\n","7  Quantitative  ...       3\n","8  Quantitative  ...       1\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"GsZwcSvcyADe","executionInfo":{"status":"ok","timestamp":1601813771439,"user_tz":240,"elapsed":291,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"35de3ee2-f3c1-4618-b639-f39a8cbd1216","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["DataC.shape"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1504, 5)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"5RzclUxhkn67"},"source":["## **Stage 2:** Data Pre-Processing\n","\n","### 3 Marks -> Clean and Transform the data into a specified format\n","\n","*   Remove the rows of the Questions column which contains blank / NaN.\n","\n","\n","*   Few set of questions have HTML tags within the question.\n","  - You can use Beautiful Soup library to convert HTML into text (Refer **\"Dealing with HTML\"** section from this [link](https://www.nltk.org/book/ch03.html).)\n","\n","\n","*  Consider Question column as feature and Sub-category as target variable. Convert Sub-category into numerical.\n","\n","*  Drop the unwanted columns\n","\n","\n","  **Hint:** Use Label Encoder for obtaining a numeric representation, refer to the [link](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). "]},{"cell_type":"code","metadata":{"id":"6WcZeO5firwQ","executionInfo":{"status":"ok","timestamp":1601813846758,"user_tz":240,"elapsed":392,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["# Intializing nltk requirements for pre-processing\n","lemmatizer = WordNetLemmatizer()\n","stoplist = set(stopwords.words('english')) "],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"oCipIJHLjAAn","executionInfo":{"status":"ok","timestamp":1601813877162,"user_tz":240,"elapsed":300,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["# Tokenize the sentence and get vocab words\n","def Tokenize(AllQuestions):\n","  pre_processed_words = []\n","  for each in AllQuestions:\n","    words = word_tokenize(each)\n","    words = [lemmatizer.lemmatize(w) for w in words]\n","    pre_processed_words.extend(words)\n","\n","  pre_processed_words = set(pre_processed_words)\n","\n","  pre_processed_words = [word for word in pre_processed_words if word not in stoplist]\n","  return pre_processed_words"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"Whj-50DlTwyZ","executionInfo":{"status":"ok","timestamp":1601773614079,"user_tz":240,"elapsed":589,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"b0075ebd-a990-49ba-f0ff-dcac0d724cd3","colab":{"base_uri":"https://localhost:8080/","height":218}},"source":["# YOUR CODE HERE for BeatifulSoup\n","DataC['Questions'] = [BeautifulSoup(text).get_text() for text in DataC['Questions'] ]\n","DataC.Questions"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3       4 men can check exam papers in 8 days working ...\n","4       From 13 persons, how many ways of selection of...\n","6       Suppose q is the number of workers employed by...\n","7       There is a group of persons each of them can c...\n","8       The ratio between the sale price and the cost ...\n","                              ...                        \n","4617    In how many ways can a committee of 5 members ...\n","4618    A Fruit seller buys some oranges at the rate o...\n","4626    Construction of a road was entrusted to a civi...\n","4628    Choose the word or phrase which is the best sy...\n","4629                        Give the antonym of CENSURE\\n\n","Name: Questions, Length: 1504, dtype: object"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"FAWccth92m44","executionInfo":{"status":"ok","timestamp":1601773670210,"user_tz":240,"elapsed":254,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"53410959-31bf-4781-c998-6c4b854be77b","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["DataC.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Category', 'Sub-Category', 'Article', 'Questions', 'Answers'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"p89qT7Re3S4G"},"source":["d1 = DataC.drop(['Category','Article','Answers'], axis=1)\n","d1.to_csv('DataC.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YAAOwE-iDE_d"},"source":["DataC1 = pd.read_csv('DataC.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zP4svG0HJ1jv","executionInfo":{"status":"ok","timestamp":1601773674585,"user_tz":240,"elapsed":290,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"74f0d0a6-8288-494c-de95-1b9a33619b67","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X = DataC1.drop(\"Sub-Category\",1)   #Features \n","y = DataC1[\"Sub-Category\"]          #Target Variable\n","\n","X.shape, y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1504, 2), (1504,))"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"VaMiP9gextc5","executionInfo":{"status":"ok","timestamp":1601773676227,"user_tz":240,"elapsed":233,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"3c76a053-440e-4921-8d9c-3bbeb3d26a16","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn import preprocessing\n","le = preprocessing.LabelEncoder() # DO NOT CHANGE THIS LINE as we will be using for the Test evaluation.\n","\n","# YOUR CODE HERE for Fit label encoder and return encoded labels\n","le.fit(DataC1['Sub-Category'])\n","print(list(le.classes_))\n","DataC1['Sub-Category'] = le.fit_transform(DataC1['Sub-Category'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['LCM and HCF', 'Permutations and Combinations', 'Profit and Loss', 'Synonyms and Antonyms', 'Time and Work']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lZ7Lz9Z7zvXF","executionInfo":{"status":"ok","timestamp":1601773677252,"user_tz":240,"elapsed":273,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"fa228c07-0c17-4ad8-d15a-ad428a0cd628","colab":{"base_uri":"https://localhost:8080/","height":218}},"source":["DataC1['Sub-Category'] "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       4\n","1       1\n","2       4\n","3       4\n","4       2\n","       ..\n","1499    1\n","1500    2\n","1501    4\n","1502    3\n","1503    3\n","Name: Sub-Category, Length: 1504, dtype: int64"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"7AOtxyuBtdKv"},"source":["## **Stage 3:** Text representation using Bag of Words (BOW)\n","\n","### 3 Marks -> a) Get valid words from all questions & add them to a list.\n","\n","\n","Treat each question as a separate document and get the list of words using the following:\n","1.   Split the sentence into words\n","\n","2.   Remove Stop words. Use NLTK packages for getting the Stop words.\n","\n","3.   Replace proper names with \"name\" \n","  - Example: \"Rahul\" -> \"name\"\n","       \n","4.   Remove the single white space character (\\n, \\t, \\f, \\r), refer [link](https://developers.google.com/edu/python/regular-expressions)\n","\n","5.   Ignore words whose length is less than 3 (Eg: 'is', 'a').\n","\n","6.   Remove punctuation and non-alphabetic words\n","\n","7.   Convert the text to lowercase\n","\n","8.   Use the Porter Stemmer to normalize the words\n","\n","\n","Refer [link](https://www.nltk.org/book/ch03.html) for extracting the words.\n","\n","Refer [link](https://medium.com/free-code-camp/an-introduction-to-bag-of-words-and-how-to-code-it-in-python-for-nlp-282e87a9da04) for more information."]},{"cell_type":"code","metadata":{"id":"JuSPlfvG3B2D","executionInfo":{"status":"ok","timestamp":1601773684800,"user_tz":240,"elapsed":1769,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"dce79bc6-c4c1-4601-9d75-41ca85b9dd2e","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["from nltk.stem import WordNetLemmatizer \n","  \n","lemmatizer = WordNetLemmatizer() \n","  \n","print(\"plays :\", lemmatizer.lemmatize(\"plays\")) \n","print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["plays : play\n","corpora : corpus\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jLyMy2q9rGK_"},"source":["def extract_words(question):\n","    # YOUR CODE HERE\n","    # Hint: Extract words for each question using the above 8 instructions.\n","    # remove single white space \n","    #tokens = re.search(r'\\n \\t \\f \\r', question)\n","    \n","    \n","    tokens = re.sub(r\"\\s+\", \"\", question)\n","    tokens = word_tokenize(question)\n","\n","    # Remove stop words\n","    tokens = [word for word in tokens if word.isalpha()]\n","    # Filter out stop words\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [w for w in tokens if not w in stop_words]\n","    # Filter out short tokens\n","    tokens = [word for word in tokens if len(word) > 4]\n","    #print(tokens)\n","    # Remove proper name\n","    tokensTags = nltk.tag.pos_tag(tokens)\n","    tokens = [word for word,tag in tokensTags if tag != 'NNP' and tag != 'NNPS']\n","    tokens = ['name' if  tag == 'NNP' else word for word,tag in tokensTags]\n","    tokens1 = str.maketrans('', '', string.punctuation)\n","    tokens = [w.translate(tokens1).lower() for w in tokens]\n","    #convert text to lower case\n","    tokens = [w.lower() for w in tokens]\n","    # Normalize the word using porter stemmer\n","    porter = nltk.PorterStemmer()\n","    tokens = [porter.stem(t) for t in tokens]\n","    #tokens = [lemmatizer.lemmatize(l) for l in tokens]\n","\n","\n","       \n","    return tokens\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ty4DphvV7oM"},"source":["# Use the function to extract words for all questions\n","def tokenize(questions): # The method iterates all the sentences and adds the extracted word into an array.\n","  valid_words = []\n","  for question in questions.itertuples(index=True, name='Pandas'):\n","    #print (getattr(row, \"Questions\"))\n","    words = extract_words(getattr(question, \"Questions\"))\n","    \n","    for word in words:\n","      if word not in valid_words:\n","        valid_words.append(word)\n","    #valid_words.extend(words)\n","    #valid_words.append(words)\n","    #valid_words = sorted(list(set(valid_words)))\n","    #print(len(valid_words))  \n","  return valid_words\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J0QSIOEkEFfA","executionInfo":{"status":"ok","timestamp":1601773727451,"user_tz":240,"elapsed":2246,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"c4d0c42c-a2b3-48d3-9373-732d520302a5","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","vocab = tokenize(DataC1)\n","print(len(vocab))\n","word_vector_size = len(vocab)\n","#print(valid_words)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1286\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rSU2s0A-GtaS","executionInfo":{"status":"ok","timestamp":1601773735092,"user_tz":240,"elapsed":267,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"fbbfb6b8-2b9a-45e5-aedf-d4a1fa7f646c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(vocab)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1286"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"9csJ86Bivg1H"},"source":["### 4 Marks -> b) Generate vectors that can be used by the machine learning algorithm\n","\n","\n","1.   The length of the vector for each question will be the length of the valid words. Initialize each vector with all Zeros\n","\n","2.   Compare each valid word with the words in question and generate the vectors based on the counter frequency of the word in that question.\n","\n"]},{"cell_type":"code","metadata":{"id":"k-xx0qAqAxKf"},"source":["def generate_vectors(question):\n","    # YOUR CODE HERE\n","    # Hint: Initialize each vector with all zeros. \n","  \n","    bow_representation = np.zeros(len(vocab))\n","\n","\n","    # Extracting words for each question and count the words\n","    words = extract_words(question)\n","    word_dict = Counter(words)\n","    \n","    for word in word_dict.keys():\n","      bow_representation[vocab.index(word)] +=word_dict[word]\n","    print(bow_representation)\n","    return bow_representation\n","    # YOUR CODE HERE \n","    # Hint: If the word is in valid words then generate the vectors based on the counter frequency of the word in that question."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mnQEkbj--Zof"},"source":["# Use the above function for collecting the vectors of all questions into a list.\n","# YOUR CODE HERE\n","vectors_of_all_questions = []\n","for question in DataC1.Questions:\n","  vectors_of_all_questions.append(generate_vectors(question))\n","vectors_of_all_questions = np.array(vectors_of_all_questions)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I-Og4IX5ZYRm"},"source":["## **Stage 4:** Classification\n","\n","### 3 Marks -> Perform a Classification \n","\n","1.   Identify the features and labels\n","\n","2.   Use train_test_split for splitting the train and test data\n","\n","3.   Fit your model on the train set using fit() and perform prediction on the test set using predict()\n","\n","4. Get the accuracy of the model\n","\n","## Expected Accuracy above 90%\n"]},{"cell_type":"code","metadata":{"id":"oPF9UF7hN08S","executionInfo":{"status":"ok","timestamp":1601773827006,"user_tz":240,"elapsed":293,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"6aee41d3-4bec-429b-af64-25352adc77df","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["features_X = vectors_of_all_questions   #Features \n","labels_y = DataC1['Sub-Category'] #Target Variable\n","labels_y = labels_y.to_numpy().reshape(-1,1)\n","features_X.shape, labels_y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1504, 1286), (1504, 1))"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"FjlN6HSMQkqm","executionInfo":{"status":"ok","timestamp":1601774030869,"user_tz":240,"elapsed":311,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"176aeb34-9e66-4cfb-a4f4-8a4fe6cc5b67","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["from sklearn.model_selection import train_test_split\n","# YOUR CODE HERE\n","X_train,X_test,y_train,y_test=train_test_split(features_X,labels_y,test_size=0.33,random_state=42)\n","\n","print(type(y_train))\n","#neigh = KNeighborsClassifier(n_neighbors=5)\n","neigh = DecisionTreeClassifier(criterion=\"entropy\", max_depth=50)\n","neigh.fit(X_train, y_train)\n","y_pred = neigh.predict(X_test)\n","score = accuracy_score(y_pred, y_test)\n","score\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'>\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.9134808853118712"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"5gyV1StGVBjj","executionInfo":{"status":"ok","timestamp":1601774028284,"user_tz":240,"elapsed":286,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"d0a1c3a6-11f0-4cc9-c017-075d8ce98cd3","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_pred= neigh.predict(X_train)\n","score = accuracy_score(X_pred, y_train)\n","score"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9980139026812314"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"markdown","metadata":{"id":"BHxULg4OggQe"},"source":["## **Stage 5:** Evaluation (This is for Mentors)\n","\n","### 6 Marks -> Evaluate with the given test data \n","\n","1.  Loading the Test data\n","\n","2.  Converting the Test data into vectors\n","\n","3.  Pass through the model and verify the accuracy\n","\n","## Expected Accuracy above 90%\n"]},{"cell_type":"code","metadata":{"id":"BWM4Boa4zXAs","executionInfo":{"status":"error","timestamp":1601774035042,"user_tz":240,"elapsed":385,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"7f0500f1-ab02-4095-b32c-c5868c34e065","colab":{"base_uri":"https://localhost:8080/","height":381}},"source":["# YOUR CODE HERE for selecting the trained classifier model, eg: MODEL = decision_tree\n","MODEL = neigh\n","\n","Test_data = pd.read_csv(\"Mentors_Test_Data.csv\")\n","Test_data = Test_data[Test_data['Sub-Category'].isin(le.classes_)]\n","labels = le.transform(Test_data['Sub-Category'])\n","Test_questions= Test_data['Questions']\n","\n","Test_BOW=[]\n","for TQ in Test_questions: \n","  Test_vectors = generate_vectors(TQ) \n","  Test_BOW.append(Test_vectors)\n","\n","predict = MODEL.predict(Test_BOW) \n","accuracy_score(labels, predict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0. 0. 0. ... 0. 0. 0.]\n","[0. 0. 0. ... 0. 0. 0.]\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-63c7712da546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mTest_BOW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mTQ\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTest_questions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mTest_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mTest_BOW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-e767d1d21b5e>\u001b[0m in \u001b[0;36mgenerate_vectors\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mbow_representation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_representation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbow_representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: 'goat' is not in list"]}]},{"cell_type":"code","metadata":{"id":"e3hHL5Biz_SR"},"source":[""],"execution_count":null,"outputs":[]}]}