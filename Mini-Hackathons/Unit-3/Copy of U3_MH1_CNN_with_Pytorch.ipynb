{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of U3_MH1_CNN_with_Pytorch.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hVMoZwHL4RTh"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"4EX7dr584we6"},"source":["## Problem Statement"]},{"cell_type":"markdown","metadata":{"id":"MjsV_asO4yL_"},"source":["To identify and classify images as cats or dogs"]},{"cell_type":"markdown","metadata":{"id":"JwfwDwfu6MXx"},"source":["## Learning Objectives\n","\n","At the end of the experiment, you will be able to :\n","\n","* Load and prepare images for the model using Pytorch\n","* Develop a CNN model and improve model performance"]},{"cell_type":"code","metadata":{"id":"qOvtkHYXZw2D","cellView":"form"},"source":["#@title Mini-hackathon walkthrough\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"500\" height=\"300\" controls>\n","  <source src=\"https://cdn.talentsprint.com/aiml/aiml_2020_b14_hyd/experiment_details_backup/Pytorch_CNN_cats_and_dogs.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YnkmRa9Uozvd"},"source":["## Dataset\n","\n","The Dogs and Cats dataset is a standard computer vision dataset that involves classifying photos as either containing a dog or cat. The train folder contains 22,500 images of dogs and cats. Each image in this folder has the label as part of the filename. The test folder contains 2,500 images, named according to a numeric id. "]},{"cell_type":"markdown","metadata":{"id":"gsyDey3To9hE"},"source":["## Grading = 20 Marks"]},{"cell_type":"markdown","metadata":{"id":"0vt5qAcHpBPO"},"source":["## Setup Steps"]},{"cell_type":"code","metadata":{"id":"PYipBJdqnkEw","cellView":"form"},"source":["#@title Run this cell to download the dataset\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","\n","def setup():\n","   ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Cat_Dog_data.zip\")\n","   ipython.magic(\"sx unzip -qq Cat_Dog_data.zip\")\n","   print (\"Setup completed successfully\")\n","   return\n","\n","setup()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NLECiqpcdQTQ"},"source":["## Basic Pytorch packages\n","\n","**torchvision:**  This package is used to load and prepare the dataset. Using this package we can perform/apply transformations on the input data.\n","\n","**transforms:**  This package is  used to perform preprocessing on images and operations sequentially. \n","\n","**nn:**  This package provides an easy and modular way to build and train simple or complex neural networks.\n","\n","**optim:** This package is used for  implementing various optimization algorithms"]},{"cell_type":"code","metadata":{"id":"MXq346qzqCdh"},"source":["# Import Libraries\n","import matplotlib.pyplot as plt\n","import torch\n","from torchvision import datasets, transforms, models\n","from torch import nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torch.autograd import Variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A-B9q2loRGyH"},"source":["## **Stage 1:** Define Transformations and import data"]},{"cell_type":"markdown","metadata":{"id":"J6XWrer9It5R"},"source":["### 2 Marks - > Compose multiple transformations with the following conditions\n","\n","1. Transform image size to 128 by using Resize()\n","\n","2. Convert image to Grayscale\n","\n","3. Transform the image into a number using tensor\n","\n","4. Normalize the tensor image with 0.5\n","\n","[Hint](https://pytorch.org/docs/stable/torchvision/transforms.html)"]},{"cell_type":"code","metadata":{"id":"qUkNUd_dqIzv"},"source":["image_size = (128,128)\n","\n","transformations =  # YOUR CODE HERE for defining Transformation for an image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2WpDKir7PheQ"},"source":["### 1 Mark -> Load the dataset with the defined transformations\n"," \n","PyTorch includes a package called torchvision which is used to load and prepare the dataset. It includes two basic functions namely Dataset and DataLoader which helps in the transformation and loading of the dataset.\n","\n","1. Dataset is used to read and transform a data point from the given dataset.  Note that, the data is not loaded on memory by now.\n","\n","2. DataLoader is used to shuffle and batch the data. It can be used to load the data in parallel with multiprocessing workers. The Data loader reads the data and puts it into memory.\n","\n","\n","\n","[Hint](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)"]},{"cell_type":"code","metadata":{"id":"ls6gI08XH2ak"},"source":["batch_size = 100 \n","\n","train_set = datasets.ImageFolder('/content/Cat_Dog_data/train', transform = transformations)\n","\n","# YOUR CODE HERE for the DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xPkXumN5P1ed"},"source":["### 2 Marks -> Plot the 5 images of Cats and 5 images of Dogs"]},{"cell_type":"code","metadata":{"id":"2SeTUS2cPwSL"},"source":["# YOUR CODE HERE for plotting the images"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m9Yv-pcJVHYh"},"source":["## **Stage2:** CNN Model\n","\n","Neural Networks are inherited from the nn.Module class.\n","\n","Define a neural network by using two functions \\__init__ and forward function.\n","\n","1. In the \\__init__  function, perform a series of convolutions and pooling operations to detect the features. Apply a fully connected layer on top of these features. Apply LogSoftmax at the output layer to improve the performance.\n","\n","2. The forward function is called on the Neural Network which takes the inputs and passes through the different layers that have been defined in the \\__init__.  The output of both convolution and pooling layers is 3D whereas a fully connected layer expects a 1D vector of numbers. So flatten the output of the final pooling layer to a vector and that becomes the input to the fully connected layer.\n","\n","[Hint](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_convolutional_neuralnetwork/)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OvZJHX_CahM9"},"source":["### 5 Marks -> Create CNN Model\n"]},{"cell_type":"code","metadata":{"id":"qsCOPyfABc7E"},"source":["class CNNModel(nn.Module):\n","    def __init__(self):\n","        super(CNNModel, self).__init__()\n","        \n","        # Convolution Layer 1 \n","        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2) # output size of the first convolutional layer is 16*128*128\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.relu1 = nn.ReLU()\n","        # Maxpool for the Convolutional Layer 1\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=4, stride=4) # Maxpooling reduces the size by kernel size. After Maxpooling the output size is 16*32*32\n","     \n","\n","        # YOUR CODE HERE for defining more number of Convolutional layers with Maxpool as required (Hint: Use at least 3 convolutional layers for better performance)\n","\n","        \n","\n","        \n","        # YOUR CODE HERE for defining the Fully Connected Layer and also define LogSoftmax\n","        \n","\n","\n","    \n","    def forward(self, x):\n","        # Convolution Layer 1 and Maxpool\n","        out = self.cnn1(x)\n","        out = self.bn1(out)\n","        out = self.relu1(out)\n","        out = self.maxpool1(out)\n","        \n","        # YOUR CODE HERE for the Convolutional Layers and Maxpool based on the defined Convolutional layers\n","       \n","\n","\n","\n","        # YOUR CODE HERE for flattening the output of the final pooling layer to a vector. Flattening is simply arranging the 3D volume of numbers into a 1D vector\n","        \n","\n","\n","        \n","        # YOUR CODE HERE for returning the output of LogSoftmax after applying Fully Connected Layer\n","        \n","      "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YmpdBc4mabIo"},"source":["### 1 Mark -> Create an instance of the model and Declare the loss function and optimizer\n"]},{"cell_type":"code","metadata":{"id":"1OFWuGmq05ZK"},"source":["# To run the training on GPU\n","print(torch.cuda.is_available())\n","\n","device  =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wkt8lKQtCIWD"},"source":["model = CNNModel()\n","model = model.to(device)\n","print(model)\n","\n","#criterion = # YOUR CODE HERE : Explore and declare loss function\n","\n","#optimizer = # YOUR CODE HERE : Explore on the optimizer and define with the learning rate\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T5nF5pwKQ2t1"},"source":["## **Stage 3:** Train the Model and validate it continuously to calculate the loss and accuracy for the train dataset across each epoch.\n","\n","### Expected training accuracy is above 90%"]},{"cell_type":"markdown","metadata":{"id":"ZLSCK_iRgyHA"},"source":["### 5 Marks -> Iterate over images in the train_loader and perform the following steps. \n","\n","1. First, we zero out the gradients using zero_grad()\n","\n","2. We pass the data to the model. Convert the data to GPU before passing data  to the model\n","\n","3. We calculate the loss using a Loss function\n","\n","4. Perform Backward pass using backward() to update the weights\n","\n","5. Optimize and predict by using the torch.max()\n","\n","6. Calculate the accuracy of the train dataset\n","\n","[Hint](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_convolutional_neuralnetwork/)"]},{"cell_type":"code","metadata":{"id":"2Ot89MxKavVy"},"source":["# YOUR CODE HERE. This will take time\n","\n","# Record loss and accuracy of the train dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K5BJIQzgHa0k"},"source":["## **Stage 4:** Testing Evaluation for CNN model\n","\n","### Expected performance of test evaluation is above 90%"]},{"cell_type":"markdown","metadata":{"id":"T_kKqw_drYXk"},"source":["### 4 Marks -> Evaluate model with the given test data\n","\n","1. Transform and load the test images.\n","\n","2. Pass the test data through the model (network) to get the outputs\n","\n","3. Get the predictions from a maximum value using torch.max\n","\n","4. Compare with the actual labels and get the count of the correct labels\n","\n","5. Calculate the accuracy based on the count of correct labels"]},{"cell_type":"code","metadata":{"id":"WmBoDOeptJfe"},"source":["val_set = datasets.ImageFolder('/content/Cat_Dog_data/test',transform = transformations)\n","\n","# YOUR CODE HERE for the DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPZCUolhaE2v"},"source":["model.eval()\n","# YOUR CODE HERE for calculating the accuracy"],"execution_count":null,"outputs":[]}]}