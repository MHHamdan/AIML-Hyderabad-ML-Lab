{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 18)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the datasets\n",
    "train = pd.read_csv('Train_Kaggle.csv').query('ProductCategory == \"WomenClothing\"') # 84 rows and 4 cols\n",
    "test = pd.read_csv('Test_Kaggle.csv').query('ProductCategory == \"WomenClothing\"')\n",
    "#train = pd.read_csv('Train_Kaggle.csv')\n",
    "#test = pd.read_csv('Test_Kaggle.csv')\n",
    "weather = pd.read_excel(\"WeatherData.xlsx\")\n",
    "economic = pd.read_excel(\"MacroEconomicData.xlsx\")\n",
    "holiday = pd.read_excel(\"Events_HolidaysData.xlsx\")\n",
    "economic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'MonthDate', 'Event', 'DayCategory'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(holiday.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 4) (12, 4)\n"
     ]
    }
   ],
   "source": [
    "# Check missing values in each data set\n",
    "train.isnull().sum() # There are 4 missing values in women sales\n",
    "train\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(train.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 2) (12, 2)\n"
     ]
    }
   ],
   "source": [
    "# Pre process train dataset for ease\n",
    "def preprocess(dataset):\n",
    "    dataset.columns = ['year','month','productcategory','target'] #Renamed the columns\n",
    "    dataset[['year','month']] = dataset[['year','month']].astype(str)\n",
    "    dataset['year-month'] = dataset.year.str[:4] + \"-\" + dataset.month.str[:2] # Add a new column to join later\n",
    "    dataset = dataset[['target','year-month']]\n",
    "    return dataset\n",
    "train = preprocess(train)\n",
    "test = preprocess(test)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned the weatherdata and downloaded onto local.\n",
    "weather_2009 = pd.read_csv(\"WeatherData2009.csv\")\n",
    "weather_2010 = pd.read_csv(\"WeatherData2010.csv\")\n",
    "weather_2011 = pd.read_csv(\"WeatherData2011.csv\")\n",
    "weather_2012 = pd.read_csv(\"WeatherData2012.csv\")\n",
    "weather_2013 = pd.read_csv(\"WeatherData2013.csv\")\n",
    "weather_2014 = pd.read_csv(\"WeatherData2014.csv\")\n",
    "weather_2015 = pd.read_csv(\"WeatherData2015.csv\")\n",
    "weather_2016 = pd.read_csv(\"WeatherData2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process weather\n",
    "def process_weather(df):\n",
    "    # Rename columns for ease\n",
    "    df.columns = ['year', 'month','day','temp_high','temp_avg','temp_low','dew_point_high','dew_point_avg',\n",
    "                  'dew_point_low','humidity_high','humidity_avg','humidity_low','pressure_high','pressure_avg','pressure_low',\n",
    "                 'visibility_high','visibility_avg','visibility_low','wind_low','wind_avg','wind_high','precip_sum','weatherevent']\n",
    "    # Convert year and day into strings\n",
    "    df[['year', 'day','month','precip_sum','weatherevent']] = df[['year', 'day','month','precip_sum','weatherevent']].astype(str)\n",
    "    \n",
    "    # Convert all other columns to numerics\n",
    "    df[['temp_high','temp_avg','temp_low','dew_point_high','dew_point_avg',\n",
    "                  'dew_point_low','humidity_high','humidity_avg','humidity_low','pressure_high','pressure_avg','pressure_low',\n",
    "                 'visibility_high','visibility_avg','visibility_low','wind_low','wind_avg','wind_high']] = df[['temp_high','temp_avg','temp_low','dew_point_high','dew_point_avg',\n",
    "                  'dew_point_low','humidity_high','humidity_avg','humidity_low','pressure_high','pressure_avg','pressure_low',\n",
    "                 'visibility_high','visibility_avg','visibility_low','wind_low','wind_avg','wind_high']].apply(pd.to_numeric, errors = \"coerce\")\n",
    "    \n",
    "    # Fill missing values with median of that column # Try mode/mean\n",
    "    df = df.fillna(df.median())\n",
    "\n",
    "    # Scaled all the numerical attributes using range method (simple custom function below)\n",
    "    df_num = df.select_dtypes(include=[np.number]) # Only include numeric columns\n",
    "    df_norm = (df_num - df_num.mean()) / (df_num.max() - df_num.min()) # Scale the numeric col\n",
    "    df[df_norm.columns] = df_norm # Add them back to the original dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_weather(df):\n",
    "    #Convert year to int\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    # Group by month all the weather attributes\n",
    "    df_aggregate_weather = df.groupby('month').mean() \n",
    "    \n",
    "    #Insert the month columns\n",
    "    month = [\"4\", \"8\", \"12\", \"2\", \"1\",\"7\", \"6\", \"3\", \"5\", \"11\", \"10\", \"9\"] \n",
    "    df_aggregate_weather.insert(loc=0, column='month', value=month)\n",
    "    \n",
    "    # Convert year back for str\n",
    "    df_aggregate_weather['year'] = df_aggregate_weather['year'].astype(str)\n",
    "    \n",
    "    # Insert a new column 'year-month' that would be useful for future join\n",
    "    df_aggregate_weather['year-month'] = df_aggregate_weather.year.str[:4] + \"-\" + df_aggregate_weather.month.str[:2]\n",
    "    \n",
    "    # Convert month back to int\n",
    "    df_aggregate_weather['month'] = df_aggregate_weather['month'].astype(int)\n",
    "    return df_aggregate_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = aggregate_weather(process_weather(weather_2009)) # 12 rows 21 columns\n",
    "df2 = aggregate_weather(process_weather(weather_2010)) # 12 rows 21 columns\n",
    "df3 = aggregate_weather(process_weather(weather_2011)) # 12 rows 21 columns\n",
    "df4 = aggregate_weather(process_weather(weather_2012)) # 12 rows 21 columns\n",
    "df5 = aggregate_weather(process_weather(weather_2013)) # 12 rows 21 columns\n",
    "df6 = aggregate_weather(process_weather(weather_2014)) # 12 rows 21 columns\n",
    "df7 = aggregate_weather(process_weather(weather_2015)) # 12 rows 21 columns\n",
    "df8 = aggregate_weather(process_weather(weather_2016)) # 12 ros 21 columns\n",
    "# clean_weather(weather_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 22) (12, 22)\n"
     ]
    }
   ],
   "source": [
    "# Merge with the train set\n",
    "df_new = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8])\n",
    "train_weather = train.merge(df_new, on='year-month', how = 'left')\n",
    "test_weather = test.merge(df_new, on='year-month', how = 'left')\n",
    "\n",
    "print(train_weather.shape, test_weather.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_weather #184 ros 22 cols\n",
    "#test_weather #12 rows 22 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 19) (72, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_weather = train_weather.drop(['year-month','year'], axis =1).iloc[:,1:]\n",
    "Y = train_weather[['target']] #Y = train[\"target\"]\n",
    "print(X_train_weather.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 19)"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_weather = test_weather.drop(['year-month','year','target'], axis =1)\n",
    "X_test_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecocnomic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_economic(df):\n",
    "    # Rename columns for ease\n",
    "    df.columns = ['year-month', 'gdp','realgdp','cpi','party',\n",
    "                  'unemployment','interestrate',\n",
    "                  'financerate','wagesperhour','adv',\n",
    "                  'cotton','cottonchange','planted','harvested','yield',\n",
    "                 'production','usage','exports']\n",
    "    # Convert year into strings\n",
    "    df[['year-month']] = df[['year-month']].astype(str)\n",
    "    \n",
    "    # Drop Adversitising, Party\n",
    "    df = df.drop(['adv','party'], axis=1)\n",
    "    # Convert all other columns to numerics\n",
    "    df[['gdp','realgdp','cpi','unemployment','interestrate',\n",
    "       'financerate','wagesperhour','cotton','cottonchange','planted','harvested','yield',\n",
    "                 'production','usage','exports']] = df[['gdp','realgdp','cpi','unemployment','interestrate',\n",
    "       'financerate','wagesperhour','cotton','cottonchange','planted','harvested','yield',\n",
    "                 'production','usage','exports']].apply(pd.to_numeric, errors = \"coerce\")\n",
    "    \n",
    "    # Fill missing values with median of that column # Try mode/mean\n",
    "    df = df.fillna(df.median())\n",
    "\n",
    "    # Scaled all the numerical attributes using range method (simple custom function below)\n",
    "    df_num = df.select_dtypes(include=[np.number]) # Only include numeric columns\n",
    "    df_norm = (df_num - df_num.mean()) / (df_num.max() - df_num.min()) # Scale the numeric col\n",
    "    df[df_norm.columns] = df_norm # Add them back to the original dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 19)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_weath_econ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 35) (36, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "# Merging Economic Data with train_weather\n",
    "\n",
    "#train_weather_economic = pd.concat([X_train_weather, X_test_weather], axis=0)\n",
    "train_weath_econ = pd.concat([train_weather, process_economic(economic.iloc[0:36,:])], axis=1)\n",
    "train_weath_econ = train_weath_econ.drop(['year-month','year'],axis=1) # 84 rows & 36 cols\n",
    "# # Merging Economic Data with test_weather\n",
    "#test_weath_econ = pd.read_excel(\"MacroEconomicData.xlsx\") # 12 rows 36 cols\n",
    "test_weath_econ = pd.concat([test_weather, process_economic(economic.iloc[0:36,:])], axis=1)\n",
    "#test_weath_econ = test_weath_econ.drop(['Year-Month', 'PartyInPower', 'AdvertisingExpenses (in Thousand Dollars)'], axis=1) #12 rows & 35 cols\n",
    "\n",
    "print(train_weath_econ.shape, test_weath_econ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 34) (72, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create X and Y for weather_economic merge\n",
    "X_train_eco = train_weath_econ.iloc[:,1:] # 84 rows 35 cols\n",
    "Y_eco = train_weath_econ[['target']] # 84 rows 1 cols\n",
    "\n",
    "print(X_train_eco.shape, Y_eco.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "#Split the data\n",
    "\n",
    "x_train = X_train_eco.iloc[0:36,:]\n",
    "x_val = X_train_eco.iloc[36:,:]\n",
    "y_train = Y_eco.iloc[0:36,:]\n",
    "y_val = Y_eco.iloc[36:,:]\n",
    "#y_val\n",
    "\n",
    "#dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "#dvalid = xgb.DMatrix(x_val, label=y_val)\n",
    "# dtest = xgb.DMatrix(test[feature_names].values)\n",
    "#watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 34) (72, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_eco.shape, Y_eco.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 38)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weath_econ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 38)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weath_econ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eco(df):\n",
    "    #Convert year to int\n",
    "    df = df.drop(['year-month'], axis=1)\n",
    "    #df = df.drop(['target'], axis=1)\n",
    "    df = df.drop(['year'], axis=1)\n",
    "    #df = df.drop(['PartyInPower'], axis=1)\n",
    "    #df['AdvertisingExpenses (in Thousand Dollars)'] = df['AdvertisingExpenses (in Thousand Dollars)'].replace('?', np.nan)\n",
    "    #df['AdvertisingExpenses (in Thousand Dollars)'] = df['AdvertisingExpenses (in Thousand Dollars)'].fillna(df['AdvertisingExpenses (in Thousand Dollars)'].median())\n",
    "    #df['AdvertisingExpenses (in Thousand Dollars)'] = df['AdvertisingExpenses (in Thousand Dollars)'].astype(int)    \n",
    "    #df['PartyInPower'] = df['PartyInPower'].astype(int)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weath_econ = process_eco(test_weath_econ)\n",
    "#test_weath_econ.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_weath_econ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_eco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holiday Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "def process_holiday(df):\n",
    "    # Rename columns for ease\n",
    "    df.columns = ['year', 'month-date','event','dat-category']\n",
    "    # Convert year into strings\n",
    "    #df[['year-month']] = df[['year-month']].astype(str)\n",
    "    \n",
    "    # Drop Adversitising, Party\n",
    "    #df = df.drop(['adv','party'], axis=1)\n",
    "    # Convert all other columns to numerics\n",
    "    df[['year', 'month-date','event','dat-category']].apply(pd.to_numeric, errors = \"coerce\")\n",
    "    \n",
    "    # Fill missing values with median of that column # Try mode/mean\n",
    "    df = df.fillna(df.median())\n",
    "      \n",
    "    le.fit(df['event'])\n",
    "    df['event'] = le.transform(df['event'])\n",
    "    le.fit(df['dat-category'])\n",
    "    df['dat-category'] = le.transform(df['dat-category'])\n",
    "    \n",
    "    # Scaled all the numerical attributes using range method (simple custom function below)\n",
    "    df_num = df.select_dtypes(include=[np.number]) # Only include numeric columns\n",
    "    df_norm = (df_num - df_num.mean()) / (df_num.max() - df_num.min()) # Scale the numeric col\n",
    "    df[df_norm.columns] = df_norm # Add them back to the original dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(process_holiday(holiday.iloc[0:36,:]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 37) (36, 39)\n"
     ]
    }
   ],
   "source": [
    "# Merging Hoilday Data with train_eco\n",
    "\n",
    "train_weath_holiday = pd.concat([train_weath_econ, process_holiday(holiday.iloc[0:36,:])], axis=1)\n",
    "train_weath_holiday = train_weath_holiday.drop(['month-date','year'],axis=1) # 84 rows & 36 cols\n",
    "# # Merging Hoilday Data with test_eco\n",
    "test_weath_holiday = pd.concat([test_weath_econ, process_holiday(holiday.iloc[0:36,:])], axis=1)\n",
    "\n",
    "print(train_weath_holiday.shape, test_weath_holiday.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_holi(df):\n",
    "    #Convert year to int\n",
    "    df = df.drop(['month-date'], axis=1)\n",
    "    df = df.drop(['target'], axis=1)\n",
    "    df = df.drop(['year'], axis=1)\n",
    "    \n",
    "    le.fit(df['event'])\n",
    "    df['event'] = le.transform(df['event'])\n",
    "    le.fit(df['dat-category'])\n",
    "    df['dat-category'] = le.transform(df['dat-category'])\n",
    "    \n",
    "    df = df.fillna(df.median())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_holi_test = test_weath_holiday[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weath_holiday = process_holi(test_weath_holiday)\n",
    "#test_weath_holiday.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_weath_holiday.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 36) (72, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create X and Y for weather_economic_holiday merge\n",
    "X_train_holi = train_weath_holiday.iloc[:,1:] \n",
    "X_train_holi = X_train_holi.fillna(X_train_holi.median())\n",
    "Y_holi = train_weath_holiday[['target']]\n",
    "\n",
    "print(X_train_holi.shape, Y_eco.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse function\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     month  temp_high  temp_avg  temp_low  dew_point_high  \\\n",
      "month            12.084507   0.206042  0.228645  0.246387        0.250651   \n",
      "temp_high         0.206042   0.045443  0.046003  0.045079        0.042897   \n",
      "temp_avg          0.228645   0.046003  0.046739  0.045974        0.043815   \n",
      "temp_low          0.246387   0.045079  0.045974  0.045425        0.043393   \n",
      "dew_point_high    0.250651   0.042897  0.043815  0.043393        0.042036   \n",
      "dew_point_avg     0.258384   0.043420  0.044406  0.044049        0.042587   \n",
      "dew_point_low     0.272150   0.044712  0.045786  0.045495        0.044003   \n",
      "humidity_high     0.102285   0.013945  0.014542  0.014801        0.015206   \n",
      "humidity_avg      0.109455   0.008931  0.009585  0.010078        0.010720   \n",
      "humidity_low      0.110666   0.004522  0.005188  0.005854        0.006694   \n",
      "pressure_high     0.021212  -0.008490 -0.008565 -0.008406       -0.008056   \n",
      "pressure_avg      0.041427  -0.002664 -0.002654 -0.002580       -0.002539   \n",
      "pressure_low      0.050791   0.001378  0.001446  0.001460        0.001285   \n",
      "visibility_high  -0.002287  -0.000049 -0.000124 -0.000203       -0.000273   \n",
      "visibility_avg    0.034938   0.000169 -0.000005 -0.000265       -0.000961   \n",
      "visibility_low    0.034765  -0.003754 -0.004069 -0.004387       -0.005171   \n",
      "wind_low         -0.085836  -0.011321 -0.011697 -0.011768       -0.011583   \n",
      "wind_avg         -0.077166  -0.011590 -0.011932 -0.011952       -0.011748   \n",
      "wind_high        -0.065945  -0.009567 -0.009895 -0.009959       -0.009685   \n",
      "gdp               0.178232   0.002673  0.002943  0.003145        0.003554   \n",
      "realgdp           0.183617   0.002347  0.002651  0.002888        0.003194   \n",
      "cpi               0.158874   0.006740  0.006980  0.007149        0.007513   \n",
      "unemployment      0.088668   0.005072  0.005270  0.005603        0.005431   \n",
      "interestrate     -0.070391   0.000587  0.000489  0.000505       -0.000338   \n",
      "financerate      -0.158451   0.001193  0.000744  0.000318        0.000227   \n",
      "wagesperhour      0.090393  -0.004776 -0.004630 -0.004394       -0.004139   \n",
      "cotton           -0.033239  -0.004829 -0.005005 -0.005027       -0.005423   \n",
      "cottonchange      0.018182  -0.006353 -0.006220 -0.005926       -0.006134   \n",
      "planted           0.219074   0.005082  0.005519  0.005825        0.006307   \n",
      "harvested         0.162861   0.003010  0.003746  0.004404        0.003835   \n",
      "yield             0.053331   0.007921  0.008611  0.009142        0.008354   \n",
      "production        0.140282   0.004230  0.004983  0.005634        0.004977   \n",
      "usage            -0.072547  -0.002897 -0.003170 -0.003531       -0.003099   \n",
      "exports          -0.083441  -0.004973 -0.004970 -0.004978       -0.005765   \n",
      "event            -0.114241   0.000154  0.000372  0.000571        0.000635   \n",
      "dat-category     -0.007042  -0.002081 -0.001560 -0.001319       -0.000650   \n",
      "\n",
      "                 dew_point_avg  dew_point_low  humidity_high  humidity_avg  \\\n",
      "month                 0.258384       0.272150       0.102285      0.109455   \n",
      "temp_high             0.043420       0.044712       0.013945      0.008931   \n",
      "temp_avg              0.044406       0.045786       0.014542      0.009585   \n",
      "temp_low              0.044049       0.045495       0.014801      0.010078   \n",
      "dew_point_high        0.042587       0.044003       0.015206      0.010720   \n",
      "dew_point_avg         0.043327       0.044857       0.015716      0.011275   \n",
      "dew_point_low         0.044857       0.046588       0.016482      0.012045   \n",
      "humidity_high         0.015716       0.016482       0.008628      0.007095   \n",
      "humidity_avg          0.011275       0.012045       0.007095      0.006629   \n",
      "humidity_low          0.007256       0.008003       0.005616      0.006020   \n",
      "pressure_high        -0.008434      -0.008944      -0.003672     -0.002659   \n",
      "pressure_avg         -0.002716      -0.002941      -0.001610     -0.001166   \n",
      "pressure_low          0.001262       0.001240      -0.000087     -0.000077   \n",
      "visibility_high      -0.000367      -0.000454      -0.000482     -0.000629   \n",
      "visibility_avg       -0.001203      -0.001420      -0.002821     -0.002855   \n",
      "visibility_low       -0.005480      -0.005817      -0.005059     -0.004497   \n",
      "wind_low             -0.011831      -0.012450      -0.004607     -0.003605   \n",
      "wind_avg             -0.011930      -0.012487      -0.004493     -0.003388   \n",
      "wind_high            -0.009958      -0.010494      -0.003799     -0.002988   \n",
      "gdp                   0.003423       0.003498       0.001539      0.001323   \n",
      "realgdp               0.003046       0.003083       0.001361      0.001094   \n",
      "cpi                   0.007601       0.007979       0.003660      0.003016   \n",
      "unemployment          0.005849       0.006361       0.003869      0.003349   \n",
      "interestrate         -0.000169      -0.000152      -0.000156     -0.000479   \n",
      "financerate           0.000532       0.000608       0.000519     -0.000190   \n",
      "wagesperhour         -0.004240      -0.004333      -0.001341     -0.000519   \n",
      "cotton               -0.005474      -0.005868      -0.002509     -0.002257   \n",
      "cottonchange         -0.006416      -0.006994      -0.002978     -0.002164   \n",
      "planted               0.006217       0.006425       0.002118      0.002043   \n",
      "harvested             0.003777       0.003624       0.000120      0.000135   \n",
      "yield                 0.008559       0.008599       0.002185      0.001414   \n",
      "production            0.004975       0.004852       0.000564      0.000392   \n",
      "usage                -0.003327      -0.003593      -0.001720     -0.001602   \n",
      "exports              -0.006090      -0.006848      -0.003920     -0.003764   \n",
      "event                 0.000988       0.001537       0.000560      0.001476   \n",
      "dat-category         -0.000996      -0.000724       0.000878      0.001379   \n",
      "\n",
      "                 humidity_low      ...         cotton  cottonchange   planted  \\\n",
      "month                0.110666      ...      -0.033239      0.018182  0.219074   \n",
      "temp_high            0.004522      ...      -0.004829     -0.006353  0.005082   \n",
      "temp_avg             0.005188      ...      -0.005005     -0.006220  0.005519   \n",
      "temp_low             0.005854      ...      -0.005027     -0.005926  0.005825   \n",
      "dew_point_high       0.006694      ...      -0.005423     -0.006134  0.006307   \n",
      "dew_point_avg        0.007256      ...      -0.005474     -0.006416  0.006217   \n",
      "dew_point_low        0.008003      ...      -0.005868     -0.006994  0.006425   \n",
      "humidity_high        0.005616      ...      -0.002509     -0.002978  0.002118   \n",
      "humidity_avg         0.006020      ...      -0.002257     -0.002164  0.002043   \n",
      "humidity_low         0.006143      ...      -0.001974     -0.001525  0.001892   \n",
      "pressure_high       -0.001749      ...       0.000834      0.002366  0.000873   \n",
      "pressure_avg        -0.000775      ...      -0.000036      0.000908  0.001248   \n",
      "pressure_low        -0.000078      ...      -0.000495      0.000042  0.001310   \n",
      "visibility_high     -0.000719      ...      -0.000232     -0.000241  0.000201   \n",
      "visibility_avg      -0.002798      ...      -0.000683      0.000009  0.001726   \n",
      "visibility_low      -0.003904      ...       0.000216      0.001224  0.001219   \n",
      "wind_low            -0.002690      ...       0.002542      0.002181 -0.002582   \n",
      "wind_avg            -0.002399      ...       0.002788      0.002110 -0.002742   \n",
      "wind_high           -0.002232      ...       0.001977      0.001627 -0.001796   \n",
      "gdp                  0.001121      ...       0.029958     -0.009561  0.045360   \n",
      "realgdp              0.000866      ...       0.027205     -0.007136  0.040339   \n",
      "cpi                  0.002472      ...       0.025922     -0.011823  0.040061   \n",
      "unemployment         0.002974      ...      -0.006040      0.008651 -0.017559   \n",
      "interestrate        -0.000649      ...      -0.003646      0.011982 -0.028259   \n",
      "financerate         -0.000668      ...      -0.000950     -0.001779 -0.016113   \n",
      "wagesperhour         0.000124      ...       0.028598     -0.006407  0.035991   \n",
      "cotton              -0.001974      ...       0.040469      0.001947  0.018260   \n",
      "cottonchange        -0.001525      ...       0.001947      0.023273 -0.011393   \n",
      "planted              0.001892      ...       0.018260     -0.011393  0.050527   \n",
      "harvested            0.000067      ...       0.042148      0.002583  0.039906   \n",
      "yield                0.000705      ...       0.008571      0.004682  0.002729   \n",
      "production           0.000168      ...       0.037369      0.003440  0.032172   \n",
      "usage               -0.001525      ...       0.004887     -0.008107  0.014914   \n",
      "exports             -0.003644      ...       0.039607      0.011007  0.008120   \n",
      "event                0.002075      ...      -0.008203      0.002205 -0.006549   \n",
      "dat-category         0.001647      ...      -0.008706     -0.009222  0.003038   \n",
      "\n",
      "                 harvested     yield  production     usage   exports  \\\n",
      "month             0.162861  0.053331    0.140282 -0.072547 -0.083441   \n",
      "temp_high         0.003010  0.007921    0.004230 -0.002897 -0.004973   \n",
      "temp_avg          0.003746  0.008611    0.004983 -0.003170 -0.004970   \n",
      "temp_low          0.004404  0.009142    0.005634 -0.003531 -0.004978   \n",
      "dew_point_high    0.003835  0.008354    0.004977 -0.003099 -0.005765   \n",
      "dew_point_avg     0.003777  0.008559    0.004975 -0.003327 -0.006090   \n",
      "dew_point_low     0.003624  0.008599    0.004852 -0.003593 -0.006848   \n",
      "humidity_high     0.000120  0.002185    0.000564 -0.001720 -0.003920   \n",
      "humidity_avg      0.000135  0.001414    0.000392 -0.001602 -0.003764   \n",
      "humidity_low      0.000067  0.000705    0.000168 -0.001525 -0.003644   \n",
      "pressure_high     0.001422 -0.000160    0.001093 -0.000113  0.001989   \n",
      "pressure_avg      0.001100  0.000328    0.000942 -0.000333  0.000611   \n",
      "pressure_low      0.000996  0.000779    0.000966 -0.000561 -0.000078   \n",
      "visibility_high  -0.000216 -0.000155   -0.000215 -0.000148 -0.000713   \n",
      "visibility_avg   -0.000018 -0.000124   -0.000076  0.000224 -0.001617   \n",
      "visibility_low    0.000135 -0.000588   -0.000070  0.000680 -0.000298   \n",
      "wind_low         -0.000815 -0.002240   -0.001126  0.000432  0.003014   \n",
      "wind_avg         -0.000211 -0.001952   -0.000569  0.000577  0.003362   \n",
      "wind_high        -0.000646 -0.001973   -0.000943  0.000771  0.002297   \n",
      "gdp               0.052177  0.003704    0.042235  0.009786  0.022665   \n",
      "realgdp           0.051813  0.004557    0.041601  0.005975  0.022231   \n",
      "cpi               0.038060  0.000139    0.030833  0.008038  0.013574   \n",
      "unemployment     -0.008578 -0.003147   -0.008143 -0.021121 -0.006548   \n",
      "interestrate     -0.007739 -0.001016   -0.006839 -0.022781  0.003393   \n",
      "financerate      -0.013444 -0.000983   -0.011061  0.003571 -0.002565   \n",
      "wagesperhour      0.040600 -0.001536    0.032321  0.007482  0.020650   \n",
      "cotton            0.042148  0.008571    0.037369  0.004887  0.039607   \n",
      "cottonchange      0.002583  0.004682    0.003440 -0.008107  0.011007   \n",
      "planted           0.039906  0.002729    0.032172  0.014914  0.008120   \n",
      "harvested         0.091378  0.030667    0.078294  0.004518  0.054978   \n",
      "yield             0.030667  0.033375    0.032232  0.001776  0.025369   \n",
      "production        0.078294  0.032232    0.069701  0.004110  0.053028   \n",
      "usage             0.004518  0.001776    0.004110  0.022296  0.001808   \n",
      "exports           0.054978  0.025369    0.053028  0.001808  0.068411   \n",
      "event             0.000066  0.008543    0.002674  0.001817  0.008567   \n",
      "dat-category      0.011011  0.002347    0.003322  0.004551 -0.018254   \n",
      "\n",
      "                    event  dat-category  \n",
      "month           -0.114241     -0.007042  \n",
      "temp_high        0.000154     -0.002081  \n",
      "temp_avg         0.000372     -0.001560  \n",
      "temp_low         0.000571     -0.001319  \n",
      "dew_point_high   0.000635     -0.000650  \n",
      "dew_point_avg    0.000988     -0.000996  \n",
      "dew_point_low    0.001537     -0.000724  \n",
      "humidity_high    0.000560      0.000878  \n",
      "humidity_avg     0.001476      0.001379  \n",
      "humidity_low     0.002075      0.001647  \n",
      "pressure_high   -0.003868     -0.000997  \n",
      "pressure_avg    -0.003195     -0.001047  \n",
      "pressure_low    -0.002514     -0.001086  \n",
      "visibility_high -0.001238      0.000339  \n",
      "visibility_avg  -0.003763      0.001406  \n",
      "visibility_low  -0.006324      0.003031  \n",
      "wind_low         0.000391      0.001933  \n",
      "wind_avg        -0.000125      0.003112  \n",
      "wind_high        0.000418      0.002199  \n",
      "gdp             -0.009643      0.006790  \n",
      "realgdp         -0.009264      0.010066  \n",
      "cpi             -0.010292      0.003687  \n",
      "unemployment    -0.001761     -0.000720  \n",
      "interestrate     0.001450     -0.002371  \n",
      "financerate      0.000886     -0.000533  \n",
      "wagesperhour    -0.010901      0.006073  \n",
      "cotton          -0.008203     -0.008706  \n",
      "cottonchange     0.002205     -0.009222  \n",
      "planted         -0.006549      0.003038  \n",
      "harvested        0.000066      0.011011  \n",
      "yield            0.008543      0.002347  \n",
      "production       0.002674      0.003322  \n",
      "usage            0.001817      0.004551  \n",
      "exports          0.008567     -0.018254  \n",
      "event            0.044939      0.002913  \n",
      "dat-category     0.002913      0.150039  \n",
      "\n",
      "[36 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "#test_weath_holiday.dtypes\n",
    "#test_weath_holiday = test_weath_holiday.drop(['month'],axis=1)\n",
    "#X_train_holi = X_train_holi.drop(['month'],axis=1)\n",
    "\n",
    "print(X_train_holi.cov())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 801.6674108\ttotal: 1.53ms\tremaining: 1.53ms\n",
      "1:\tlearn: 582.2141568\ttotal: 2.61ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>1562.202754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>2920.784460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>2984.297660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2988.393152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>3019.282850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>3028.455601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>3222.148990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR</td>\n",
       "      <td>3242.134289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>3252.061496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model         RMSE\n",
       "6           LinearRegression  1562.202754\n",
       "5      DecisionTreeRegressor  2920.784460\n",
       "1               XGBRegressor  2984.297660\n",
       "4         LogisticRegression  2988.393152\n",
       "7  GradientBoostingRegressor  3019.282850\n",
       "2      RandomForestRegressor  3028.455601\n",
       "3          CatBoostRegressor  3222.148990\n",
       "8                        SVR  3242.134289\n",
       "9          AdaBoostRegressor  3252.061496"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from pandas import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# XGBRegressor\n",
    "# A parameter grid for XGBoost\n",
    "params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],\n",
    "'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4]}\n",
    "\n",
    "model_xgbr = XGBRegressor(nthread=-1) \n",
    "model_xgbr = GridSearchCV(model_xgbr, params)\n",
    "model_xgbr.fit(X_train_holi, Y_holi)\n",
    "\n",
    "y_test_xgb = model_xgbr.best_estimator_.predict(test_weath_holiday)\n",
    "y_test_xgb_score = model_xgbr.score(test_weath_holiday, y_test_xgb)\n",
    "#print(test_weath_holiday.values.shape)\n",
    "rmse_xgb_value = rmse(y_test_xgb,test_weath_holiday.values)\n",
    "\n",
    "# RandomForestRegressor\n",
    "model_rfr = RandomForestRegressor(100, oob_score = 1,n_jobs = 1,random_state =42)\n",
    "model_rfr.fit(X_train_holi, Y_holi)\n",
    "\n",
    "y_test_rfr = model_rfr.predict(test_weath_holiday)\n",
    "y_test_rfr_score = model_rfr.score(test_weath_holiday, y_test_xgb)\n",
    "rmse_rfr_value = rmse(y_test_rfr,test_weath_holiday.values)\n",
    "\n",
    "# CatBoostRegressor\n",
    "model_cbr = CatBoostRegressor(iterations=2, learning_rate=1, depth=2)\n",
    "model_cbr.fit(X_train_holi, Y_holi)\n",
    "\n",
    "y_test_cbr = model_cbr.predict(test_weath_holiday)\n",
    "y_test_cbr_score = model_cbr.score(test_weath_holiday, y_test_cbr)\n",
    "rmse_cbr_value = rmse(y_test_cbr, test_weath_holiday.values)\n",
    "\n",
    "# LogisticRegression\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train_holi, Y_holi)\n",
    "\n",
    "y_test_lr = model_lr.predict(test_weath_holiday)\n",
    "y_test_lr_score = model_lr.score(test_weath_holiday, y_test_lr)\n",
    "rmse_lr_value = rmse(y_test_lr, test_weath_holiday.values)\n",
    "\n",
    "# DecisionTreeRegressor\n",
    "model_dtr = DecisionTreeRegressor(random_state=0)\n",
    "model_dtr.fit(X_train_holi, Y_holi)\n",
    "\n",
    "y_test_dtr = model_dtr.predict(test_weath_holiday)\n",
    "y_test_dtr_score = model_dtr.score(test_weath_holiday, y_test_dtr)\n",
    "rmse_dtr_value = rmse(y_test_dtr, test_weath_holiday.values)\n",
    "\n",
    "# LinearRegression\n",
    "model_lrm = LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)\n",
    "model_lrm.fit(X_train_holi, Y_holi)\n",
    "\n",
    "y_test_lrm = model_lrm.predict(test_weath_holiday)\n",
    "y_test_lrm_score = model_lrm.score(test_weath_holiday, y_test_lrm)\n",
    "rmse_lrm_value = rmse(y_test_lrm, test_weath_holiday.values)\n",
    "\n",
    "# GradientBoostingRegressor\n",
    "model_gbr = GradientBoostingRegressor()\n",
    "model_gbr.fit(X_train_holi, Y_holi)\n",
    "\n",
    "y_test_gbr = model_gbr.predict(test_weath_holiday)\n",
    "y_test_gbr_score = model_gbr.score(test_weath_holiday, y_test_gbr)\n",
    "rmse_gbr_value = rmse(y_test_gbr, test_weath_holiday.values)\n",
    "\n",
    "# SVR\n",
    "model_svr = SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "model_svr.fit(X_train_holi, Y_holi)\n",
    "\n",
    "y_test_svr = model_svr.predict(test_weath_holiday)\n",
    "y_test_svr_score = model_svr.score(test_weath_holiday, y_test_svr)\n",
    "rmse_svr_value = rmse(y_test_svr, test_weath_holiday.values)\n",
    "\n",
    "# AdaBoostRegressor\n",
    "model_adb = AdaBoostRegressor()\n",
    "model_adb.fit(X_train_holi, Y_holi)\n",
    "\n",
    "y_test_adb = model_adb.predict(test_weath_holiday)\n",
    "y_test_adb_score = model_adb.score(test_weath_holiday, y_test_adb)\n",
    "rmse_adb_value = rmse(y_test_adb, test_weath_holiday.values)\n",
    "\n",
    "# #ARIMA\n",
    "# #ts = pd.Series(np.random.randn(500), index=pd.date_range('2010-01-01', periods=500))\n",
    "# history = [x for x in X_train_holi]\n",
    "# #print(history)\n",
    "# model_arma = ARIMA(np.asarray(history, dtype=float).mean(), order=(5,1,0))\n",
    "# model_arma.fit(X_train_holi, Y_holi)\n",
    "\n",
    "# y_test_arma = model_arma.predict(test_weath_holiday)\n",
    "# y_test_arma_score = model_arma.score(test_weath_holiday, y_test_arma)\n",
    "# rmse_arma_value = rmse(y_test_arma, test_weath_holiday.values)\n",
    "\n",
    "\n",
    "# Model mapping \n",
    "models = pd.DataFrame({\n",
    "    'Model': ['XGBRegressor', 'RandomForestRegressor', 'CatBoostRegressor',\n",
    "              'LogisticRegression', 'DecisionTreeRegressor', 'LinearRegression',\n",
    "              'GradientBoostingRegressor', 'SVR', 'AdaBoostRegressor'],\n",
    "#     'Score': [y_test_xgb_score, y_test_rfr_score, y_test_cbr_score,\n",
    "#               y_test_lr_score, y_test_dtr_score, y_test_lrm_score,\n",
    "#               y_test_gbr_score, y_test_svr_score, y_test_adb_score],\n",
    "    'RMSE': [rmse_xgb_value, rmse_rfr_value, rmse_cbr_value,\n",
    "             rmse_lr_value, rmse_dtr_value, rmse_lrm_value,\n",
    "             rmse_gbr_value, rmse_svr_value, rmse_adb_value]})\n",
    "models.index = np.arange(1, len(models)+1) # starting index from 1\n",
    "models.sort_values(by='RMSE', ascending=True)\n",
    "\n",
    "# results_xgb = pd.DataFrame(data={'Sales(In ThousandDollars)':y_test_xgb}) \n",
    "# results_xgb.index = np.arange(1, len(results_xgb)+1) # starting index from 1\n",
    "# results_xgb.index.name = \"Year\" # index header name\n",
    "# results_xgb.to_csv('test_results.csv')\n",
    "# results_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
