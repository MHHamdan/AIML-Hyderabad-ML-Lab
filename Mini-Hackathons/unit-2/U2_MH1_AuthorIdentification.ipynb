{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"U2_MH1_AuthorIdentification.ipynb","provenance":[],"collapsed_sections":["1BQEA97zTlTa","ioUZ8pJa9--n","gXGRHmvSJWRd"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"74lzxaiQ9-9s"},"source":["\n","\n","\n","# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"O4mJKZzgrMLp"},"source":["## Problem Statement"]},{"cell_type":"markdown","metadata":{"id":"kiWKLfqkrOB6"},"source":["The problem is to identify the author of a  book from a given list of possible authors."]},{"cell_type":"markdown","metadata":{"id":"6ElufS5-9-99"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"dCHP0foL9--C"},"source":["At the end of the experiment, you will be able to:\n","\n","* Use NLTK package\n","* Extract handcrafted features \n","* Preprocess the text\n","* Write an algorithm to identify author of a given book\n"]},{"cell_type":"code","metadata":{"cellView":"form","id":"nYG9AXM_oe--"},"source":["#@title  Mini Hackathon Walkthrough\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"320\" height=\"240\" controls>\n","  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/authoridentification.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FCz5oobSruGF"},"source":["## Background "]},{"cell_type":"markdown","metadata":{"id":"hZWNTcd4oo-D"},"source":["Author identification is the task of identifying the author of a given text. It can be considered as a typical classification problem, where a set of books with known authors are used for training. The aim is to automatically determine the corresponding author of an anonymous text. "]},{"cell_type":"markdown","metadata":{"id":"1BQEA97zTlTa"},"source":["## Grading = 20 Marks"]},{"cell_type":"markdown","metadata":{"id":"9fYwJv9T9--K"},"source":["## Setup Steps"]},{"cell_type":"code","metadata":{"cellView":"form","id":"HPdGmFba9--f"},"source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"U2_MH1_AuthorIdentification\" #name of the notebook\n","Answer = \"This notebook is graded by mentors on the day of hackathon\"\n","def setup():\n","    ipython.magic(\"sx wget https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/experiment_related_data/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\")\n","    ipython.magic(\"sx unrar e /content/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\")\n","    print (\"Setup completed successfully\")\n","    return\n","\n","setup()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ioUZ8pJa9--n"},"source":["### NOTE: You are allowed to use ML libraries such as Sklearn, NLTK etc wherever applicable"]},{"cell_type":"markdown","metadata":{"id":"jR6_IRo7vTrs"},"source":["### Downloading the required nltk Packages before moving ahead"]},{"cell_type":"code","metadata":{"id":"7BOKJN039--v"},"source":["import nltk\n","nltk.download('gutenberg')\n","nltk.download('punkt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kp3h5QWhNsUv"},"source":["## **Stage 1:** Dataset Preparation"]},{"cell_type":"markdown","metadata":{"id":"4bLZIvs3Ae70"},"source":["### 3 Marks -> Ensure you appropriately split the multiple short stories for the below mentioned authors, Which will be your training data.\n","\n","**1.** Before moving ahead choose two authors based on your team-number allocation: <br/>\n","\n","\n","Team=1,5,9,13 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;    Author-A Vs Author-B <br />\n","Team=2,6,10,14 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;         Author-B Vs Author-C <br />\n","Team=3,7,11,15 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;         Author-C Vs Author-D <br />\n","Team=4,8,12,16 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;           Author-D Vs Author-E <br />\n","\n","\n","\n","**2.** Link to the short stories collection of each author for your problem: <br /> \n","\n","*   Author-A -> Rudyard Kipling   [Short Stories Collection](http://www.gutenberg.org/files/2781/2781-0.txt) &nbsp;&nbsp;\n","*   Author-B -> Anton Chekhov [Short Stories Collection](http://www.gutenberg.org/files/1732/1732-0.txt) &nbsp;&nbsp;\n","*   Author-C -> Guy De Maupassant [Short Stories Collection](http://www.gutenberg.org/cache/epub/21327/pg21327.txt)&nbsp;&nbsp;\n","*   Author-D -> Mark Twain [Short Stories Collection](http://www.gutenberg.org/files/245/245-0.txt)&nbsp;&nbsp;\n","*   Author-E -> Saki [Short Stories Collection](http://www.gutenberg.org/files/1477/1477-0.txt)&nbsp;&nbsp;\n","\n","**Hint for downloading raw text from Gutenberg :**  Refer section \"Electronic Books\" in the following  [link](https://www.nltk.org/book/ch03.html) for the instructions.  \n"," \n","\n","\n","**Hint for finding the index of a text:**   You may use raw.find() and raw.rfind() in the same [link](https://www.nltk.org/book/ch03.html) to find appropriate index of the start and end location \n","\n","**Hint for splitting the multiple stories:** Split the stories using long space (white space character)\n","\n","**Note:** Ignore the table of contents section from the given stories"]},{"cell_type":"code","metadata":{"id":"PQ11fjLkoj8d"},"source":["# YOUR CODE HERE for downloading and splitting the multiple stories of respective authors which are allocated to you"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mIC7IE8lmFDA"},"source":["## **Stage 2**: Experiment with Handcrafted features representation\n","Extract Handcrafted features for the obtained short stories from **Stage-1**\n","\n","**Stylometry:** \n","\n","Each person has a unique vocabulary, sometimes rich, sometimes limited. Although a larger vocabulary is usually associated with literary quality, this is not always the case. Ernest Hemingway is famous for using a surprisingly small number of different words in his writing, which did not prevent him from winning the Nobel Prize for Literature in 1954.\n","\n","Some people write in short sentences, while others prefer long blocks of text consisting of many clauses. No two people use semicolons, em-dashes, and other forms of punctuation in the same way.\n","\n","\n","\n","\n","**You may explore the following ways to analyze the text and generate handcrafted features by searching text in a probing way:**\n","\n","a)  Could the style of punctuation usage help as a handcrafted feature? Both by those who follow punctuations and by those who don't? Interesting [link](https://qwiklit.com/2014/03/05/top-10-authors-who-ignored-the-basic-rules-of-punctuation/) \n","\n","b) The same word can sometimes be used in different contexts repeatedly by different authors. Could this fact be converted as a handcrafted feature? [link](https://www.nltk.org/book/ch01.html)\n","\n","c) The above two are merely examples; As you might have noticed already the NLTK book [link](https://www.nltk.org/book/) offers several methods of analyzing and understanding the text. Each of these analyses is in itself capable of being a handcrafted feature. **However for your evaluation a minimal set of useful handcrafted features which is helping you prove a classification of an is sufficient**\n","\n","d) Could most command words be used to distinguish authors?  Refer \"Counting Vocabulary\" section of the [link](https://www.nltk.org/book/ch01.html)\n","\n","e) How about using a count of most frequently used bi-gram, tri-grams, and using it to classify an author?\n","\n","f) How about using the frequency histogram of the most frequently used words across the stories by a given author a useful feature? \n","\n","The limit here is endlessly limited only by your imagination, and of course your accuracy! :)\n"]},{"cell_type":"markdown","metadata":{"id":"ZmJX5Jl1CRKg"},"source":["### 2 Marks ->  a) List 6 handcrafted features to distinguish author stories."]},{"cell_type":"code","metadata":{"id":"TUJlJdy_EGAP"},"source":["# For eg:\n","# 1. UniqueWords\n","# 2. AvgSentLength\n","# List the other handcrafted features here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E4Bynbq3C4o1"},"source":["###  4 Marks -> b) Write functions for any 4 of the above 6 handcrafted features and label your authors accordingly.\n","\n","- Get any 4 hand crafted features from the above listed 6 hand-crafted features for every story obtained from **stage-1**.\n","- Identify your target variable as author and label them accordingly."]},{"cell_type":"code","metadata":{"id":"xwA5nx2IEAhN"},"source":["# Stories_list    UniqueWords    AvgSentLength     Label \n","#     1               x1               x2            y \n","\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QiJOpSJ0yJod"},"source":["##**Stage 3:** Experiment with Text processing and representation:\n","Extract features using TFIDF or CountVectorizer or Word2vec for the obtained short stories from **Stage-1**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ecMmcZfm_Eek"},"source":["### 1 Mark -> a) Performing basic cleanup operations such as removing the newline characters and removing trailing spaces\n","\n","**For example,** Your sentence looks as follows \\[' This is a sentence\\n\\r. Another sentence \\n'].\n","\n","After newline removal from the above example, your sentence will look like \\['This is a sentence. Another sentence'].\n","\n"," In order to do this you can try using a combination of split() and join()"]},{"cell_type":"code","metadata":{"id":"vw2DhQGK_Eel"},"source":["# YOUR CODE HERE "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z64gLpY2_Ee1"},"source":["###  5 Marks-> b) Generate vectors for the given stories"]},{"cell_type":"markdown","metadata":{"id":"rbkfSFT2xXJY"},"source":["Create a representation of text, convert it into vectors (numbers)\n","\n","\n","**Use any one** of the following algorithms for this task :\n","\n","* Countvectorizer or\n","* TFIDFVectorizer or \n","* Word2Vec (The word2vec bin file (AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD) can be downloaded as a part of setup  )\n","  * perform sentence level tokenization and word level tokenization for the given stories\n","\n","    **Example of sentences as list of words:**<br/>\n","    **Before:** ['This is a sentence .' , ' Another sentence']<br/>\n","    **After:** ['This', 'is' ,'a', 'sentence' , ' . ' , ' Another ', ' sentence ' ]\n","\n","References Documents: \n","\n","1.   [Countvectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n","2.  [TFIDFVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n"]},{"cell_type":"code","metadata":{"id":"Kyk9-3BRhCf-"},"source":["# YOUR CODE HERE (HINT: Convert to numpy array if needed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lgEtwoYw_Eet"},"source":["###  1 Mark -> c) Is stop word removal necessary in the context of author identification? Your thoughts below?"]},{"cell_type":"code","metadata":{"id":"mLrl-HCA_Eeu"},"source":["# YOUR ANSWER IN TEXT"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vWZ-5hiZN-jR"},"source":["##**Stage 4:** Classification :\n","\n","### Expected accuracy is above 85%"]},{"cell_type":"markdown","metadata":{"id":"p9eqZubqiRKi"},"source":["### 4 Marks -> Perform a classification using either features obtained from Stage2 or Stage3"]},{"cell_type":"code","metadata":{"id":"lKmfqV25a05p"},"source":["# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gXGRHmvSJWRd"},"source":["# Further Ideas for exploration after the hackathon:\n","\n","**Statistical analysis** of text using NLP, by analysis meaning of sentences, feature based grammars and analyzing structure of sentences! \n","\n","reference: www.nltk.org/book"]}]}